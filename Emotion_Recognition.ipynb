{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\Anaconda3\\envs\\may\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist= os.listdir('Audio_Song_Actors_01-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-02-01-01-01-01-20.wav\n"
     ]
    }
   ],
   "source": [
    "print(mylist[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03\n"
     ]
    }
   ],
   "source": [
    "print(mylist[400][6:-16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the audio file's waveform and its spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('Audio_Song_Actors_01-24/03-02-06-02-02-01-15.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x2a263738470>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# % pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\Anaconda3\\envs\\may\\lib\\site-packages\\ipykernel_launcher.py:7: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incomplete wav chunk.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5b8917c70f58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwavfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Audio_Song_Actors_01-24/03-02-06-02-02-01-15.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m## Parameters: 10ms step, 30ms window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\may\\lib\\site-packages\\scipy\\io\\wavfile.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unexpected end of file.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Incomplete wav chunk.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mchunk_id\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb'fmt '\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Incomplete wav chunk."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "import wavio\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "sr,x = scipy.io.wavfile.read('Audio_Song_Actors_01-24/03-02-06-02-02-01-15.wav')\n",
    "\n",
    "## Parameters: 10ms step, 30ms window\n",
    "nstep = int(sr * 0.01)\n",
    "nwin  = int(sr * 0.03)\n",
    "nfft = nwin\n",
    "\n",
    "window = np.hamming(nwin)\n",
    "\n",
    "## will take windows x[n1:n2].  generate\n",
    "## and loop over n2 such that all frames\n",
    "## fit within the waveform\n",
    "nn = range(nwin, len(x), nstep)\n",
    "\n",
    "X = np.zeros( (len(nn), nfft//2) )\n",
    "\n",
    "for i,n in enumerate(nn):\n",
    "    xseg = x[n-nwin:n]\n",
    "    z = np.fft.fft(window * xseg, nfft)\n",
    "    X[i,:] = np.log(np.abs(z[:nfft//2]))\n",
    "\n",
    "plt.imshow(X.T, interpolation='nearest',\n",
    "    origin='lower',\n",
    "    aspect='auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_calm')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_calm')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_sad')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='a':\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[:1]=='f':\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='h':\n",
    "        feeling_list.append('male_happy')\n",
    "    #elif item[:1]=='n':\n",
    "        #feeling_list.append('neutral')\n",
    "    elif item[:2]=='sa':\n",
    "        feeling_list.append('male_sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(feeling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    male_calm\n",
       "1  female_calm\n",
       "2    male_calm\n",
       "3  female_calm\n",
       "4    male_calm\n",
       "5  female_calm\n",
       "6    male_calm\n",
       "7  female_calm\n",
       "8    male_calm\n",
       "9  female_calm"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the features of audio files using librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "        X, sample_rate = librosa.load('Audio_Song_Actors_01-24/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        #[float(i) for i in feature]\n",
    "        #feature1=feature[:135]\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-61.542942, -61.67029, -61.663513, -61.675594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-59.344055, -59.344055, -59.344055, -59.34405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-48.954494, -48.82861, -49.6816, -52.03216, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-60.07603, -60.313347, -59.857048, -57.80332,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-60.01485, -62.686897, -65.488106, -60.48127,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-61.542942, -61.67029, -61.663513, -61.675594...\n",
       "1  [-59.344055, -59.344055, -59.344055, -59.34405...\n",
       "2  [-48.954494, -48.82861, -49.6816, -52.03216, -...\n",
       "3  [-60.07603, -60.313347, -59.857048, -57.80332,...\n",
       "4  [-60.01485, -62.686897, -65.488106, -60.48127,..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-61.542942</td>\n",
       "      <td>-61.670292</td>\n",
       "      <td>-61.663513</td>\n",
       "      <td>-61.675594</td>\n",
       "      <td>-59.627464</td>\n",
       "      <td>-58.578274</td>\n",
       "      <td>-60.384644</td>\n",
       "      <td>-60.370815</td>\n",
       "      <td>-59.209068</td>\n",
       "      <td>-59.793682</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.029648</td>\n",
       "      <td>-28.536741</td>\n",
       "      <td>-27.502647</td>\n",
       "      <td>-26.418858</td>\n",
       "      <td>-27.831207</td>\n",
       "      <td>-28.752033</td>\n",
       "      <td>-28.786449</td>\n",
       "      <td>-21.615858</td>\n",
       "      <td>-17.308699</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.964802</td>\n",
       "      <td>-43.955097</td>\n",
       "      <td>-44.208008</td>\n",
       "      <td>-43.749870</td>\n",
       "      <td>-42.165371</td>\n",
       "      <td>-43.236343</td>\n",
       "      <td>-43.611912</td>\n",
       "      <td>-20.658558</td>\n",
       "      <td>-12.422130</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-48.954494</td>\n",
       "      <td>-48.828609</td>\n",
       "      <td>-49.681599</td>\n",
       "      <td>-52.032162</td>\n",
       "      <td>-48.399113</td>\n",
       "      <td>-47.975899</td>\n",
       "      <td>-49.650616</td>\n",
       "      <td>-51.260963</td>\n",
       "      <td>-49.758038</td>\n",
       "      <td>-50.975227</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.577650</td>\n",
       "      <td>-24.113667</td>\n",
       "      <td>-22.895826</td>\n",
       "      <td>-22.712572</td>\n",
       "      <td>-24.839592</td>\n",
       "      <td>-27.322344</td>\n",
       "      <td>-28.557560</td>\n",
       "      <td>-28.592690</td>\n",
       "      <td>-25.435741</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-60.076031</td>\n",
       "      <td>-60.313347</td>\n",
       "      <td>-59.857048</td>\n",
       "      <td>-57.803322</td>\n",
       "      <td>-58.947750</td>\n",
       "      <td>-59.264015</td>\n",
       "      <td>-57.992619</td>\n",
       "      <td>-57.401936</td>\n",
       "      <td>-57.059830</td>\n",
       "      <td>-57.166061</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.776798</td>\n",
       "      <td>-40.195335</td>\n",
       "      <td>-38.818481</td>\n",
       "      <td>-39.010696</td>\n",
       "      <td>-41.907330</td>\n",
       "      <td>-42.493778</td>\n",
       "      <td>-43.464279</td>\n",
       "      <td>-36.841316</td>\n",
       "      <td>-29.907366</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-60.014851</td>\n",
       "      <td>-62.686897</td>\n",
       "      <td>-65.488106</td>\n",
       "      <td>-60.481270</td>\n",
       "      <td>-60.038151</td>\n",
       "      <td>-64.788376</td>\n",
       "      <td>-66.386238</td>\n",
       "      <td>-61.152500</td>\n",
       "      <td>-58.949646</td>\n",
       "      <td>-59.597214</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.592575</td>\n",
       "      <td>-42.287838</td>\n",
       "      <td>-42.087948</td>\n",
       "      <td>-42.331047</td>\n",
       "      <td>-40.317867</td>\n",
       "      <td>-37.837944</td>\n",
       "      <td>-35.932858</td>\n",
       "      <td>-32.704998</td>\n",
       "      <td>-28.022449</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0 -61.542942 -61.670292 -61.663513 -61.675594 -59.627464 -58.578274   \n",
       "1 -59.344055 -59.344055 -59.344055 -59.344055 -59.344055 -59.344055   \n",
       "2 -48.954494 -48.828609 -49.681599 -52.032162 -48.399113 -47.975899   \n",
       "3 -60.076031 -60.313347 -59.857048 -57.803322 -58.947750 -59.264015   \n",
       "4 -60.014851 -62.686897 -65.488106 -60.481270 -60.038151 -64.788376   \n",
       "\n",
       "         6          7          8          9    ...        207        208  \\\n",
       "0 -60.384644 -60.370815 -59.209068 -59.793682  ... -32.029648 -28.536741   \n",
       "1 -59.344055 -59.344055 -59.344055 -59.344055  ... -42.964802 -43.955097   \n",
       "2 -49.650616 -51.260963 -49.758038 -50.975227  ... -23.577650 -24.113667   \n",
       "3 -57.992619 -57.401936 -57.059830 -57.166061  ... -42.776798 -40.195335   \n",
       "4 -66.386238 -61.152500 -58.949646 -59.597214  ... -43.592575 -42.287838   \n",
       "\n",
       "         209        210        211        212        213        214  \\\n",
       "0 -27.502647 -26.418858 -27.831207 -28.752033 -28.786449 -21.615858   \n",
       "1 -44.208008 -43.749870 -42.165371 -43.236343 -43.611912 -20.658558   \n",
       "2 -22.895826 -22.712572 -24.839592 -27.322344 -28.557560 -28.592690   \n",
       "3 -38.818481 -39.010696 -41.907330 -42.493778 -43.464279 -36.841316   \n",
       "4 -42.087948 -42.331047 -40.317867 -37.837944 -35.932858 -32.704998   \n",
       "\n",
       "         215          0    \n",
       "0 -17.308699    male_calm  \n",
       "1 -12.422130  female_calm  \n",
       "2 -25.435741    male_calm  \n",
       "3 -29.907366  female_calm  \n",
       "4 -28.022449    male_calm  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnewdf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>-66.509750</td>\n",
       "      <td>-66.509750</td>\n",
       "      <td>-65.822456</td>\n",
       "      <td>-64.809219</td>\n",
       "      <td>-66.102219</td>\n",
       "      <td>-66.087387</td>\n",
       "      <td>-65.922943</td>\n",
       "      <td>-64.785065</td>\n",
       "      <td>-65.326797</td>\n",
       "      <td>-66.509750</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.988800</td>\n",
       "      <td>-35.967766</td>\n",
       "      <td>-35.286049</td>\n",
       "      <td>-35.278831</td>\n",
       "      <td>-34.740929</td>\n",
       "      <td>-33.830132</td>\n",
       "      <td>-34.372265</td>\n",
       "      <td>-27.292450</td>\n",
       "      <td>-21.947689</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>-54.954708</td>\n",
       "      <td>-55.314987</td>\n",
       "      <td>-55.057285</td>\n",
       "      <td>-54.872440</td>\n",
       "      <td>-54.372139</td>\n",
       "      <td>-54.192894</td>\n",
       "      <td>-55.845810</td>\n",
       "      <td>-55.657249</td>\n",
       "      <td>-55.506344</td>\n",
       "      <td>-55.612911</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.676435</td>\n",
       "      <td>-18.845058</td>\n",
       "      <td>-20.505796</td>\n",
       "      <td>-19.861799</td>\n",
       "      <td>-18.432095</td>\n",
       "      <td>-18.100405</td>\n",
       "      <td>-19.246204</td>\n",
       "      <td>-17.491056</td>\n",
       "      <td>-13.092523</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>-47.044193</td>\n",
       "      <td>-47.289349</td>\n",
       "      <td>-47.470638</td>\n",
       "      <td>-48.799614</td>\n",
       "      <td>-49.333187</td>\n",
       "      <td>-49.770626</td>\n",
       "      <td>-51.110378</td>\n",
       "      <td>-50.408272</td>\n",
       "      <td>-48.978878</td>\n",
       "      <td>-49.951946</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.393440</td>\n",
       "      <td>-43.701225</td>\n",
       "      <td>-43.187355</td>\n",
       "      <td>-42.882408</td>\n",
       "      <td>-41.781040</td>\n",
       "      <td>-40.758301</td>\n",
       "      <td>-40.495689</td>\n",
       "      <td>-26.161119</td>\n",
       "      <td>-17.332867</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>-53.631245</td>\n",
       "      <td>-53.396553</td>\n",
       "      <td>-52.188229</td>\n",
       "      <td>-52.714775</td>\n",
       "      <td>-53.663898</td>\n",
       "      <td>-52.832962</td>\n",
       "      <td>-52.588661</td>\n",
       "      <td>-52.761787</td>\n",
       "      <td>-52.586689</td>\n",
       "      <td>-56.523075</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.393986</td>\n",
       "      <td>-42.583073</td>\n",
       "      <td>-44.382141</td>\n",
       "      <td>-44.495911</td>\n",
       "      <td>-45.511631</td>\n",
       "      <td>-44.837948</td>\n",
       "      <td>-43.241463</td>\n",
       "      <td>-40.181438</td>\n",
       "      <td>-35.077282</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>-42.368225</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.699057</td>\n",
       "      <td>-32.587414</td>\n",
       "      <td>-30.132870</td>\n",
       "      <td>-30.099989</td>\n",
       "      <td>-32.439384</td>\n",
       "      <td>-35.606876</td>\n",
       "      <td>-35.007420</td>\n",
       "      <td>-6.784913</td>\n",
       "      <td>1.771483</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>-51.863243</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.939270</td>\n",
       "      <td>-24.900156</td>\n",
       "      <td>-24.463625</td>\n",
       "      <td>-23.779470</td>\n",
       "      <td>-23.550243</td>\n",
       "      <td>-23.911640</td>\n",
       "      <td>-23.861238</td>\n",
       "      <td>-16.416420</td>\n",
       "      <td>-12.178488</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-49.591824</td>\n",
       "      <td>-48.310486</td>\n",
       "      <td>-47.640793</td>\n",
       "      <td>-46.625343</td>\n",
       "      <td>-47.571945</td>\n",
       "      <td>-45.061790</td>\n",
       "      <td>-44.766438</td>\n",
       "      <td>-47.780540</td>\n",
       "      <td>-48.729347</td>\n",
       "      <td>-49.939213</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.188894</td>\n",
       "      <td>-24.044216</td>\n",
       "      <td>-23.870291</td>\n",
       "      <td>-25.385349</td>\n",
       "      <td>-24.725368</td>\n",
       "      <td>-24.086088</td>\n",
       "      <td>-25.574514</td>\n",
       "      <td>-14.032943</td>\n",
       "      <td>-9.047819</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-51.352337</td>\n",
       "      <td>-51.739861</td>\n",
       "      <td>-51.824787</td>\n",
       "      <td>-51.898354</td>\n",
       "      <td>-53.880802</td>\n",
       "      <td>-55.147137</td>\n",
       "      <td>-56.017246</td>\n",
       "      <td>-57.151360</td>\n",
       "      <td>-53.582645</td>\n",
       "      <td>-52.549515</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.520126</td>\n",
       "      <td>-48.110996</td>\n",
       "      <td>-48.306107</td>\n",
       "      <td>-49.382084</td>\n",
       "      <td>-49.741432</td>\n",
       "      <td>-47.963890</td>\n",
       "      <td>-49.856045</td>\n",
       "      <td>-48.339905</td>\n",
       "      <td>-48.574669</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>-47.872246</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.040310</td>\n",
       "      <td>-41.931236</td>\n",
       "      <td>-41.863094</td>\n",
       "      <td>-41.289543</td>\n",
       "      <td>-40.327633</td>\n",
       "      <td>-41.391624</td>\n",
       "      <td>-42.071861</td>\n",
       "      <td>-36.798592</td>\n",
       "      <td>-30.512257</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>-47.028503</td>\n",
       "      <td>-47.306553</td>\n",
       "      <td>-46.636471</td>\n",
       "      <td>-45.185234</td>\n",
       "      <td>-46.110672</td>\n",
       "      <td>-46.848824</td>\n",
       "      <td>-46.637112</td>\n",
       "      <td>-49.055954</td>\n",
       "      <td>-48.240440</td>\n",
       "      <td>-46.492306</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.329691</td>\n",
       "      <td>-21.944942</td>\n",
       "      <td>-22.006681</td>\n",
       "      <td>-24.828522</td>\n",
       "      <td>-27.322060</td>\n",
       "      <td>-27.433422</td>\n",
       "      <td>-29.647484</td>\n",
       "      <td>-25.831942</td>\n",
       "      <td>-24.255632</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "123 -66.509750 -66.509750 -65.822456 -64.809219 -66.102219 -66.087387   \n",
       "675 -54.954708 -55.314987 -55.057285 -54.872440 -54.372139 -54.192894   \n",
       "881 -47.044193 -47.289349 -47.470638 -48.799614 -49.333187 -49.770626   \n",
       "444 -53.631245 -53.396553 -52.188229 -52.714775 -53.663898 -52.832962   \n",
       "708 -42.368225 -42.368225 -42.368225 -42.368225 -42.368225 -42.368225   \n",
       "895 -51.863243 -51.863243 -51.863243 -51.863243 -51.863243 -51.863243   \n",
       "320 -49.591824 -48.310486 -47.640793 -46.625343 -47.571945 -45.061790   \n",
       "53  -51.352337 -51.739861 -51.824787 -51.898354 -53.880802 -55.147137   \n",
       "294 -47.872246 -47.872246 -47.872246 -47.872246 -47.872246 -47.872246   \n",
       "462 -47.028503 -47.306553 -46.636471 -45.185234 -46.110672 -46.848824   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "123 -65.922943 -64.785065 -65.326797 -66.509750  ... -35.988800 -35.967766   \n",
       "675 -55.845810 -55.657249 -55.506344 -55.612911  ... -17.676435 -18.845058   \n",
       "881 -51.110378 -50.408272 -48.978878 -49.951946  ... -43.393440 -43.701225   \n",
       "444 -52.588661 -52.761787 -52.586689 -56.523075  ... -42.393986 -42.583073   \n",
       "708 -42.368225 -42.368225 -42.368225 -42.368225  ... -31.699057 -32.587414   \n",
       "895 -51.863243 -51.863243 -51.863243 -51.863243  ... -24.939270 -24.900156   \n",
       "320 -44.766438 -47.780540 -48.729347 -49.939213  ... -25.188894 -24.044216   \n",
       "53  -56.017246 -57.151360 -53.582645 -52.549515  ... -44.520126 -48.110996   \n",
       "294 -47.872246 -47.872246 -47.872246 -47.872246  ... -41.040310 -41.931236   \n",
       "462 -46.637112 -49.055954 -48.240440 -46.492306  ... -24.329691 -21.944942   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "123 -35.286049 -35.278831 -34.740929 -33.830132 -34.372265 -27.292450   \n",
       "675 -20.505796 -19.861799 -18.432095 -18.100405 -19.246204 -17.491056   \n",
       "881 -43.187355 -42.882408 -41.781040 -40.758301 -40.495689 -26.161119   \n",
       "444 -44.382141 -44.495911 -45.511631 -44.837948 -43.241463 -40.181438   \n",
       "708 -30.132870 -30.099989 -32.439384 -35.606876 -35.007420  -6.784913   \n",
       "895 -24.463625 -23.779470 -23.550243 -23.911640 -23.861238 -16.416420   \n",
       "320 -23.870291 -25.385349 -24.725368 -24.086088 -25.574514 -14.032943   \n",
       "53  -48.306107 -49.382084 -49.741432 -47.963890 -49.856045 -48.339905   \n",
       "294 -41.863094 -41.289543 -40.327633 -41.391624 -42.071861 -36.798592   \n",
       "462 -22.006681 -24.828522 -27.322060 -27.433422 -29.647484 -25.831942   \n",
       "\n",
       "           215             0    \n",
       "123 -21.947689       male_calm  \n",
       "675 -13.092523      male_angry  \n",
       "881 -17.332867  female_fearful  \n",
       "444 -35.077282      female_sad  \n",
       "708   1.771483    female_angry  \n",
       "895 -12.178488    male_fearful  \n",
       "320  -9.047819      male_happy  \n",
       "53  -48.574669     female_calm  \n",
       "294 -30.512257    female_happy  \n",
       "462 -24.255632        male_sad  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>-52.608078</td>\n",
       "      <td>-49.516914</td>\n",
       "      <td>-50.374348</td>\n",
       "      <td>-53.096924</td>\n",
       "      <td>-52.763943</td>\n",
       "      <td>-50.902691</td>\n",
       "      <td>-49.895927</td>\n",
       "      <td>-47.445251</td>\n",
       "      <td>-47.316082</td>\n",
       "      <td>-43.325771</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.610821</td>\n",
       "      <td>-24.327301</td>\n",
       "      <td>-24.709219</td>\n",
       "      <td>-27.589947</td>\n",
       "      <td>-26.442131</td>\n",
       "      <td>-26.327812</td>\n",
       "      <td>-25.804108</td>\n",
       "      <td>-19.461014</td>\n",
       "      <td>-14.189299</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-60.076031</td>\n",
       "      <td>-60.313347</td>\n",
       "      <td>-59.857048</td>\n",
       "      <td>-57.803322</td>\n",
       "      <td>-58.947750</td>\n",
       "      <td>-59.264015</td>\n",
       "      <td>-57.992619</td>\n",
       "      <td>-57.401936</td>\n",
       "      <td>-57.059830</td>\n",
       "      <td>-57.166061</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.776798</td>\n",
       "      <td>-40.195335</td>\n",
       "      <td>-38.818481</td>\n",
       "      <td>-39.010696</td>\n",
       "      <td>-41.907330</td>\n",
       "      <td>-42.493778</td>\n",
       "      <td>-43.464279</td>\n",
       "      <td>-36.841316</td>\n",
       "      <td>-29.907366</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>-50.002640</td>\n",
       "      <td>-50.114021</td>\n",
       "      <td>-51.335884</td>\n",
       "      <td>-51.368019</td>\n",
       "      <td>-51.357754</td>\n",
       "      <td>-50.199341</td>\n",
       "      <td>-49.533943</td>\n",
       "      <td>-49.755497</td>\n",
       "      <td>-50.893185</td>\n",
       "      <td>-49.808876</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.585426</td>\n",
       "      <td>-39.068604</td>\n",
       "      <td>-39.899551</td>\n",
       "      <td>-38.985703</td>\n",
       "      <td>-39.612740</td>\n",
       "      <td>-41.767555</td>\n",
       "      <td>-42.121475</td>\n",
       "      <td>-23.383146</td>\n",
       "      <td>-16.090076</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>-49.168858</td>\n",
       "      <td>-46.598984</td>\n",
       "      <td>-45.677940</td>\n",
       "      <td>-46.527248</td>\n",
       "      <td>-49.652214</td>\n",
       "      <td>-48.046116</td>\n",
       "      <td>-47.477135</td>\n",
       "      <td>-45.425594</td>\n",
       "      <td>-45.391949</td>\n",
       "      <td>-45.334816</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.416927</td>\n",
       "      <td>-43.439781</td>\n",
       "      <td>-46.734238</td>\n",
       "      <td>-45.012756</td>\n",
       "      <td>-42.766567</td>\n",
       "      <td>-43.993099</td>\n",
       "      <td>-45.036140</td>\n",
       "      <td>-22.641428</td>\n",
       "      <td>-13.785501</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>-45.047260</td>\n",
       "      <td>-45.014275</td>\n",
       "      <td>-45.090595</td>\n",
       "      <td>-44.972416</td>\n",
       "      <td>-45.012264</td>\n",
       "      <td>-44.720352</td>\n",
       "      <td>-44.659321</td>\n",
       "      <td>-44.350342</td>\n",
       "      <td>-44.390793</td>\n",
       "      <td>-44.119331</td>\n",
       "      <td>...</td>\n",
       "      <td>-35.444653</td>\n",
       "      <td>-34.365459</td>\n",
       "      <td>-32.823845</td>\n",
       "      <td>-34.002800</td>\n",
       "      <td>-35.127888</td>\n",
       "      <td>-35.148537</td>\n",
       "      <td>-36.351570</td>\n",
       "      <td>-22.161703</td>\n",
       "      <td>-16.037973</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-61.197495</td>\n",
       "      <td>-61.591118</td>\n",
       "      <td>-58.713886</td>\n",
       "      <td>-58.276283</td>\n",
       "      <td>-61.533199</td>\n",
       "      <td>-61.718014</td>\n",
       "      <td>-61.686478</td>\n",
       "      <td>-61.306633</td>\n",
       "      <td>-59.106869</td>\n",
       "      <td>-59.439903</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.732288</td>\n",
       "      <td>-29.556192</td>\n",
       "      <td>-27.134611</td>\n",
       "      <td>-28.124929</td>\n",
       "      <td>-28.885090</td>\n",
       "      <td>-28.086546</td>\n",
       "      <td>-28.274565</td>\n",
       "      <td>-24.938246</td>\n",
       "      <td>-20.766357</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>-60.602760</td>\n",
       "      <td>-60.924969</td>\n",
       "      <td>-61.564854</td>\n",
       "      <td>-58.466652</td>\n",
       "      <td>-56.777584</td>\n",
       "      <td>-58.518856</td>\n",
       "      <td>-60.507912</td>\n",
       "      <td>-60.939365</td>\n",
       "      <td>-61.327938</td>\n",
       "      <td>-62.278896</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.085529</td>\n",
       "      <td>-45.905193</td>\n",
       "      <td>-45.820110</td>\n",
       "      <td>-45.183754</td>\n",
       "      <td>-45.501438</td>\n",
       "      <td>-43.343258</td>\n",
       "      <td>-43.069851</td>\n",
       "      <td>-42.566338</td>\n",
       "      <td>-36.447304</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-59.283310</td>\n",
       "      <td>-59.283310</td>\n",
       "      <td>-59.283310</td>\n",
       "      <td>-59.283310</td>\n",
       "      <td>-59.283310</td>\n",
       "      <td>-59.283310</td>\n",
       "      <td>-59.283310</td>\n",
       "      <td>-60.162197</td>\n",
       "      <td>-58.328056</td>\n",
       "      <td>-58.705463</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.280170</td>\n",
       "      <td>-37.908653</td>\n",
       "      <td>-37.050064</td>\n",
       "      <td>-38.493828</td>\n",
       "      <td>-38.409847</td>\n",
       "      <td>-40.297588</td>\n",
       "      <td>-40.275467</td>\n",
       "      <td>-26.389078</td>\n",
       "      <td>-18.184639</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-54.618992</td>\n",
       "      <td>-54.074741</td>\n",
       "      <td>-56.352791</td>\n",
       "      <td>-59.550545</td>\n",
       "      <td>-58.432732</td>\n",
       "      <td>-55.242760</td>\n",
       "      <td>-54.547325</td>\n",
       "      <td>-56.185379</td>\n",
       "      <td>-57.388470</td>\n",
       "      <td>-57.412113</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.968554</td>\n",
       "      <td>-30.679962</td>\n",
       "      <td>-31.553383</td>\n",
       "      <td>-27.987570</td>\n",
       "      <td>-25.827244</td>\n",
       "      <td>-24.439589</td>\n",
       "      <td>-25.158400</td>\n",
       "      <td>-21.805180</td>\n",
       "      <td>-16.859730</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>-55.711002</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.372776</td>\n",
       "      <td>-39.288120</td>\n",
       "      <td>-41.244530</td>\n",
       "      <td>-41.955376</td>\n",
       "      <td>-41.237968</td>\n",
       "      <td>-40.284386</td>\n",
       "      <td>-41.162289</td>\n",
       "      <td>-36.426846</td>\n",
       "      <td>-29.188198</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "585 -52.608078 -49.516914 -50.374348 -53.096924 -52.763943 -50.902691   \n",
       "3   -60.076031 -60.313347 -59.857048 -57.803322 -58.947750 -59.264015   \n",
       "745 -50.002640 -50.114021 -51.335884 -51.368019 -51.357754 -50.199341   \n",
       "636 -49.168858 -46.598984 -45.677940 -46.527248 -49.652214 -48.046116   \n",
       "733 -45.047260 -45.014275 -45.090595 -44.972416 -45.012264 -44.720352   \n",
       "136 -61.197495 -61.591118 -58.713886 -58.276283 -61.533199 -61.718014   \n",
       "371 -60.602760 -60.924969 -61.564854 -58.466652 -56.777584 -58.518856   \n",
       "49  -59.283310 -59.283310 -59.283310 -59.283310 -59.283310 -59.283310   \n",
       "234 -54.618992 -54.074741 -56.352791 -59.550545 -58.432732 -55.242760   \n",
       "639 -55.711002 -55.711002 -55.711002 -55.711002 -55.711002 -55.711002   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "585 -49.895927 -47.445251 -47.316082 -43.325771  ... -23.610821 -24.327301   \n",
       "3   -57.992619 -57.401936 -57.059830 -57.166061  ... -42.776798 -40.195335   \n",
       "745 -49.533943 -49.755497 -50.893185 -49.808876  ... -37.585426 -39.068604   \n",
       "636 -47.477135 -45.425594 -45.391949 -45.334816  ... -42.416927 -43.439781   \n",
       "733 -44.659321 -44.350342 -44.390793 -44.119331  ... -35.444653 -34.365459   \n",
       "136 -61.686478 -61.306633 -59.106869 -59.439903  ... -33.732288 -29.556192   \n",
       "371 -60.507912 -60.939365 -61.327938 -62.278896  ... -47.085529 -45.905193   \n",
       "49  -59.283310 -60.162197 -58.328056 -58.705463  ... -42.280170 -37.908653   \n",
       "234 -54.547325 -56.185379 -57.388470 -57.412113  ... -31.968554 -30.679962   \n",
       "639 -55.711002 -55.711002 -55.711002 -55.711002  ... -38.372776 -39.288120   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "585 -24.709219 -27.589947 -26.442131 -26.327812 -25.804108 -19.461014   \n",
       "3   -38.818481 -39.010696 -41.907330 -42.493778 -43.464279 -36.841316   \n",
       "745 -39.899551 -38.985703 -39.612740 -41.767555 -42.121475 -23.383146   \n",
       "636 -46.734238 -45.012756 -42.766567 -43.993099 -45.036140 -22.641428   \n",
       "733 -32.823845 -34.002800 -35.127888 -35.148537 -36.351570 -22.161703   \n",
       "136 -27.134611 -28.124929 -28.885090 -28.086546 -28.274565 -24.938246   \n",
       "371 -45.820110 -45.183754 -45.501438 -43.343258 -43.069851 -42.566338   \n",
       "49  -37.050064 -38.493828 -38.409847 -40.297588 -40.275467 -26.389078   \n",
       "234 -31.553383 -27.987570 -25.827244 -24.439589 -25.158400 -21.805180   \n",
       "639 -41.244530 -41.955376 -41.237968 -40.284386 -41.162289 -36.426846   \n",
       "\n",
       "           215             0    \n",
       "585 -14.189299      male_angry  \n",
       "3   -29.907366     female_calm  \n",
       "745 -16.090076  female_fearful  \n",
       "636 -13.785501    female_angry  \n",
       "733 -16.037973    female_angry  \n",
       "136 -20.766357       male_calm  \n",
       "371 -36.447304      female_sad  \n",
       "49  -18.184639     female_calm  \n",
       "234 -16.859730      male_happy  \n",
       "639 -29.188198    female_angry  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[250:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\Anaconda3\\envs\\may\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746, 216)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                34570     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 364,170\n",
      "Trainable params: 364,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removed the whole training part for avoiding unnecessary long epochs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 746 samples, validate on 174 samples\n",
      "Epoch 1/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 2.5260 - accuracy: 0.0871 - val_loss: 2.2926 - val_accuracy: 0.0747\n",
      "Epoch 2/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 2.2797 - accuracy: 0.1206 - val_loss: 2.2542 - val_accuracy: 0.0805\n",
      "Epoch 3/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 2.2250 - accuracy: 0.1233 - val_loss: 2.2156 - val_accuracy: 0.1954\n",
      "Epoch 4/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 2.1730 - accuracy: 0.1662 - val_loss: 2.1702 - val_accuracy: 0.1724\n",
      "Epoch 5/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 2.1340 - accuracy: 0.1810 - val_loss: 2.1469 - val_accuracy: 0.1149\n",
      "Epoch 6/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 2.1058 - accuracy: 0.1944 - val_loss: 2.0982 - val_accuracy: 0.2069\n",
      "Epoch 7/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 2.0695 - accuracy: 0.2212 - val_loss: 2.0755 - val_accuracy: 0.2241\n",
      "Epoch 8/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 2.0308 - accuracy: 0.2279 - val_loss: 2.0401 - val_accuracy: 0.2529\n",
      "Epoch 9/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.9998 - accuracy: 0.2694 - val_loss: 2.0239 - val_accuracy: 0.2471\n",
      "Epoch 10/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.9758 - accuracy: 0.2815 - val_loss: 2.0011 - val_accuracy: 0.2644\n",
      "Epoch 11/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.9479 - accuracy: 0.2802 - val_loss: 1.9512 - val_accuracy: 0.3218\n",
      "Epoch 12/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.9247 - accuracy: 0.2828 - val_loss: 1.9423 - val_accuracy: 0.2816\n",
      "Epoch 13/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.8921 - accuracy: 0.2855 - val_loss: 1.9136 - val_accuracy: 0.2586\n",
      "Epoch 14/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.8724 - accuracy: 0.3164 - val_loss: 1.8809 - val_accuracy: 0.3736\n",
      "Epoch 15/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.8502 - accuracy: 0.2989 - val_loss: 1.8633 - val_accuracy: 0.3563\n",
      "Epoch 16/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.8238 - accuracy: 0.3177 - val_loss: 1.8484 - val_accuracy: 0.3448\n",
      "Epoch 17/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.7941 - accuracy: 0.3137 - val_loss: 1.8428 - val_accuracy: 0.3851\n",
      "Epoch 18/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.7891 - accuracy: 0.3123 - val_loss: 1.8064 - val_accuracy: 0.3333\n",
      "Epoch 19/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.7580 - accuracy: 0.3606 - val_loss: 1.8116 - val_accuracy: 0.2816\n",
      "Epoch 20/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.7393 - accuracy: 0.3445 - val_loss: 1.7705 - val_accuracy: 0.3736\n",
      "Epoch 21/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.7198 - accuracy: 0.3458 - val_loss: 1.7674 - val_accuracy: 0.3218\n",
      "Epoch 22/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.7021 - accuracy: 0.3619 - val_loss: 1.7397 - val_accuracy: 0.3391\n",
      "Epoch 23/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.6833 - accuracy: 0.3646 - val_loss: 1.7251 - val_accuracy: 0.3103\n",
      "Epoch 24/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.6620 - accuracy: 0.3445 - val_loss: 1.7195 - val_accuracy: 0.3621\n",
      "Epoch 25/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.6510 - accuracy: 0.3673 - val_loss: 1.6730 - val_accuracy: 0.4195\n",
      "Epoch 26/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.6370 - accuracy: 0.3673 - val_loss: 1.6743 - val_accuracy: 0.33910s - loss: 1.6364 \n",
      "Epoch 27/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.6167 - accuracy: 0.3834 - val_loss: 1.6553 - val_accuracy: 0.3908\n",
      "Epoch 28/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.6084 - accuracy: 0.3606 - val_loss: 1.6561 - val_accuracy: 0.3218\n",
      "Epoch 29/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.5939 - accuracy: 0.3954 - val_loss: 1.6520 - val_accuracy: 0.3621\n",
      "Epoch 30/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.5802 - accuracy: 0.3767 - val_loss: 1.6452 - val_accuracy: 0.3448\n",
      "Epoch 31/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.5683 - accuracy: 0.3874 - val_loss: 1.6389 - val_accuracy: 0.3563\n",
      "Epoch 32/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.5502 - accuracy: 0.4102 - val_loss: 1.6053 - val_accuracy: 0.3851\n",
      "Epoch 33/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.5348 - accuracy: 0.4155 - val_loss: 1.6383 - val_accuracy: 0.3276\n",
      "Epoch 34/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.5264 - accuracy: 0.4223 - val_loss: 1.5903 - val_accuracy: 0.4253 l\n",
      "Epoch 35/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.5234 - accuracy: 0.4021 - val_loss: 1.5788 - val_accuracy: 0.3966\n",
      "Epoch 36/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.5028 - accuracy: 0.4142 - val_loss: 1.5889 - val_accuracy: 0.3678\n",
      "Epoch 37/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4982 - accuracy: 0.4142 - val_loss: 1.5565 - val_accuracy: 0.4138\n",
      "Epoch 38/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4819 - accuracy: 0.4209 - val_loss: 1.5912 - val_accuracy: 0.3793\n",
      "Epoch 39/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4772 - accuracy: 0.4357 - val_loss: 1.5695 - val_accuracy: 0.3908\n",
      "Epoch 40/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4653 - accuracy: 0.4209 - val_loss: 1.5927 - val_accuracy: 0.3218\n",
      "Epoch 41/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4575 - accuracy: 0.4249 - val_loss: 1.5205 - val_accuracy: 0.4310\n",
      "Epoch 42/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4391 - accuracy: 0.4383 - val_loss: 1.5875 - val_accuracy: 0.3793\n",
      "Epoch 43/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4371 - accuracy: 0.4182 - val_loss: 1.5117 - val_accuracy: 0.3966\n",
      "Epoch 44/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4325 - accuracy: 0.4464 - val_loss: 1.5266 - val_accuracy: 0.3908\n",
      "Epoch 45/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4174 - accuracy: 0.4410 - val_loss: 1.5380 - val_accuracy: 0.3506\n",
      "Epoch 46/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4149 - accuracy: 0.4598 - val_loss: 1.5122 - val_accuracy: 0.4138\n",
      "Epoch 47/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4073 - accuracy: 0.4343 - val_loss: 1.4790 - val_accuracy: 0.4195\n",
      "Epoch 48/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.4043 - accuracy: 0.4316 - val_loss: 1.4634 - val_accuracy: 0.4195\n",
      "Epoch 49/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3936 - accuracy: 0.4410 - val_loss: 1.5312 - val_accuracy: 0.3966\n",
      "Epoch 50/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3815 - accuracy: 0.4397 - val_loss: 1.4665 - val_accuracy: 0.4138\n",
      "Epoch 51/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3855 - accuracy: 0.4491 - val_loss: 1.4477 - val_accuracy: 0.4425\n",
      "Epoch 52/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3705 - accuracy: 0.4638 - val_loss: 1.4578 - val_accuracy: 0.4138\n",
      "Epoch 53/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3570 - accuracy: 0.4504 - val_loss: 1.4440 - val_accuracy: 0.4195\n",
      "Epoch 54/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3523 - accuracy: 0.4651 - val_loss: 1.4499 - val_accuracy: 0.4253\n",
      "Epoch 55/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3529 - accuracy: 0.4611 - val_loss: 1.4635 - val_accuracy: 0.4080\n",
      "Epoch 56/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3455 - accuracy: 0.4611 - val_loss: 1.4377 - val_accuracy: 0.4138\n",
      "Epoch 57/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3258 - accuracy: 0.4812 - val_loss: 1.4251 - val_accuracy: 0.3966\n",
      "Epoch 58/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3253 - accuracy: 0.4853 - val_loss: 1.4111 - val_accuracy: 0.4310\n",
      "Epoch 59/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3311 - accuracy: 0.4558 - val_loss: 1.3991 - val_accuracy: 0.4885\n",
      "Epoch 60/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3229 - accuracy: 0.4651 - val_loss: 1.4195 - val_accuracy: 0.4138\n",
      "Epoch 61/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3134 - accuracy: 0.4786 - val_loss: 1.4327 - val_accuracy: 0.4655\n",
      "Epoch 62/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3066 - accuracy: 0.4625 - val_loss: 1.4311 - val_accuracy: 0.4310\n",
      "Epoch 63/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.3006 - accuracy: 0.4625 - val_loss: 1.3882 - val_accuracy: 0.4713\n",
      "Epoch 64/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2910 - accuracy: 0.4625 - val_loss: 1.4024 - val_accuracy: 0.4655\n",
      "Epoch 65/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2936 - accuracy: 0.4866 - val_loss: 1.3816 - val_accuracy: 0.4540\n",
      "Epoch 66/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2907 - accuracy: 0.4759 - val_loss: 1.4140 - val_accuracy: 0.4023\n",
      "Epoch 67/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2815 - accuracy: 0.4665 - val_loss: 1.3679 - val_accuracy: 0.4598\n",
      "Epoch 68/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2767 - accuracy: 0.4826 - val_loss: 1.3827 - val_accuracy: 0.4425\n",
      "Epoch 69/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2761 - accuracy: 0.4893 - val_loss: 1.3712 - val_accuracy: 0.4368\n",
      "Epoch 70/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2691 - accuracy: 0.4879 - val_loss: 1.3774 - val_accuracy: 0.4483\n",
      "Epoch 71/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2644 - accuracy: 0.5013 - val_loss: 1.3698 - val_accuracy: 0.4540\n",
      "Epoch 72/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2508 - accuracy: 0.4933 - val_loss: 1.4072 - val_accuracy: 0.4253\n",
      "Epoch 73/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2438 - accuracy: 0.4826 - val_loss: 1.3643 - val_accuracy: 0.4770\n",
      "Epoch 74/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2496 - accuracy: 0.5040 - val_loss: 1.4013 - val_accuracy: 0.4253\n",
      "Epoch 75/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2432 - accuracy: 0.5027 - val_loss: 1.3737 - val_accuracy: 0.4310\n",
      "Epoch 76/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2414 - accuracy: 0.5094 - val_loss: 1.3728 - val_accuracy: 0.4023\n",
      "Epoch 77/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2343 - accuracy: 0.4920 - val_loss: 1.3556 - val_accuracy: 0.4483\n",
      "Epoch 78/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2369 - accuracy: 0.5107 - val_loss: 1.3357 - val_accuracy: 0.4483\n",
      "Epoch 79/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2239 - accuracy: 0.5201 - val_loss: 1.3396 - val_accuracy: 0.4540\n",
      "Epoch 80/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2216 - accuracy: 0.5000 - val_loss: 1.3365 - val_accuracy: 0.4885\n",
      "Epoch 81/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2155 - accuracy: 0.5094 - val_loss: 1.3280 - val_accuracy: 0.4540\n",
      "Epoch 82/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1994 - accuracy: 0.5456 - val_loss: 1.4289 - val_accuracy: 0.4023\n",
      "Epoch 83/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2074 - accuracy: 0.5027 - val_loss: 1.3173 - val_accuracy: 0.4943\n",
      "Epoch 84/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2071 - accuracy: 0.5174 - val_loss: 1.3614 - val_accuracy: 0.4425\n",
      "Epoch 85/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2026 - accuracy: 0.5255 - val_loss: 1.3536 - val_accuracy: 0.4483\n",
      "Epoch 86/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.2041 - accuracy: 0.5027 - val_loss: 1.3452 - val_accuracy: 0.4483\n",
      "Epoch 87/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1924 - accuracy: 0.5121 - val_loss: 1.3496 - val_accuracy: 0.4655\n",
      "Epoch 88/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1823 - accuracy: 0.5241 - val_loss: 1.3786 - val_accuracy: 0.4138\n",
      "Epoch 89/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1913 - accuracy: 0.5322 - val_loss: 1.3137 - val_accuracy: 0.4655\n",
      "Epoch 90/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1851 - accuracy: 0.5322 - val_loss: 1.3212 - val_accuracy: 0.4540\n",
      "Epoch 91/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1879 - accuracy: 0.5188 - val_loss: 1.3209 - val_accuracy: 0.4598\n",
      "Epoch 92/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.1709 - accuracy: 0.5362 - val_loss: 1.3082 - val_accuracy: 0.4253\n",
      "Epoch 93/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1734 - accuracy: 0.5416 - val_loss: 1.3510 - val_accuracy: 0.4253\n",
      "Epoch 94/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1689 - accuracy: 0.5295 - val_loss: 1.3339 - val_accuracy: 0.4655\n",
      "Epoch 95/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1809 - accuracy: 0.5241 - val_loss: 1.3020 - val_accuracy: 0.4713\n",
      "Epoch 96/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.1696 - accuracy: 0.5174 - val_loss: 1.3062 - val_accuracy: 0.4655\n",
      "Epoch 97/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1517 - accuracy: 0.5282 - val_loss: 1.3515 - val_accuracy: 0.3908\n",
      "Epoch 98/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1570 - accuracy: 0.5282 - val_loss: 1.3539 - val_accuracy: 0.4483\n",
      "Epoch 99/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1614 - accuracy: 0.5335 - val_loss: 1.3006 - val_accuracy: 0.4598\n",
      "Epoch 100/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1620 - accuracy: 0.5442 - val_loss: 1.3305 - val_accuracy: 0.4023\n",
      "Epoch 101/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1527 - accuracy: 0.5469 - val_loss: 1.3130 - val_accuracy: 0.4483\n",
      "Epoch 102/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1569 - accuracy: 0.5308 - val_loss: 1.2937 - val_accuracy: 0.4828\n",
      "Epoch 103/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1352 - accuracy: 0.5429 - val_loss: 1.3289 - val_accuracy: 0.4598\n",
      "Epoch 104/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1519 - accuracy: 0.5362 - val_loss: 1.2735 - val_accuracy: 0.4770\n",
      "Epoch 105/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1438 - accuracy: 0.5402 - val_loss: 1.3158 - val_accuracy: 0.4310\n",
      "Epoch 106/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1273 - accuracy: 0.5496 - val_loss: 1.3063 - val_accuracy: 0.4540\n",
      "Epoch 107/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1352 - accuracy: 0.5416 - val_loss: 1.2884 - val_accuracy: 0.4253\n",
      "Epoch 108/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1216 - accuracy: 0.5536 - val_loss: 1.3125 - val_accuracy: 0.4598\n",
      "Epoch 109/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1326 - accuracy: 0.5429 - val_loss: 1.2649 - val_accuracy: 0.4655\n",
      "Epoch 110/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1254 - accuracy: 0.5523 - val_loss: 1.2787 - val_accuracy: 0.4770\n",
      "Epoch 111/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1229 - accuracy: 0.5523 - val_loss: 1.2795 - val_accuracy: 0.4655\n",
      "Epoch 112/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1181 - accuracy: 0.5576 - val_loss: 1.2615 - val_accuracy: 0.4828\n",
      "Epoch 113/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1180 - accuracy: 0.5617 - val_loss: 1.2741 - val_accuracy: 0.4770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.1240 - accuracy: 0.5496 - val_loss: 1.2756 - val_accuracy: 0.4483\n",
      "Epoch 115/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1169 - accuracy: 0.5670 - val_loss: 1.2524 - val_accuracy: 0.5057\n",
      "Epoch 116/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1028 - accuracy: 0.5509 - val_loss: 1.2745 - val_accuracy: 0.5000\n",
      "Epoch 117/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.1000 - accuracy: 0.5764 - val_loss: 1.2856 - val_accuracy: 0.4713\n",
      "Epoch 118/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.1078 - accuracy: 0.5483 - val_loss: 1.2772 - val_accuracy: 0.4828\n",
      "Epoch 119/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.1021 - accuracy: 0.5509 - val_loss: 1.3066 - val_accuracy: 0.4425\n",
      "Epoch 120/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.1102 - accuracy: 0.5456 - val_loss: 1.2983 - val_accuracy: 0.4368\n",
      "Epoch 121/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.1033 - accuracy: 0.5630 - val_loss: 1.2781 - val_accuracy: 0.4540\n",
      "Epoch 122/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0998 - accuracy: 0.5483 - val_loss: 1.2818 - val_accuracy: 0.4713\n",
      "Epoch 123/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0906 - accuracy: 0.5617 - val_loss: 1.2578 - val_accuracy: 0.4655\n",
      "Epoch 124/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0997 - accuracy: 0.5456 - val_loss: 1.2661 - val_accuracy: 0.4828\n",
      "Epoch 125/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0918 - accuracy: 0.5670 - val_loss: 1.2928 - val_accuracy: 0.4598\n",
      "Epoch 126/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0780 - accuracy: 0.5710 - val_loss: 1.2583 - val_accuracy: 0.4770\n",
      "Epoch 127/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0870 - accuracy: 0.5536 - val_loss: 1.2681 - val_accuracy: 0.4598\n",
      "Epoch 128/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0790 - accuracy: 0.5724 - val_loss: 1.2622 - val_accuracy: 0.4713\n",
      "Epoch 129/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0875 - accuracy: 0.5710 - val_loss: 1.2869 - val_accuracy: 0.4598\n",
      "Epoch 130/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0693 - accuracy: 0.5845 - val_loss: 1.2515 - val_accuracy: 0.4770\n",
      "Epoch 131/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.0768 - accuracy: 0.5777 - val_loss: 1.2762 - val_accuracy: 0.5057\n",
      "Epoch 132/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.0721 - accuracy: 0.5590 - val_loss: 1.2618 - val_accuracy: 0.4828\n",
      "Epoch 133/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0695 - accuracy: 0.5777 - val_loss: 1.2439 - val_accuracy: 0.5115\n",
      "Epoch 134/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0615 - accuracy: 0.5764 - val_loss: 1.2446 - val_accuracy: 0.4828\n",
      "Epoch 135/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.0641 - accuracy: 0.5791 - val_loss: 1.2885 - val_accuracy: 0.4540\n",
      "Epoch 136/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.0696 - accuracy: 0.5804 - val_loss: 1.2280 - val_accuracy: 0.4713\n",
      "Epoch 137/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0654 - accuracy: 0.5643 - val_loss: 1.2895 - val_accuracy: 0.4253\n",
      "Epoch 138/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.0625 - accuracy: 0.5737 - val_loss: 1.2538 - val_accuracy: 0.4828\n",
      "Epoch 139/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.0622 - accuracy: 0.5845 - val_loss: 1.2400 - val_accuracy: 0.5115\n",
      "Epoch 140/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0487 - accuracy: 0.5952 - val_loss: 1.2212 - val_accuracy: 0.4770\n",
      "Epoch 141/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0582 - accuracy: 0.5925 - val_loss: 1.2500 - val_accuracy: 0.4770\n",
      "Epoch 142/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0533 - accuracy: 0.5831 - val_loss: 1.2400 - val_accuracy: 0.4943\n",
      "Epoch 143/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0517 - accuracy: 0.5938 - val_loss: 1.2934 - val_accuracy: 0.4598\n",
      "Epoch 144/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0444 - accuracy: 0.5845 - val_loss: 1.2390 - val_accuracy: 0.4943\n",
      "Epoch 145/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0460 - accuracy: 0.5818 - val_loss: 1.2493 - val_accuracy: 0.4885\n",
      "Epoch 146/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0474 - accuracy: 0.5831 - val_loss: 1.2410 - val_accuracy: 0.5000\n",
      "Epoch 147/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0332 - accuracy: 0.5898 - val_loss: 1.2817 - val_accuracy: 0.4310\n",
      "Epoch 148/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0429 - accuracy: 0.5818 - val_loss: 1.2319 - val_accuracy: 0.4943\n",
      "Epoch 149/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0434 - accuracy: 0.5831 - val_loss: 1.2417 - val_accuracy: 0.4885\n",
      "Epoch 150/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0196 - accuracy: 0.6099 - val_loss: 1.3542 - val_accuracy: 0.4368\n",
      "Epoch 151/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0456 - accuracy: 0.5858 - val_loss: 1.2707 - val_accuracy: 0.4885\n",
      "Epoch 152/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0202 - accuracy: 0.6180 - val_loss: 1.2714 - val_accuracy: 0.5057\n",
      "Epoch 153/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0360 - accuracy: 0.6126 - val_loss: 1.2437 - val_accuracy: 0.5115\n",
      "Epoch 154/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0165 - accuracy: 0.6005 - val_loss: 1.2345 - val_accuracy: 0.4713\n",
      "Epoch 155/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0142 - accuracy: 0.6019 - val_loss: 1.2947 - val_accuracy: 0.4540\n",
      "Epoch 156/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0167 - accuracy: 0.6153 - val_loss: 1.2323 - val_accuracy: 0.4943\n",
      "Epoch 157/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0113 - accuracy: 0.5992 - val_loss: 1.2498 - val_accuracy: 0.4713\n",
      "Epoch 158/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0218 - accuracy: 0.5979 - val_loss: 1.2309 - val_accuracy: 0.5230\n",
      "Epoch 159/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0144 - accuracy: 0.6166 - val_loss: 1.2435 - val_accuracy: 0.4598\n",
      "Epoch 160/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0151 - accuracy: 0.5952 - val_loss: 1.2626 - val_accuracy: 0.4770\n",
      "Epoch 161/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0172 - accuracy: 0.5912 - val_loss: 1.2558 - val_accuracy: 0.4540\n",
      "Epoch 162/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.0120 - accuracy: 0.6032 - val_loss: 1.2433 - val_accuracy: 0.4713\n",
      "Epoch 163/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 0.9993 - accuracy: 0.6193 - val_loss: 1.2622 - val_accuracy: 0.5057\n",
      "Epoch 164/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 1.0089 - accuracy: 0.5871 - val_loss: 1.2694 - val_accuracy: 0.4943\n",
      "Epoch 165/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 0.9934 - accuracy: 0.6193 - val_loss: 1.2461 - val_accuracy: 0.4598\n",
      "Epoch 166/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 1.0098 - accuracy: 0.6032 - val_loss: 1.2263 - val_accuracy: 0.5057\n",
      "Epoch 167/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 1.0005 - accuracy: 0.6153 - val_loss: 1.2685 - val_accuracy: 0.4885\n",
      "Epoch 168/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 0.9921 - accuracy: 0.6166 - val_loss: 1.2619 - val_accuracy: 0.4483\n",
      "Epoch 169/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 0.9931 - accuracy: 0.5992 - val_loss: 1.2580 - val_accuracy: 0.4598\n",
      "Epoch 170/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 5ms/step - loss: 0.9963 - accuracy: 0.6153 - val_loss: 1.2378 - val_accuracy: 0.5057\n",
      "Epoch 171/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 0.9925 - accuracy: 0.6032 - val_loss: 1.2363 - val_accuracy: 0.5115\n",
      "Epoch 172/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9853 - accuracy: 0.5992 - val_loss: 1.2341 - val_accuracy: 0.4943\n",
      "Epoch 173/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 0.9893 - accuracy: 0.6247 - val_loss: 1.2283 - val_accuracy: 0.5000\n",
      "Epoch 174/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 0.9868 - accuracy: 0.5858 - val_loss: 1.2014 - val_accuracy: 0.4828\n",
      "Epoch 175/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 0.9730 - accuracy: 0.6153 - val_loss: 1.2474 - val_accuracy: 0.4770\n",
      "Epoch 176/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 0.9982 - accuracy: 0.6019 - val_loss: 1.2236 - val_accuracy: 0.5057\n",
      "Epoch 177/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9697 - accuracy: 0.6287 - val_loss: 1.2753 - val_accuracy: 0.4540\n",
      "Epoch 178/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9791 - accuracy: 0.5965 - val_loss: 1.2325 - val_accuracy: 0.4770\n",
      "Epoch 179/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 0.9787 - accuracy: 0.6206 - val_loss: 1.2307 - val_accuracy: 0.5000\n",
      "Epoch 180/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 0.9769 - accuracy: 0.6206 - val_loss: 1.2068 - val_accuracy: 0.5287\n",
      "Epoch 181/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9777 - accuracy: 0.6340 - val_loss: 1.2271 - val_accuracy: 0.5057\n",
      "Epoch 182/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 0.9740 - accuracy: 0.6220 - val_loss: 1.2535 - val_accuracy: 0.5230\n",
      "Epoch 183/700\n",
      "746/746 [==============================] - 4s 5ms/step - loss: 0.9669 - accuracy: 0.6247 - val_loss: 1.2502 - val_accuracy: 0.4943\n",
      "Epoch 184/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9718 - accuracy: 0.6287 - val_loss: 1.2372 - val_accuracy: 0.4655\n",
      "Epoch 185/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9628 - accuracy: 0.6287 - val_loss: 1.2115 - val_accuracy: 0.5057\n",
      "Epoch 186/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9698 - accuracy: 0.6233 - val_loss: 1.2321 - val_accuracy: 0.5115\n",
      "Epoch 187/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9752 - accuracy: 0.6314 - val_loss: 1.2233 - val_accuracy: 0.5115\n",
      "Epoch 188/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9740 - accuracy: 0.6019 - val_loss: 1.2281 - val_accuracy: 0.4885\n",
      "Epoch 189/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9760 - accuracy: 0.6099 - val_loss: 1.2185 - val_accuracy: 0.5172\n",
      "Epoch 190/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9689 - accuracy: 0.6247 - val_loss: 1.2402 - val_accuracy: 0.4540\n",
      "Epoch 191/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9611 - accuracy: 0.6206 - val_loss: 1.1992 - val_accuracy: 0.4770\n",
      "Epoch 192/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9653 - accuracy: 0.6153 - val_loss: 1.2245 - val_accuracy: 0.4943\n",
      "Epoch 193/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9555 - accuracy: 0.6193 - val_loss: 1.2422 - val_accuracy: 0.4885\n",
      "Epoch 194/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9570 - accuracy: 0.6273 - val_loss: 1.2287 - val_accuracy: 0.5000\n",
      "Epoch 195/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9510 - accuracy: 0.6300 - val_loss: 1.3527 - val_accuracy: 0.4080\n",
      "Epoch 196/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9487 - accuracy: 0.6273 - val_loss: 1.2463 - val_accuracy: 0.5057\n",
      "Epoch 197/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9598 - accuracy: 0.6300 - val_loss: 1.1803 - val_accuracy: 0.5000\n",
      "Epoch 198/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9405 - accuracy: 0.6220 - val_loss: 1.2469 - val_accuracy: 0.5115\n",
      "Epoch 199/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9474 - accuracy: 0.6367 - val_loss: 1.2106 - val_accuracy: 0.5057\n",
      "Epoch 200/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9389 - accuracy: 0.6381 - val_loss: 1.2307 - val_accuracy: 0.4770\n",
      "Epoch 201/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9394 - accuracy: 0.6273 - val_loss: 1.2060 - val_accuracy: 0.4770\n",
      "Epoch 202/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9368 - accuracy: 0.6515 - val_loss: 1.2324 - val_accuracy: 0.4368- accura\n",
      "Epoch 203/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9377 - accuracy: 0.6381 - val_loss: 1.2016 - val_accuracy: 0.5000\n",
      "Epoch 204/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9274 - accuracy: 0.6461 - val_loss: 1.3090 - val_accuracy: 0.4368\n",
      "Epoch 205/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9323 - accuracy: 0.6327 - val_loss: 1.3127 - val_accuracy: 0.4425\n",
      "Epoch 206/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9391 - accuracy: 0.6381 - val_loss: 1.2562 - val_accuracy: 0.4943\n",
      "Epoch 207/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9306 - accuracy: 0.6582 - val_loss: 1.1929 - val_accuracy: 0.5000\n",
      "Epoch 208/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9328 - accuracy: 0.6233 - val_loss: 1.2768 - val_accuracy: 0.4483\n",
      "Epoch 209/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9354 - accuracy: 0.6394 - val_loss: 1.2139 - val_accuracy: 0.4885\n",
      "Epoch 210/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9311 - accuracy: 0.6394 - val_loss: 1.2128 - val_accuracy: 0.5172\n",
      "Epoch 211/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9341 - accuracy: 0.6448 - val_loss: 1.2068 - val_accuracy: 0.5057\n",
      "Epoch 212/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9189 - accuracy: 0.6448 - val_loss: 1.2263 - val_accuracy: 0.4655\n",
      "Epoch 213/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9210 - accuracy: 0.6421 - val_loss: 1.2016 - val_accuracy: 0.5115\n",
      "Epoch 214/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9191 - accuracy: 0.6515 - val_loss: 1.2027 - val_accuracy: 0.5460\n",
      "Epoch 215/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9141 - accuracy: 0.6515 - val_loss: 1.2337 - val_accuracy: 0.4828\n",
      "Epoch 216/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9247 - accuracy: 0.6515 - val_loss: 1.2025 - val_accuracy: 0.5287\n",
      "Epoch 217/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9185 - accuracy: 0.6381 - val_loss: 1.2051 - val_accuracy: 0.4540\n",
      "Epoch 218/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9177 - accuracy: 0.6381 - val_loss: 1.1889 - val_accuracy: 0.5287\n",
      "Epoch 219/700\n",
      "746/746 [==============================] - 3s 3ms/step - loss: 0.9136 - accuracy: 0.6461 - val_loss: 1.2233 - val_accuracy: 0.4885\n",
      "Epoch 220/700\n",
      "746/746 [==============================] - 615s 824ms/step - loss: 0.9022 - accuracy: 0.6354 - val_loss: 1.2491 - val_accuracy: 0.5115\n",
      "Epoch 221/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.9049 - accuracy: 0.6448 - val_loss: 1.1910 - val_accuracy: 0.5460\n",
      "Epoch 222/700\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 0.9124 - accuracy: 0.6408 - val_loss: 1.2111 - val_accuracy: 0.5057\n",
      "Epoch 223/700\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 0.9013 - accuracy: 0.6622 - val_loss: 1.1960 - val_accuracy: 0.4713\n",
      "Epoch 224/700\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 0.9207 - accuracy: 0.6327 - val_loss: 1.1957 - val_accuracy: 0.5172\n",
      "Epoch 225/700\n",
      "746/746 [==============================] - 2s 3ms/step - loss: 0.8981 - accuracy: 0.6769 - val_loss: 1.2663 - val_accuracy: 0.4713\n",
      "Epoch 226/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8966 - accuracy: 0.6515 - val_loss: 1.2468 - val_accuracy: 0.4943\n",
      "Epoch 227/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8981 - accuracy: 0.6408 - val_loss: 1.2827 - val_accuracy: 0.4655\n",
      "Epoch 228/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 0.9053 - accuracy: 0.6542 - val_loss: 1.2487 - val_accuracy: 0.4943\n",
      "Epoch 229/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8987 - accuracy: 0.6542 - val_loss: 1.2438 - val_accuracy: 0.4425\n",
      "Epoch 230/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8991 - accuracy: 0.6622 - val_loss: 1.2259 - val_accuracy: 0.4828\n",
      "Epoch 231/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8912 - accuracy: 0.6729 - val_loss: 1.2280 - val_accuracy: 0.5057\n",
      "Epoch 232/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8830 - accuracy: 0.6555 - val_loss: 1.1862 - val_accuracy: 0.5345\n",
      "Epoch 233/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8983 - accuracy: 0.6528 - val_loss: 1.2042 - val_accuracy: 0.4828\n",
      "Epoch 234/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8840 - accuracy: 0.6622 - val_loss: 1.2660 - val_accuracy: 0.4943\n",
      "Epoch 235/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8871 - accuracy: 0.6662 - val_loss: 1.2145 - val_accuracy: 0.5057\n",
      "Epoch 236/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8943 - accuracy: 0.6568 - val_loss: 1.1895 - val_accuracy: 0.5172\n",
      "Epoch 237/700\n",
      "746/746 [==============================] - 3s 5ms/step - loss: 0.8668 - accuracy: 0.6582 - val_loss: 1.2326 - val_accuracy: 0.4943\n",
      "Epoch 238/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8945 - accuracy: 0.6676 - val_loss: 1.2412 - val_accuracy: 0.4770\n",
      "Epoch 239/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8863 - accuracy: 0.6528 - val_loss: 1.2150 - val_accuracy: 0.5402\n",
      "Epoch 240/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8819 - accuracy: 0.6609 - val_loss: 1.1906 - val_accuracy: 0.5287\n",
      "Epoch 241/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8763 - accuracy: 0.6716 - val_loss: 1.2361 - val_accuracy: 0.5000\n",
      "Epoch 242/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8741 - accuracy: 0.6609 - val_loss: 1.1970 - val_accuracy: 0.4713\n",
      "Epoch 243/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8782 - accuracy: 0.6555 - val_loss: 1.2418 - val_accuracy: 0.4943\n",
      "Epoch 244/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8784 - accuracy: 0.6649 - val_loss: 1.2363 - val_accuracy: 0.5057\n",
      "Epoch 245/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8689 - accuracy: 0.6568 - val_loss: 1.2828 - val_accuracy: 0.4425\n",
      "Epoch 246/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8716 - accuracy: 0.6622 - val_loss: 1.2443 - val_accuracy: 0.4828\n",
      "Epoch 247/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8702 - accuracy: 0.6676 - val_loss: 1.1925 - val_accuracy: 0.5287\n",
      "Epoch 248/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8775 - accuracy: 0.6635 - val_loss: 1.1715 - val_accuracy: 0.5230\n",
      "Epoch 249/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8645 - accuracy: 0.6716 - val_loss: 1.2048 - val_accuracy: 0.5460\n",
      "Epoch 250/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8696 - accuracy: 0.6676 - val_loss: 1.2094 - val_accuracy: 0.5115\n",
      "Epoch 251/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8577 - accuracy: 0.6622 - val_loss: 1.2976 - val_accuracy: 0.4655\n",
      "Epoch 252/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8551 - accuracy: 0.6609 - val_loss: 1.2024 - val_accuracy: 0.5057\n",
      "Epoch 253/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8629 - accuracy: 0.6676 - val_loss: 1.1946 - val_accuracy: 0.5000\n",
      "Epoch 254/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8627 - accuracy: 0.6810 - val_loss: 1.2242 - val_accuracy: 0.5057\n",
      "Epoch 255/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8568 - accuracy: 0.6796 - val_loss: 1.2072 - val_accuracy: 0.5345\n",
      "Epoch 256/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8573 - accuracy: 0.6622 - val_loss: 1.2258 - val_accuracy: 0.5460\n",
      "Epoch 257/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8515 - accuracy: 0.6917 - val_loss: 1.2196 - val_accuracy: 0.5115\n",
      "Epoch 258/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8569 - accuracy: 0.6635 - val_loss: 1.1813 - val_accuracy: 0.5000\n",
      "Epoch 259/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8450 - accuracy: 0.6890 - val_loss: 1.2198 - val_accuracy: 0.4713\n",
      "Epoch 260/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8568 - accuracy: 0.6515 - val_loss: 1.1773 - val_accuracy: 0.5172\n",
      "Epoch 261/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8409 - accuracy: 0.6702 - val_loss: 1.2298 - val_accuracy: 0.4828\n",
      "Epoch 262/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8494 - accuracy: 0.6823 - val_loss: 1.1810 - val_accuracy: 0.5000\n",
      "Epoch 263/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8362 - accuracy: 0.6743 - val_loss: 1.2070 - val_accuracy: 0.5115\n",
      "Epoch 264/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8358 - accuracy: 0.6756 - val_loss: 1.2027 - val_accuracy: 0.5000\n",
      "Epoch 265/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8330 - accuracy: 0.6890 - val_loss: 1.2620 - val_accuracy: 0.4655\n",
      "Epoch 266/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8325 - accuracy: 0.6769 - val_loss: 1.1963 - val_accuracy: 0.5115\n",
      "Epoch 267/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8338 - accuracy: 0.6783 - val_loss: 1.1858 - val_accuracy: 0.5172\n",
      "Epoch 268/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8178 - accuracy: 0.6877 - val_loss: 1.2314 - val_accuracy: 0.4885\n",
      "Epoch 269/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8468 - accuracy: 0.6823 - val_loss: 1.2841 - val_accuracy: 0.4943\n",
      "Epoch 270/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8318 - accuracy: 0.6716 - val_loss: 1.1821 - val_accuracy: 0.5287\n",
      "Epoch 271/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8356 - accuracy: 0.6756 - val_loss: 1.2035 - val_accuracy: 0.5172\n",
      "Epoch 272/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8238 - accuracy: 0.6890 - val_loss: 1.2306 - val_accuracy: 0.5230\n",
      "Epoch 273/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8370 - accuracy: 0.6729 - val_loss: 1.1912 - val_accuracy: 0.5230\n",
      "Epoch 274/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8334 - accuracy: 0.6810 - val_loss: 1.2622 - val_accuracy: 0.5000\n",
      "Epoch 275/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8360 - accuracy: 0.6984 - val_loss: 1.1807 - val_accuracy: 0.5057\n",
      "Epoch 276/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8392 - accuracy: 0.6944 - val_loss: 1.2169 - val_accuracy: 0.5345\n",
      "Epoch 277/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8159 - accuracy: 0.6756 - val_loss: 1.2144 - val_accuracy: 0.5057\n",
      "Epoch 278/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8301 - accuracy: 0.6850 - val_loss: 1.1871 - val_accuracy: 0.5115\n",
      "Epoch 279/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8166 - accuracy: 0.6903 - val_loss: 1.2472 - val_accuracy: 0.5172\n",
      "Epoch 280/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8277 - accuracy: 0.7011 - val_loss: 1.2141 - val_accuracy: 0.5230\n",
      "Epoch 281/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8124 - accuracy: 0.6984 - val_loss: 1.1894 - val_accuracy: 0.5230\n",
      "Epoch 282/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8154 - accuracy: 0.6836 - val_loss: 1.2121 - val_accuracy: 0.5115\n",
      "Epoch 283/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8281 - accuracy: 0.6903 - val_loss: 1.1768 - val_accuracy: 0.5000\n",
      "Epoch 284/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8134 - accuracy: 0.6930 - val_loss: 1.2577 - val_accuracy: 0.4483\n",
      "Epoch 285/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8150 - accuracy: 0.6836 - val_loss: 1.2059 - val_accuracy: 0.4943\n",
      "Epoch 286/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8048 - accuracy: 0.6957 - val_loss: 1.2176 - val_accuracy: 0.5000\n",
      "Epoch 287/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8161 - accuracy: 0.6971 - val_loss: 1.2252 - val_accuracy: 0.5230\n",
      "Epoch 288/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8074 - accuracy: 0.6957 - val_loss: 1.2310 - val_accuracy: 0.4713\n",
      "Epoch 289/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8133 - accuracy: 0.7011 - val_loss: 1.2360 - val_accuracy: 0.5287\n",
      "Epoch 290/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7997 - accuracy: 0.7078 - val_loss: 1.1801 - val_accuracy: 0.5115\n",
      "Epoch 291/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8091 - accuracy: 0.7051 - val_loss: 1.2148 - val_accuracy: 0.5115\n",
      "Epoch 292/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7983 - accuracy: 0.6957 - val_loss: 1.2051 - val_accuracy: 0.5230\n",
      "Epoch 293/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7999 - accuracy: 0.7011 - val_loss: 1.2072 - val_accuracy: 0.5172\n",
      "Epoch 294/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.8111 - accuracy: 0.6890 - val_loss: 1.2092 - val_accuracy: 0.5115\n",
      "Epoch 295/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7937 - accuracy: 0.7038 - val_loss: 1.1991 - val_accuracy: 0.4885\n",
      "Epoch 296/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7937 - accuracy: 0.6836 - val_loss: 1.2201 - val_accuracy: 0.5287\n",
      "Epoch 297/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7946 - accuracy: 0.7239 - val_loss: 1.1926 - val_accuracy: 0.5287\n",
      "Epoch 298/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7966 - accuracy: 0.6917 - val_loss: 1.2038 - val_accuracy: 0.5115\n",
      "Epoch 299/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7928 - accuracy: 0.7105 - val_loss: 1.2095 - val_accuracy: 0.5287\n",
      "Epoch 300/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7782 - accuracy: 0.6971 - val_loss: 1.2435 - val_accuracy: 0.5345\n",
      "Epoch 301/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7865 - accuracy: 0.7091 - val_loss: 1.1887 - val_accuracy: 0.5287\n",
      "Epoch 302/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7780 - accuracy: 0.7105 - val_loss: 1.2788 - val_accuracy: 0.4770\n",
      "Epoch 303/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7964 - accuracy: 0.6917 - val_loss: 1.1872 - val_accuracy: 0.5402\n",
      "Epoch 304/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7899 - accuracy: 0.7038 - val_loss: 1.1732 - val_accuracy: 0.5115\n",
      "Epoch 305/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7816 - accuracy: 0.6944 - val_loss: 1.2016 - val_accuracy: 0.5172\n",
      "Epoch 306/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7750 - accuracy: 0.7158 - val_loss: 1.2231 - val_accuracy: 0.4885\n",
      "Epoch 307/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7864 - accuracy: 0.6984 - val_loss: 1.2256 - val_accuracy: 0.4828\n",
      "Epoch 308/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7844 - accuracy: 0.6877 - val_loss: 1.2260 - val_accuracy: 0.4828\n",
      "Epoch 309/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7767 - accuracy: 0.7105 - val_loss: 1.1914 - val_accuracy: 0.5287\n",
      "Epoch 310/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7791 - accuracy: 0.6957 - val_loss: 1.2054 - val_accuracy: 0.5057\n",
      "Epoch 311/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7820 - accuracy: 0.7024 - val_loss: 1.2034 - val_accuracy: 0.4943\n",
      "Epoch 312/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7754 - accuracy: 0.7011 - val_loss: 1.1803 - val_accuracy: 0.5517\n",
      "Epoch 313/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7724 - accuracy: 0.7078 - val_loss: 1.2095 - val_accuracy: 0.4943\n",
      "Epoch 314/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7806 - accuracy: 0.6877 - val_loss: 1.1814 - val_accuracy: 0.5115\n",
      "Epoch 315/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7771 - accuracy: 0.6997 - val_loss: 1.2120 - val_accuracy: 0.4770\n",
      "Epoch 316/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7725 - accuracy: 0.7078 - val_loss: 1.2418 - val_accuracy: 0.4943\n",
      "Epoch 317/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7714 - accuracy: 0.6971 - val_loss: 1.2137 - val_accuracy: 0.5115\n",
      "Epoch 318/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7637 - accuracy: 0.7279 - val_loss: 1.2357 - val_accuracy: 0.5345\n",
      "Epoch 319/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7654 - accuracy: 0.6997 - val_loss: 1.2107 - val_accuracy: 0.4713\n",
      "Epoch 320/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7723 - accuracy: 0.6971 - val_loss: 1.1855 - val_accuracy: 0.4655\n",
      "Epoch 321/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7598 - accuracy: 0.7158 - val_loss: 1.1692 - val_accuracy: 0.5287\n",
      "Epoch 322/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7641 - accuracy: 0.7185 - val_loss: 1.1821 - val_accuracy: 0.5230\n",
      "Epoch 323/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7526 - accuracy: 0.7292 - val_loss: 1.2296 - val_accuracy: 0.5230\n",
      "Epoch 324/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7621 - accuracy: 0.7051 - val_loss: 1.2436 - val_accuracy: 0.5115\n",
      "Epoch 325/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7528 - accuracy: 0.7252 - val_loss: 1.2275 - val_accuracy: 0.5057\n",
      "Epoch 326/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7466 - accuracy: 0.7145 - val_loss: 1.2174 - val_accuracy: 0.4943\n",
      "Epoch 327/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7544 - accuracy: 0.7212 - val_loss: 1.2064 - val_accuracy: 0.5115\n",
      "Epoch 328/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7470 - accuracy: 0.7131 - val_loss: 1.2357 - val_accuracy: 0.4713\n",
      "Epoch 329/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7572 - accuracy: 0.7212 - val_loss: 1.2051 - val_accuracy: 0.4943\n",
      "Epoch 330/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7417 - accuracy: 0.7319 - val_loss: 1.2288 - val_accuracy: 0.5115\n",
      "Epoch 331/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7458 - accuracy: 0.7064 - val_loss: 1.2381 - val_accuracy: 0.4713\n",
      "Epoch 332/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7512 - accuracy: 0.7319 - val_loss: 1.2022 - val_accuracy: 0.5172\n",
      "Epoch 333/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7433 - accuracy: 0.7292 - val_loss: 1.1718 - val_accuracy: 0.5230\n",
      "Epoch 334/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7366 - accuracy: 0.7359 - val_loss: 1.2029 - val_accuracy: 0.5345\n",
      "Epoch 335/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7408 - accuracy: 0.7399 - val_loss: 1.2484 - val_accuracy: 0.4943\n",
      "Epoch 336/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7367 - accuracy: 0.7172 - val_loss: 1.2834 - val_accuracy: 0.4828\n",
      "Epoch 337/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7446 - accuracy: 0.7279 - val_loss: 1.2273 - val_accuracy: 0.4828\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7331 - accuracy: 0.7279 - val_loss: 1.1904 - val_accuracy: 0.5345\n",
      "Epoch 339/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7370 - accuracy: 0.7225 - val_loss: 1.2143 - val_accuracy: 0.5000\n",
      "Epoch 340/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7407 - accuracy: 0.7332 - val_loss: 1.1839 - val_accuracy: 0.5057\n",
      "Epoch 341/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7182 - accuracy: 0.7440 - val_loss: 1.2175 - val_accuracy: 0.4713\n",
      "Epoch 342/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7356 - accuracy: 0.7373 - val_loss: 1.2121 - val_accuracy: 0.5460s: 0.7371 - ac - ETA: 0s - loss: 0.7411 - accuracy: \n",
      "Epoch 343/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7319 - accuracy: 0.7359 - val_loss: 1.2208 - val_accuracy: 0.5575\n",
      "Epoch 344/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7249 - accuracy: 0.7493 - val_loss: 1.1994 - val_accuracy: 0.5000\n",
      "Epoch 345/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7317 - accuracy: 0.7239 - val_loss: 1.2037 - val_accuracy: 0.5057\n",
      "Epoch 346/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7258 - accuracy: 0.7319 - val_loss: 1.2953 - val_accuracy: 0.5115\n",
      "Epoch 347/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7230 - accuracy: 0.7306 - val_loss: 1.1809 - val_accuracy: 0.5287\n",
      "Epoch 348/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7234 - accuracy: 0.7265 - val_loss: 1.1927 - val_accuracy: 0.5230\n",
      "Epoch 349/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7243 - accuracy: 0.7373 - val_loss: 1.2203 - val_accuracy: 0.4885\n",
      "Epoch 350/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7367 - accuracy: 0.7292 - val_loss: 1.1896 - val_accuracy: 0.5000\n",
      "Epoch 351/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7113 - accuracy: 0.7466 - val_loss: 1.1842 - val_accuracy: 0.5057\n",
      "Epoch 352/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7109 - accuracy: 0.7466 - val_loss: 1.2144 - val_accuracy: 0.5057\n",
      "Epoch 353/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7196 - accuracy: 0.7319 - val_loss: 1.2572 - val_accuracy: 0.4943\n",
      "Epoch 354/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7094 - accuracy: 0.7453 - val_loss: 1.2040 - val_accuracy: 0.5115\n",
      "Epoch 355/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7084 - accuracy: 0.7252 - val_loss: 1.2692 - val_accuracy: 0.4943\n",
      "Epoch 356/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7143 - accuracy: 0.7493 - val_loss: 1.2186 - val_accuracy: 0.4885\n",
      "Epoch 357/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7054 - accuracy: 0.7346 - val_loss: 1.1972 - val_accuracy: 0.5057\n",
      "Epoch 358/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7114 - accuracy: 0.7346 - val_loss: 1.2312 - val_accuracy: 0.4655\n",
      "Epoch 359/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7045 - accuracy: 0.7426 - val_loss: 1.3682 - val_accuracy: 0.4885\n",
      "Epoch 360/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7114 - accuracy: 0.7319 - val_loss: 1.2186 - val_accuracy: 0.5115\n",
      "Epoch 361/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7043 - accuracy: 0.7346 - val_loss: 1.2099 - val_accuracy: 0.5287\n",
      "Epoch 362/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7121 - accuracy: 0.7453 - val_loss: 1.2249 - val_accuracy: 0.5172\n",
      "Epoch 363/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6898 - accuracy: 0.7386 - val_loss: 1.2434 - val_accuracy: 0.5057\n",
      "Epoch 364/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6989 - accuracy: 0.7252 - val_loss: 1.2040 - val_accuracy: 0.5575\n",
      "Epoch 365/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6991 - accuracy: 0.7426 - val_loss: 1.2300 - val_accuracy: 0.4885\n",
      "Epoch 366/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.7028 - accuracy: 0.7373 - val_loss: 1.3061 - val_accuracy: 0.4943\n",
      "Epoch 367/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6969 - accuracy: 0.7507 - val_loss: 1.3671 - val_accuracy: 0.4425\n",
      "Epoch 368/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6818 - accuracy: 0.7507 - val_loss: 1.2520 - val_accuracy: 0.5230\n",
      "Epoch 369/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6888 - accuracy: 0.7466 - val_loss: 1.2297 - val_accuracy: 0.5460\n",
      "Epoch 370/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6903 - accuracy: 0.7587 - val_loss: 1.2296 - val_accuracy: 0.4713\n",
      "Epoch 371/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6936 - accuracy: 0.7480 - val_loss: 1.2159 - val_accuracy: 0.5172\n",
      "Epoch 372/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6911 - accuracy: 0.7507 - val_loss: 1.2161 - val_accuracy: 0.5402\n",
      "Epoch 373/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6902 - accuracy: 0.7413 - val_loss: 1.1948 - val_accuracy: 0.5345\n",
      "Epoch 374/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6950 - accuracy: 0.7373 - val_loss: 1.2306 - val_accuracy: 0.5000\n",
      "Epoch 375/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6850 - accuracy: 0.7560 - val_loss: 1.2153 - val_accuracy: 0.5172\n",
      "Epoch 376/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6748 - accuracy: 0.7466 - val_loss: 1.1852 - val_accuracy: 0.5402\n",
      "Epoch 377/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6883 - accuracy: 0.7332 - val_loss: 1.2139 - val_accuracy: 0.5057\n",
      "Epoch 378/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6797 - accuracy: 0.7614 - val_loss: 1.2267 - val_accuracy: 0.5402\n",
      "Epoch 379/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6853 - accuracy: 0.7413 - val_loss: 1.1929 - val_accuracy: 0.5057\n",
      "Epoch 380/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6776 - accuracy: 0.7601 - val_loss: 1.2203 - val_accuracy: 0.5115\n",
      "Epoch 381/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6816 - accuracy: 0.7493 - val_loss: 1.2236 - val_accuracy: 0.5000\n",
      "Epoch 382/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6718 - accuracy: 0.7547 - val_loss: 1.1827 - val_accuracy: 0.5345\n",
      "Epoch 383/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6745 - accuracy: 0.7748 - val_loss: 1.2884 - val_accuracy: 0.4943\n",
      "Epoch 384/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6692 - accuracy: 0.7668 - val_loss: 1.2523 - val_accuracy: 0.5000\n",
      "Epoch 385/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6703 - accuracy: 0.7386 - val_loss: 1.2551 - val_accuracy: 0.4713\n",
      "Epoch 386/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6765 - accuracy: 0.7601 - val_loss: 1.2322 - val_accuracy: 0.5345\n",
      "Epoch 387/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6653 - accuracy: 0.7748 - val_loss: 1.1966 - val_accuracy: 0.5000\n",
      "Epoch 388/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6595 - accuracy: 0.7735 - val_loss: 1.2392 - val_accuracy: 0.4885\n",
      "Epoch 389/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6744 - accuracy: 0.7359 - val_loss: 1.1929 - val_accuracy: 0.4943\n",
      "Epoch 390/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6708 - accuracy: 0.7426 - val_loss: 1.2581 - val_accuracy: 0.4828\n",
      "Epoch 391/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6577 - accuracy: 0.7641 - val_loss: 1.2029 - val_accuracy: 0.5402\n",
      "Epoch 392/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6656 - accuracy: 0.7534 - val_loss: 1.2224 - val_accuracy: 0.4943\n",
      "Epoch 393/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6629 - accuracy: 0.7587 - val_loss: 1.2188 - val_accuracy: 0.4828\n",
      "Epoch 394/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6620 - accuracy: 0.7654 - val_loss: 1.2511 - val_accuracy: 0.5345\n",
      "Epoch 395/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6563 - accuracy: 0.7668 - val_loss: 1.1937 - val_accuracy: 0.5287\n",
      "Epoch 396/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6623 - accuracy: 0.7507 - val_loss: 1.1914 - val_accuracy: 0.5172\n",
      "Epoch 397/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6664 - accuracy: 0.7507 - val_loss: 1.1972 - val_accuracy: 0.5115\n",
      "Epoch 398/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6488 - accuracy: 0.7614 - val_loss: 1.1802 - val_accuracy: 0.5287\n",
      "Epoch 399/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6523 - accuracy: 0.7480 - val_loss: 1.2011 - val_accuracy: 0.5057\n",
      "Epoch 400/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6576 - accuracy: 0.7654 - val_loss: 1.2776 - val_accuracy: 0.4655\n",
      "Epoch 401/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6483 - accuracy: 0.7694 - val_loss: 1.2400 - val_accuracy: 0.5287\n",
      "Epoch 402/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6436 - accuracy: 0.7534 - val_loss: 1.2415 - val_accuracy: 0.4713\n",
      "Epoch 403/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6468 - accuracy: 0.7601 - val_loss: 1.2130 - val_accuracy: 0.4885\n",
      "Epoch 404/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6460 - accuracy: 0.7708 - val_loss: 1.2193 - val_accuracy: 0.4828\n",
      "Epoch 405/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6426 - accuracy: 0.7627 - val_loss: 1.2528 - val_accuracy: 0.4828\n",
      "Epoch 406/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6412 - accuracy: 0.7654 - val_loss: 1.2500 - val_accuracy: 0.4885\n",
      "Epoch 407/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6453 - accuracy: 0.7547 - val_loss: 1.2281 - val_accuracy: 0.4598\n",
      "Epoch 408/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6342 - accuracy: 0.7802 - val_loss: 1.2333 - val_accuracy: 0.4828\n",
      "Epoch 409/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6330 - accuracy: 0.7761 - val_loss: 1.1997 - val_accuracy: 0.5115\n",
      "Epoch 410/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6370 - accuracy: 0.7735 - val_loss: 1.2084 - val_accuracy: 0.5345\n",
      "Epoch 411/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6403 - accuracy: 0.7775 - val_loss: 1.2505 - val_accuracy: 0.4943\n",
      "Epoch 412/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6397 - accuracy: 0.7668 - val_loss: 1.1897 - val_accuracy: 0.4885\n",
      "Epoch 413/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6269 - accuracy: 0.7761 - val_loss: 1.2820 - val_accuracy: 0.5057\n",
      "Epoch 414/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6417 - accuracy: 0.7601 - val_loss: 1.2105 - val_accuracy: 0.5000\n",
      "Epoch 415/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6299 - accuracy: 0.7748 - val_loss: 1.2060 - val_accuracy: 0.5172\n",
      "Epoch 416/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6267 - accuracy: 0.7681 - val_loss: 1.2194 - val_accuracy: 0.5345\n",
      "Epoch 417/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6351 - accuracy: 0.7895 - val_loss: 1.2279 - val_accuracy: 0.5345\n",
      "Epoch 418/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6279 - accuracy: 0.7869 - val_loss: 1.2098 - val_accuracy: 0.5287\n",
      "Epoch 419/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6210 - accuracy: 0.7788 - val_loss: 1.2699 - val_accuracy: 0.5345\n",
      "Epoch 420/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6321 - accuracy: 0.7708 - val_loss: 1.2294 - val_accuracy: 0.5460\n",
      "Epoch 421/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6245 - accuracy: 0.7761 - val_loss: 1.2227 - val_accuracy: 0.5057\n",
      "Epoch 422/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6167 - accuracy: 0.7721 - val_loss: 1.1994 - val_accuracy: 0.5402\n",
      "Epoch 423/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6209 - accuracy: 0.7855 - val_loss: 1.2109 - val_accuracy: 0.5460\n",
      "Epoch 424/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6239 - accuracy: 0.7815 - val_loss: 1.2087 - val_accuracy: 0.5172\n",
      "Epoch 425/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6103 - accuracy: 0.7788 - val_loss: 1.2115 - val_accuracy: 0.5460\n",
      "Epoch 426/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6078 - accuracy: 0.7815 - val_loss: 1.2011 - val_accuracy: 0.4943\n",
      "Epoch 427/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6155 - accuracy: 0.7855 - val_loss: 1.2060 - val_accuracy: 0.5172\n",
      "Epoch 428/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6080 - accuracy: 0.7909 - val_loss: 1.2787 - val_accuracy: 0.5115\n",
      "Epoch 429/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6157 - accuracy: 0.7775 - val_loss: 1.2467 - val_accuracy: 0.5402\n",
      "Epoch 430/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6209 - accuracy: 0.7748 - val_loss: 1.2327 - val_accuracy: 0.4713\n",
      "Epoch 431/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6052 - accuracy: 0.7842 - val_loss: 1.2337 - val_accuracy: 0.5230\n",
      "Epoch 432/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5979 - accuracy: 0.7869 - val_loss: 1.2278 - val_accuracy: 0.5172\n",
      "Epoch 433/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5987 - accuracy: 0.7828 - val_loss: 1.2271 - val_accuracy: 0.5000\n",
      "Epoch 434/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5988 - accuracy: 0.7815 - val_loss: 1.2029 - val_accuracy: 0.5057\n",
      "Epoch 435/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6109 - accuracy: 0.7735 - val_loss: 1.2108 - val_accuracy: 0.5517\n",
      "Epoch 436/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5934 - accuracy: 0.7815 - val_loss: 1.3102 - val_accuracy: 0.4770\n",
      "Epoch 437/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.6158 - accuracy: 0.7761 - val_loss: 1.2352 - val_accuracy: 0.5115\n",
      "Epoch 438/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5972 - accuracy: 0.7882 - val_loss: 1.2175 - val_accuracy: 0.5172\n",
      "Epoch 439/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5998 - accuracy: 0.7895 - val_loss: 1.2254 - val_accuracy: 0.5172\n",
      "Epoch 440/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5923 - accuracy: 0.7882 - val_loss: 1.2245 - val_accuracy: 0.5172\n",
      "Epoch 441/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5905 - accuracy: 0.7802 - val_loss: 1.1907 - val_accuracy: 0.5345\n",
      "Epoch 442/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5915 - accuracy: 0.7922 - val_loss: 1.2479 - val_accuracy: 0.5057\n",
      "Epoch 443/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5922 - accuracy: 0.7976 - val_loss: 1.2043 - val_accuracy: 0.5287\n",
      "Epoch 444/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5823 - accuracy: 0.7842 - val_loss: 1.2014 - val_accuracy: 0.5230\n",
      "Epoch 445/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5833 - accuracy: 0.8043 - val_loss: 1.2655 - val_accuracy: 0.5172\n",
      "Epoch 446/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5977 - accuracy: 0.7775 - val_loss: 1.2112 - val_accuracy: 0.5287\n",
      "Epoch 447/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5788 - accuracy: 0.7989 - val_loss: 1.2539 - val_accuracy: 0.5057\n",
      "Epoch 448/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5937 - accuracy: 0.7909 - val_loss: 1.2059 - val_accuracy: 0.5057\n",
      "Epoch 449/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5829 - accuracy: 0.8029 - val_loss: 1.2187 - val_accuracy: 0.5460\n",
      "Epoch 450/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5812 - accuracy: 0.7989 - val_loss: 1.1999 - val_accuracy: 0.5345\n",
      "Epoch 451/700\n",
      "746/746 [==============================] - ETA: 0s - loss: 0.5859 - accuracy: 0.80 - 3s 4ms/step - loss: 0.5830 - accuracy: 0.8043 - val_loss: 1.2292 - val_accuracy: 0.5000\n",
      "Epoch 452/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5906 - accuracy: 0.7828 - val_loss: 1.2047 - val_accuracy: 0.5000\n",
      "Epoch 453/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5723 - accuracy: 0.8083 - val_loss: 1.3866 - val_accuracy: 0.4540\n",
      "Epoch 454/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5793 - accuracy: 0.7895 - val_loss: 1.2278 - val_accuracy: 0.5402\n",
      "Epoch 455/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5813 - accuracy: 0.7855 - val_loss: 1.2324 - val_accuracy: 0.5402\n",
      "Epoch 456/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5783 - accuracy: 0.8003 - val_loss: 1.2568 - val_accuracy: 0.5000\n",
      "Epoch 457/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5766 - accuracy: 0.7962 - val_loss: 1.2952 - val_accuracy: 0.5115\n",
      "Epoch 458/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5780 - accuracy: 0.7895 - val_loss: 1.3432 - val_accuracy: 0.4770\n",
      "Epoch 459/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5729 - accuracy: 0.7949 - val_loss: 1.2681 - val_accuracy: 0.4943\n",
      "Epoch 460/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5599 - accuracy: 0.8016 - val_loss: 1.3248 - val_accuracy: 0.4655\n",
      "Epoch 461/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5874 - accuracy: 0.7815 - val_loss: 1.2510 - val_accuracy: 0.4943\n",
      "Epoch 462/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5669 - accuracy: 0.8003 - val_loss: 1.2330 - val_accuracy: 0.4885\n",
      "Epoch 463/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5673 - accuracy: 0.8029 - val_loss: 1.2576 - val_accuracy: 0.4885\n",
      "Epoch 464/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5632 - accuracy: 0.8003 - val_loss: 1.1963 - val_accuracy: 0.5172\n",
      "Epoch 465/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5741 - accuracy: 0.7989 - val_loss: 1.2061 - val_accuracy: 0.5402\n",
      "Epoch 466/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5596 - accuracy: 0.8083 - val_loss: 1.3552 - val_accuracy: 0.4713\n",
      "Epoch 467/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5546 - accuracy: 0.8123 - val_loss: 1.2349 - val_accuracy: 0.5345\n",
      "Epoch 468/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5635 - accuracy: 0.8029 - val_loss: 1.1861 - val_accuracy: 0.5230\n",
      "Epoch 469/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5574 - accuracy: 0.8083 - val_loss: 1.2510 - val_accuracy: 0.5057\n",
      "Epoch 470/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5587 - accuracy: 0.8070 - val_loss: 1.2184 - val_accuracy: 0.5057\n",
      "Epoch 471/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5546 - accuracy: 0.8190 - val_loss: 1.2410 - val_accuracy: 0.5402\n",
      "Epoch 472/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5566 - accuracy: 0.8123 - val_loss: 1.2266 - val_accuracy: 0.5575\n",
      "Epoch 473/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5413 - accuracy: 0.8137 - val_loss: 1.2890 - val_accuracy: 0.5057\n",
      "Epoch 474/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5408 - accuracy: 0.8003 - val_loss: 1.2622 - val_accuracy: 0.4943\n",
      "Epoch 475/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5487 - accuracy: 0.8070 - val_loss: 1.3733 - val_accuracy: 0.4770\n",
      "Epoch 476/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5444 - accuracy: 0.8123 - val_loss: 1.2157 - val_accuracy: 0.5402\n",
      "Epoch 477/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5426 - accuracy: 0.8190 - val_loss: 1.2820 - val_accuracy: 0.5000\n",
      "Epoch 478/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5478 - accuracy: 0.8083 - val_loss: 1.2458 - val_accuracy: 0.5115\n",
      "Epoch 479/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5495 - accuracy: 0.8016 - val_loss: 1.2238 - val_accuracy: 0.5402\n",
      "Epoch 480/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5437 - accuracy: 0.8123 - val_loss: 1.2256 - val_accuracy: 0.5057\n",
      "Epoch 481/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5469 - accuracy: 0.8150 - val_loss: 1.2853 - val_accuracy: 0.5230\n",
      "Epoch 482/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5469 - accuracy: 0.8110 - val_loss: 1.2281 - val_accuracy: 0.5000\n",
      "Epoch 483/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5401 - accuracy: 0.8164 - val_loss: 1.2540 - val_accuracy: 0.5115\n",
      "Epoch 484/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5506 - accuracy: 0.8097 - val_loss: 1.2474 - val_accuracy: 0.5172\n",
      "Epoch 485/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5392 - accuracy: 0.8217 - val_loss: 1.2127 - val_accuracy: 0.5230\n",
      "Epoch 486/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5320 - accuracy: 0.8123 - val_loss: 1.2483 - val_accuracy: 0.5115\n",
      "Epoch 487/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5393 - accuracy: 0.8284 - val_loss: 1.2199 - val_accuracy: 0.5230\n",
      "Epoch 488/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5289 - accuracy: 0.8177 - val_loss: 1.2649 - val_accuracy: 0.5345\n",
      "Epoch 489/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5365 - accuracy: 0.8029 - val_loss: 1.2286 - val_accuracy: 0.5345\n",
      "Epoch 490/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5385 - accuracy: 0.8164 - val_loss: 1.2030 - val_accuracy: 0.4885\n",
      "Epoch 491/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5294 - accuracy: 0.8190 - val_loss: 1.2430 - val_accuracy: 0.5575\n",
      "Epoch 492/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5408 - accuracy: 0.8070 - val_loss: 1.2207 - val_accuracy: 0.5460\n",
      "Epoch 493/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5299 - accuracy: 0.8217 - val_loss: 1.2331 - val_accuracy: 0.5402\n",
      "Epoch 494/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5295 - accuracy: 0.8097 - val_loss: 1.2447 - val_accuracy: 0.5000\n",
      "Epoch 495/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5269 - accuracy: 0.8204 - val_loss: 1.2046 - val_accuracy: 0.5287\n",
      "Epoch 496/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5205 - accuracy: 0.8177 - val_loss: 1.2161 - val_accuracy: 0.5172\n",
      "Epoch 497/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5182 - accuracy: 0.8217 - val_loss: 1.2461 - val_accuracy: 0.5287\n",
      "Epoch 498/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5221 - accuracy: 0.8244 - val_loss: 1.2665 - val_accuracy: 0.5287\n",
      "Epoch 499/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5149 - accuracy: 0.8177 - val_loss: 1.2251 - val_accuracy: 0.5057\n",
      "Epoch 500/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5282 - accuracy: 0.8097 - val_loss: 1.2247 - val_accuracy: 0.5460\n",
      "Epoch 501/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5207 - accuracy: 0.8177 - val_loss: 1.2190 - val_accuracy: 0.5345\n",
      "Epoch 502/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5152 - accuracy: 0.8123 - val_loss: 1.2327 - val_accuracy: 0.5115\n",
      "Epoch 503/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5262 - accuracy: 0.8177 - val_loss: 1.2230 - val_accuracy: 0.5230\n",
      "Epoch 504/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5149 - accuracy: 0.8164 - val_loss: 1.2868 - val_accuracy: 0.4713\n",
      "Epoch 505/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5086 - accuracy: 0.8177 - val_loss: 1.2252 - val_accuracy: 0.5345\n",
      "Epoch 506/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5166 - accuracy: 0.8190 - val_loss: 1.2333 - val_accuracy: 0.5000\n",
      "Epoch 507/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5168 - accuracy: 0.8284 - val_loss: 1.2560 - val_accuracy: 0.5000\n",
      "Epoch 508/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5081 - accuracy: 0.8418 - val_loss: 1.3378 - val_accuracy: 0.4828\n",
      "Epoch 509/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5048 - accuracy: 0.8418 - val_loss: 1.2119 - val_accuracy: 0.5287\n",
      "Epoch 510/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5045 - accuracy: 0.8338 - val_loss: 1.2354 - val_accuracy: 0.5172\n",
      "Epoch 511/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5016 - accuracy: 0.8284 - val_loss: 1.2330 - val_accuracy: 0.5115\n",
      "Epoch 512/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5039 - accuracy: 0.8378 - val_loss: 1.2641 - val_accuracy: 0.5000\n",
      "Epoch 513/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5029 - accuracy: 0.8244 - val_loss: 1.2597 - val_accuracy: 0.5057\n",
      "Epoch 514/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4913 - accuracy: 0.8324 - val_loss: 1.2642 - val_accuracy: 0.5057\n",
      "Epoch 515/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.5025 - accuracy: 0.8284 - val_loss: 1.2022 - val_accuracy: 0.5287\n",
      "Epoch 516/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4888 - accuracy: 0.8445 - val_loss: 1.2712 - val_accuracy: 0.5057\n",
      "Epoch 517/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4977 - accuracy: 0.8231 - val_loss: 1.2291 - val_accuracy: 0.5402\n",
      "Epoch 518/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4871 - accuracy: 0.8351 - val_loss: 1.2441 - val_accuracy: 0.5057\n",
      "Epoch 519/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4969 - accuracy: 0.8365 - val_loss: 1.2841 - val_accuracy: 0.4943\n",
      "Epoch 520/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4913 - accuracy: 0.8284 - val_loss: 1.2149 - val_accuracy: 0.5230\n",
      "Epoch 521/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4945 - accuracy: 0.8231 - val_loss: 1.2306 - val_accuracy: 0.5345\n",
      "Epoch 522/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4892 - accuracy: 0.8338 - val_loss: 1.2833 - val_accuracy: 0.5172\n",
      "Epoch 523/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4975 - accuracy: 0.8231 - val_loss: 1.2341 - val_accuracy: 0.5172\n",
      "Epoch 524/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4869 - accuracy: 0.8351 - val_loss: 1.2844 - val_accuracy: 0.5000\n",
      "Epoch 525/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4940 - accuracy: 0.8298 - val_loss: 1.2485 - val_accuracy: 0.5287\n",
      "Epoch 526/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4931 - accuracy: 0.8351 - val_loss: 1.2382 - val_accuracy: 0.5172\n",
      "Epoch 527/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4939 - accuracy: 0.8351 - val_loss: 1.2567 - val_accuracy: 0.5115\n",
      "Epoch 528/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4838 - accuracy: 0.8458 - val_loss: 1.2258 - val_accuracy: 0.5172\n",
      "Epoch 529/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4826 - accuracy: 0.8458 - val_loss: 1.2568 - val_accuracy: 0.5230\n",
      "Epoch 530/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4698 - accuracy: 0.8525 - val_loss: 1.2339 - val_accuracy: 0.5230\n",
      "Epoch 531/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4760 - accuracy: 0.8378 - val_loss: 1.4400 - val_accuracy: 0.4713\n",
      "Epoch 532/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4774 - accuracy: 0.8445 - val_loss: 1.2775 - val_accuracy: 0.5115\n",
      "Epoch 533/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4753 - accuracy: 0.8351 - val_loss: 1.2511 - val_accuracy: 0.5115\n",
      "Epoch 534/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4794 - accuracy: 0.8405 - val_loss: 1.2558 - val_accuracy: 0.5287\n",
      "Epoch 535/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4669 - accuracy: 0.8418 - val_loss: 1.2330 - val_accuracy: 0.5115\n",
      "Epoch 536/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4752 - accuracy: 0.8432 - val_loss: 1.2781 - val_accuracy: 0.5115\n",
      "Epoch 537/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4716 - accuracy: 0.8244 - val_loss: 1.2608 - val_accuracy: 0.5000\n",
      "Epoch 538/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4718 - accuracy: 0.8378 - val_loss: 1.2543 - val_accuracy: 0.5230\n",
      "Epoch 539/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4719 - accuracy: 0.8418 - val_loss: 1.2505 - val_accuracy: 0.5287\n",
      "Epoch 540/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4757 - accuracy: 0.8472 - val_loss: 1.2452 - val_accuracy: 0.5230\n",
      "Epoch 541/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4693 - accuracy: 0.8485 - val_loss: 1.2485 - val_accuracy: 0.5000\n",
      "Epoch 542/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4719 - accuracy: 0.8324 - val_loss: 1.2718 - val_accuracy: 0.5345\n",
      "Epoch 543/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4600 - accuracy: 0.8472 - val_loss: 1.2826 - val_accuracy: 0.5000\n",
      "Epoch 544/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4642 - accuracy: 0.8445 - val_loss: 1.2445 - val_accuracy: 0.5230\n",
      "Epoch 545/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4694 - accuracy: 0.8445 - val_loss: 1.2997 - val_accuracy: 0.5230\n",
      "Epoch 546/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4673 - accuracy: 0.8539 - val_loss: 1.2593 - val_accuracy: 0.5172\n",
      "Epoch 547/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4569 - accuracy: 0.8499 - val_loss: 1.2202 - val_accuracy: 0.5230\n",
      "Epoch 548/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4663 - accuracy: 0.8365 - val_loss: 1.3734 - val_accuracy: 0.4943\n",
      "Epoch 549/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4582 - accuracy: 0.8485 - val_loss: 1.2742 - val_accuracy: 0.5287\n",
      "Epoch 550/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4446 - accuracy: 0.8539 - val_loss: 1.2485 - val_accuracy: 0.5172\n",
      "Epoch 551/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4537 - accuracy: 0.8539 - val_loss: 1.2553 - val_accuracy: 0.5345 - loss: 0.4567 - accuracy\n",
      "Epoch 552/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4568 - accuracy: 0.8539 - val_loss: 1.2918 - val_accuracy: 0.4885\n",
      "Epoch 553/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4460 - accuracy: 0.8445 - val_loss: 1.2586 - val_accuracy: 0.5115\n",
      "Epoch 554/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4410 - accuracy: 0.8525 - val_loss: 1.2662 - val_accuracy: 0.5057\n",
      "Epoch 555/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4502 - accuracy: 0.8606 - val_loss: 1.3252 - val_accuracy: 0.5000\n",
      "Epoch 556/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4533 - accuracy: 0.8646 - val_loss: 1.2654 - val_accuracy: 0.4828\n",
      "Epoch 557/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4471 - accuracy: 0.8512 - val_loss: 1.4135 - val_accuracy: 0.4828\n",
      "Epoch 558/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4466 - accuracy: 0.8552 - val_loss: 1.2975 - val_accuracy: 0.5345\n",
      "Epoch 559/700\n",
      "746/746 [==============================] - ETA: 0s - loss: 0.4485 - accuracy: 0.84 - 3s 4ms/step - loss: 0.4494 - accuracy: 0.8458 - val_loss: 1.2754 - val_accuracy: 0.5345\n",
      "Epoch 560/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4452 - accuracy: 0.8485 - val_loss: 1.2963 - val_accuracy: 0.4943\n",
      "Epoch 561/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4429 - accuracy: 0.8633 - val_loss: 1.3217 - val_accuracy: 0.5345\n",
      "Epoch 562/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4382 - accuracy: 0.8592 - val_loss: 1.5048 - val_accuracy: 0.4483\n",
      "Epoch 563/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4372 - accuracy: 0.8499 - val_loss: 1.2719 - val_accuracy: 0.5345\n",
      "Epoch 564/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4403 - accuracy: 0.8458 - val_loss: 1.3965 - val_accuracy: 0.4713\n",
      "Epoch 565/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4476 - accuracy: 0.8512 - val_loss: 1.2833 - val_accuracy: 0.5287\n",
      "Epoch 566/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4367 - accuracy: 0.8525 - val_loss: 1.2798 - val_accuracy: 0.5230\n",
      "Epoch 567/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4404 - accuracy: 0.8646 - val_loss: 1.2910 - val_accuracy: 0.4828\n",
      "Epoch 568/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4354 - accuracy: 0.8646 - val_loss: 1.3226 - val_accuracy: 0.5287\n",
      "Epoch 569/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4245 - accuracy: 0.8646 - val_loss: 1.3084 - val_accuracy: 0.5345\n",
      "Epoch 570/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4239 - accuracy: 0.8525 - val_loss: 1.2757 - val_accuracy: 0.4885\n",
      "Epoch 571/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4255 - accuracy: 0.8579 - val_loss: 1.2794 - val_accuracy: 0.5172\n",
      "Epoch 572/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4230 - accuracy: 0.8646 - val_loss: 1.3054 - val_accuracy: 0.5000\n",
      "Epoch 573/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4244 - accuracy: 0.8646 - val_loss: 1.4047 - val_accuracy: 0.4713\n",
      "Epoch 574/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4294 - accuracy: 0.8619 - val_loss: 1.3613 - val_accuracy: 0.4943\n",
      "Epoch 575/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4359 - accuracy: 0.8539 - val_loss: 1.2970 - val_accuracy: 0.5230\n",
      "Epoch 576/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4158 - accuracy: 0.8660 - val_loss: 1.2868 - val_accuracy: 0.5287\n",
      "Epoch 577/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4203 - accuracy: 0.8686 - val_loss: 1.2978 - val_accuracy: 0.5057\n",
      "Epoch 578/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4276 - accuracy: 0.8552 - val_loss: 1.3096 - val_accuracy: 0.5287\n",
      "Epoch 579/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4208 - accuracy: 0.8552 - val_loss: 1.2882 - val_accuracy: 0.5172\n",
      "Epoch 580/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4209 - accuracy: 0.8566 - val_loss: 1.2999 - val_accuracy: 0.5460\n",
      "Epoch 581/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4114 - accuracy: 0.8740 - val_loss: 1.2784 - val_accuracy: 0.5287\n",
      "Epoch 582/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4232 - accuracy: 0.8673 - val_loss: 1.2834 - val_accuracy: 0.5287\n",
      "Epoch 583/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4197 - accuracy: 0.8619 - val_loss: 1.3041 - val_accuracy: 0.5172\n",
      "Epoch 584/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4204 - accuracy: 0.8619 - val_loss: 1.2709 - val_accuracy: 0.5172\n",
      "Epoch 585/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4176 - accuracy: 0.8592 - val_loss: 1.2481 - val_accuracy: 0.5115\n",
      "Epoch 586/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4101 - accuracy: 0.8633 - val_loss: 1.2545 - val_accuracy: 0.5402\n",
      "Epoch 587/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4111 - accuracy: 0.8619 - val_loss: 1.2884 - val_accuracy: 0.5000\n",
      "Epoch 588/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4126 - accuracy: 0.8807 - val_loss: 1.2608 - val_accuracy: 0.5115\n",
      "Epoch 589/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4056 - accuracy: 0.8646 - val_loss: 1.2790 - val_accuracy: 0.5402\n",
      "Epoch 590/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4035 - accuracy: 0.8780 - val_loss: 1.2945 - val_accuracy: 0.5115\n",
      "Epoch 591/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4104 - accuracy: 0.8512 - val_loss: 1.3312 - val_accuracy: 0.4770\n",
      "Epoch 592/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4007 - accuracy: 0.8660 - val_loss: 1.3054 - val_accuracy: 0.5057\n",
      "Epoch 593/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4072 - accuracy: 0.8700 - val_loss: 1.2902 - val_accuracy: 0.5287\n",
      "Epoch 594/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.4091 - accuracy: 0.8646 - val_loss: 1.2753 - val_accuracy: 0.5115\n",
      "Epoch 595/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3984 - accuracy: 0.8713 - val_loss: 1.3577 - val_accuracy: 0.4828\n",
      "Epoch 596/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3956 - accuracy: 0.8713 - val_loss: 1.2920 - val_accuracy: 0.5287\n",
      "Epoch 597/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3965 - accuracy: 0.8767 - val_loss: 1.3098 - val_accuracy: 0.5172\n",
      "Epoch 598/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3896 - accuracy: 0.8847 - val_loss: 1.3245 - val_accuracy: 0.5000\n",
      "Epoch 599/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3991 - accuracy: 0.8740 - val_loss: 1.3049 - val_accuracy: 0.5287\n",
      "Epoch 600/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3951 - accuracy: 0.8794 - val_loss: 1.2975 - val_accuracy: 0.5172\n",
      "Epoch 601/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3975 - accuracy: 0.8780 - val_loss: 1.5326 - val_accuracy: 0.4713\n",
      "Epoch 602/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3940 - accuracy: 0.8700 - val_loss: 1.3281 - val_accuracy: 0.5287\n",
      "Epoch 603/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3949 - accuracy: 0.8794 - val_loss: 1.2814 - val_accuracy: 0.5115\n",
      "Epoch 604/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3870 - accuracy: 0.8928 - val_loss: 1.3267 - val_accuracy: 0.5402\n",
      "Epoch 605/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3944 - accuracy: 0.8753 - val_loss: 1.3212 - val_accuracy: 0.5460\n",
      "Epoch 606/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3865 - accuracy: 0.8740 - val_loss: 1.4809 - val_accuracy: 0.5000\n",
      "Epoch 607/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3942 - accuracy: 0.8753 - val_loss: 1.3051 - val_accuracy: 0.5287\n",
      "Epoch 608/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3880 - accuracy: 0.8847 - val_loss: 1.4001 - val_accuracy: 0.5172\n",
      "Epoch 609/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3714 - accuracy: 0.8861 - val_loss: 1.4606 - val_accuracy: 0.4943\n",
      "Epoch 610/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3748 - accuracy: 0.8954 - val_loss: 1.3082 - val_accuracy: 0.5402\n",
      "Epoch 611/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3798 - accuracy: 0.8713 - val_loss: 1.3663 - val_accuracy: 0.4943\n",
      "Epoch 612/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3858 - accuracy: 0.8834 - val_loss: 1.2700 - val_accuracy: 0.5115\n",
      "Epoch 613/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3832 - accuracy: 0.8740 - val_loss: 1.4530 - val_accuracy: 0.4713\n",
      "Epoch 614/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3769 - accuracy: 0.8767 - val_loss: 1.3571 - val_accuracy: 0.5172\n",
      "Epoch 615/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3822 - accuracy: 0.8767 - val_loss: 1.2965 - val_accuracy: 0.5115\n",
      "Epoch 616/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3751 - accuracy: 0.8968 - val_loss: 1.2940 - val_accuracy: 0.5402\n",
      "Epoch 617/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3776 - accuracy: 0.8727 - val_loss: 1.2813 - val_accuracy: 0.5345\n",
      "Epoch 618/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3813 - accuracy: 0.8981 - val_loss: 1.3074 - val_accuracy: 0.5000\n",
      "Epoch 619/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3675 - accuracy: 0.8941 - val_loss: 1.3830 - val_accuracy: 0.4943\n",
      "Epoch 620/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3651 - accuracy: 0.8780 - val_loss: 1.3146 - val_accuracy: 0.5000\n",
      "Epoch 621/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3759 - accuracy: 0.8928 - val_loss: 1.3402 - val_accuracy: 0.5172\n",
      "Epoch 622/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3807 - accuracy: 0.8794 - val_loss: 1.3374 - val_accuracy: 0.5402\n",
      "Epoch 623/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3687 - accuracy: 0.8740 - val_loss: 1.3074 - val_accuracy: 0.5057\n",
      "Epoch 624/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3658 - accuracy: 0.8981 - val_loss: 1.3449 - val_accuracy: 0.5345\n",
      "Epoch 625/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3681 - accuracy: 0.8887 - val_loss: 1.5091 - val_accuracy: 0.4598\n",
      "Epoch 626/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3652 - accuracy: 0.8968 - val_loss: 1.3350 - val_accuracy: 0.5172\n",
      "Epoch 627/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3564 - accuracy: 0.8874 - val_loss: 1.3167 - val_accuracy: 0.5230\n",
      "Epoch 628/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3677 - accuracy: 0.8794 - val_loss: 1.3402 - val_accuracy: 0.5057\n",
      "Epoch 629/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3589 - accuracy: 0.8954 - val_loss: 1.4137 - val_accuracy: 0.4885\n",
      "Epoch 630/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3594 - accuracy: 0.9062 - val_loss: 1.4762 - val_accuracy: 0.4540\n",
      "Epoch 631/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3558 - accuracy: 0.8981 - val_loss: 1.3091 - val_accuracy: 0.5230\n",
      "Epoch 632/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3679 - accuracy: 0.8874 - val_loss: 1.3030 - val_accuracy: 0.5172\n",
      "Epoch 633/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3646 - accuracy: 0.8847 - val_loss: 1.3750 - val_accuracy: 0.5402\n",
      "Epoch 634/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3535 - accuracy: 0.8928 - val_loss: 1.3705 - val_accuracy: 0.5345\n",
      "Epoch 635/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3524 - accuracy: 0.9008 - val_loss: 1.4278 - val_accuracy: 0.4713\n",
      "Epoch 636/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3566 - accuracy: 0.8914 - val_loss: 1.3978 - val_accuracy: 0.5115\n",
      "Epoch 637/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3611 - accuracy: 0.8901 - val_loss: 1.3693 - val_accuracy: 0.5057\n",
      "Epoch 638/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3489 - accuracy: 0.8887 - val_loss: 1.3383 - val_accuracy: 0.5287\n",
      "Epoch 639/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3460 - accuracy: 0.8995 - val_loss: 1.4712 - val_accuracy: 0.4713\n",
      "Epoch 640/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3503 - accuracy: 0.8995 - val_loss: 1.3514 - val_accuracy: 0.5172\n",
      "Epoch 641/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3511 - accuracy: 0.8981 - val_loss: 1.3809 - val_accuracy: 0.5345\n",
      "Epoch 642/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3393 - accuracy: 0.9008 - val_loss: 1.3674 - val_accuracy: 0.5230\n",
      "Epoch 643/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3452 - accuracy: 0.8995 - val_loss: 1.3550 - val_accuracy: 0.5057\n",
      "Epoch 644/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3377 - accuracy: 0.9048 - val_loss: 1.4072 - val_accuracy: 0.5230\n",
      "Epoch 645/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3465 - accuracy: 0.8995 - val_loss: 1.4470 - val_accuracy: 0.4828\n",
      "Epoch 646/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3456 - accuracy: 0.8928 - val_loss: 1.3539 - val_accuracy: 0.5115\n",
      "Epoch 647/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3374 - accuracy: 0.8887 - val_loss: 1.2909 - val_accuracy: 0.5575\n",
      "Epoch 648/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3429 - accuracy: 0.8954 - val_loss: 1.3768 - val_accuracy: 0.5287\n",
      "Epoch 649/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3361 - accuracy: 0.9062 - val_loss: 1.4222 - val_accuracy: 0.4770\n",
      "Epoch 650/700\n",
      "746/746 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.9076 ETA: 0s - loss: - 3s 4ms/step - loss: 0.3378 - accuracy: 0.9075 - val_loss: 1.3150 - val_accuracy: 0.5402\n",
      "Epoch 651/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3330 - accuracy: 0.9182 - val_loss: 1.3295 - val_accuracy: 0.5517\n",
      "Epoch 652/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3390 - accuracy: 0.8968 - val_loss: 1.2941 - val_accuracy: 0.5460\n",
      "Epoch 653/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3342 - accuracy: 0.9075 - val_loss: 1.4391 - val_accuracy: 0.4943\n",
      "Epoch 654/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3261 - accuracy: 0.9115 - val_loss: 1.3649 - val_accuracy: 0.4943\n",
      "Epoch 655/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3349 - accuracy: 0.9021 - val_loss: 1.3409 - val_accuracy: 0.5345760 \n",
      "Epoch 656/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3301 - accuracy: 0.9035 - val_loss: 1.3640 - val_accuracy: 0.5287\n",
      "Epoch 657/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3309 - accuracy: 0.9035 - val_loss: 1.3736 - val_accuracy: 0.4943\n",
      "Epoch 658/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3253 - accuracy: 0.8995 - val_loss: 1.3751 - val_accuracy: 0.4770\n",
      "Epoch 659/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3319 - accuracy: 0.8968 - val_loss: 1.3425 - val_accuracy: 0.5287\n",
      "Epoch 660/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3224 - accuracy: 0.9062 - val_loss: 1.3666 - val_accuracy: 0.5115\n",
      "Epoch 661/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3270 - accuracy: 0.8981 - val_loss: 1.3768 - val_accuracy: 0.5057\n",
      "Epoch 662/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3189 - accuracy: 0.9075 - val_loss: 1.3197 - val_accuracy: 0.5345\n",
      "Epoch 663/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3189 - accuracy: 0.9088 - val_loss: 1.3309 - val_accuracy: 0.5230\n",
      "Epoch 664/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3208 - accuracy: 0.9169 - val_loss: 1.3816 - val_accuracy: 0.5287\n",
      "Epoch 665/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3275 - accuracy: 0.9048 - val_loss: 1.4910 - val_accuracy: 0.5057\n",
      "Epoch 666/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3258 - accuracy: 0.9075 - val_loss: 1.3783 - val_accuracy: 0.5230\n",
      "Epoch 667/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3198 - accuracy: 0.9142 - val_loss: 1.3387 - val_accuracy: 0.5345\n",
      "Epoch 668/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3158 - accuracy: 0.9075 - val_loss: 1.3646 - val_accuracy: 0.5057\n",
      "Epoch 669/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3080 - accuracy: 0.9102 - val_loss: 1.3416 - val_accuracy: 0.5230\n",
      "Epoch 670/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3195 - accuracy: 0.9129 - val_loss: 1.5626 - val_accuracy: 0.4540\n",
      "Epoch 671/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3144 - accuracy: 0.9182 - val_loss: 1.4338 - val_accuracy: 0.4943\n",
      "Epoch 672/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3077 - accuracy: 0.9209 - val_loss: 1.3642 - val_accuracy: 0.5057\n",
      "Epoch 673/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3070 - accuracy: 0.9129 - val_loss: 1.4133 - val_accuracy: 0.4943\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3087 - accuracy: 0.9115 - val_loss: 1.4700 - val_accuracy: 0.5057\n",
      "Epoch 675/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3144 - accuracy: 0.9129 - val_loss: 1.3329 - val_accuracy: 0.5287\n",
      "Epoch 676/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3055 - accuracy: 0.9115 - val_loss: 1.3504 - val_accuracy: 0.5230\n",
      "Epoch 677/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3113 - accuracy: 0.9129 - val_loss: 1.3559 - val_accuracy: 0.5460\n",
      "Epoch 678/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3031 - accuracy: 0.9236 - val_loss: 1.3945 - val_accuracy: 0.5230\n",
      "Epoch 679/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3088 - accuracy: 0.9088 - val_loss: 1.3998 - val_accuracy: 0.5000\n",
      "Epoch 680/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3001 - accuracy: 0.9021 - val_loss: 1.4619 - val_accuracy: 0.4943\n",
      "Epoch 681/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3127 - accuracy: 0.9088 - val_loss: 1.3890 - val_accuracy: 0.4943\n",
      "Epoch 682/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3017 - accuracy: 0.9249 - val_loss: 1.3421 - val_accuracy: 0.5115\n",
      "Epoch 683/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3034 - accuracy: 0.9209 - val_loss: 1.3751 - val_accuracy: 0.5115\n",
      "Epoch 684/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3100 - accuracy: 0.9075 - val_loss: 1.4490 - val_accuracy: 0.5230\n",
      "Epoch 685/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3007 - accuracy: 0.9290 - val_loss: 1.3725 - val_accuracy: 0.5115\n",
      "Epoch 686/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2927 - accuracy: 0.9249 - val_loss: 1.3801 - val_accuracy: 0.5230\n",
      "Epoch 687/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.3095 - accuracy: 0.9142 - val_loss: 1.4435 - val_accuracy: 0.5172\n",
      "Epoch 688/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2943 - accuracy: 0.9249 - val_loss: 1.4992 - val_accuracy: 0.5057\n",
      "Epoch 689/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2984 - accuracy: 0.9169 - val_loss: 1.3749 - val_accuracy: 0.5230\n",
      "Epoch 690/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2972 - accuracy: 0.9196 - val_loss: 1.4060 - val_accuracy: 0.5000\n",
      "Epoch 691/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2908 - accuracy: 0.9209 - val_loss: 1.3548 - val_accuracy: 0.5460\n",
      "Epoch 692/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2896 - accuracy: 0.9236 - val_loss: 1.4799 - val_accuracy: 0.4885\n",
      "Epoch 693/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2864 - accuracy: 0.9169 - val_loss: 1.5539 - val_accuracy: 0.4713\n",
      "Epoch 694/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2851 - accuracy: 0.9276 - val_loss: 1.3387 - val_accuracy: 0.5460\n",
      "Epoch 695/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2931 - accuracy: 0.9196 - val_loss: 1.3643 - val_accuracy: 0.5575\n",
      "Epoch 696/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2908 - accuracy: 0.9343 - val_loss: 1.3861 - val_accuracy: 0.5057\n",
      "Epoch 697/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2917 - accuracy: 0.9209 - val_loss: 1.3532 - val_accuracy: 0.5517\n",
      "Epoch 698/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2897 - accuracy: 0.9290 - val_loss: 1.4191 - val_accuracy: 0.5345\n",
      "Epoch 699/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2861 - accuracy: 0.9196 - val_loss: 1.3990 - val_accuracy: 0.5460\n",
      "Epoch 700/700\n",
      "746/746 [==============================] - 3s 4ms/step - loss: 0.2816 - accuracy: 0.9276 - val_loss: 1.3810 - val_accuracy: 0.5690\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\niran\\OneDrive\\Desktop\\Project_1\\Project3_Test\\Speech-Emotion-Analyzer\\saved_models\\Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 56.90%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting emotions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 0s 837us/step\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7959729e-02, 8.7069750e-01, 5.7607435e-02, ..., 1.5059882e-09,\n",
       "        7.9698957e-08, 9.8825944e-07],\n",
       "       [9.9393374e-01, 2.3338059e-06, 5.0824117e-03, ..., 8.0131571e-04,\n",
       "        7.6434864e-10, 6.6599874e-08],\n",
       "       [7.9300191e-04, 8.1794106e-08, 6.3181716e-08, ..., 8.2529372e-01,\n",
       "        1.2009321e-01, 2.0690896e-02],\n",
       "       ...,\n",
       "       [7.6109415e-01, 1.3778335e-02, 1.7926528e-01, ..., 7.4362742e-06,\n",
       "        7.8526837e-06, 5.3586027e-05],\n",
       "       [1.4799385e-04, 1.4709103e-12, 3.6663247e-10, ..., 5.4231696e-03,\n",
       "        7.8261690e-03, 3.5130241e-05],\n",
       "       [3.0906018e-04, 9.6911073e-01, 7.4267527e-03, ..., 8.4677558e-05,\n",
       "        1.5725852e-06, 1.8616332e-03]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 7, 5, 2, 6, 0, 7, 2, 0, 2, 4, 8, 6, 1, 0, 7, 4, 3, 1, 1, 6,\n",
       "       5, 6, 7, 4, 5, 7, 4, 3, 7, 3, 7, 1, 2, 5, 3, 3, 2, 3, 5, 4, 9, 3,\n",
       "       1, 3, 4, 7, 1, 2, 9, 8, 0, 7, 5, 6, 6, 5, 6, 5, 3, 6, 9, 6, 5, 2,\n",
       "       9, 0, 3, 0, 8, 7, 3, 2, 0, 0, 6, 2, 1, 1, 9, 9, 7, 4, 6, 8, 3, 6,\n",
       "       1, 7, 8, 6, 4, 2, 9, 6, 9, 6, 3, 3, 1, 3, 2, 0, 7, 4, 5, 9, 7, 6,\n",
       "       6, 5, 3, 4, 5, 9, 1, 5, 3, 5, 5, 5, 5, 6, 1, 5, 3, 7, 8, 0, 6, 8,\n",
       "       3, 4, 8, 8, 8, 2, 7, 7, 5, 0, 4, 8, 2, 1, 7, 7, 8, 0, 7, 8, 2, 5,\n",
       "       5, 7, 7, 3, 9, 3, 4, 7, 8, 9, 0, 7, 3, 6, 0, 0, 9, 0, 5, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predictedvalues\n",
       "0     female_calm\n",
       "1    female_angry\n",
       "2    male_fearful\n",
       "3      male_angry\n",
       "4  female_fearful\n",
       "5       male_calm\n",
       "6    female_angry\n",
       "7    male_fearful\n",
       "8  female_fearful\n",
       "9    female_angry"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actualvalues\n",
       "0    female_angry\n",
       "1    female_angry\n",
       "2        male_sad\n",
       "3      male_angry\n",
       "4  female_fearful\n",
       "5        male_sad\n",
       "6    female_angry\n",
       "7      male_angry\n",
       "8  female_fearful\n",
       "9  female_fearful"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual v/s Predicted emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>female_fearful</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>female_calm</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actualvalues predictedvalues\n",
       "170        male_sad        male_sad\n",
       "171  female_fearful    female_angry\n",
       "172      male_angry      male_angry\n",
       "173     female_calm     female_calm"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf[170:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_calm</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_calm</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predictedvalues\n",
       "actualvalues                   \n",
       "female_angry                 20\n",
       "female_calm                  17\n",
       "female_fearful               17\n",
       "female_happy                 14\n",
       "female_sad                   14\n",
       "male_angry                   23\n",
       "male_calm                    14\n",
       "male_fearful                 16\n",
       "male_happy                   21\n",
       "male_sad                     18"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictedvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_calm</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_calm</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 actualvalues\n",
       "predictedvalues              \n",
       "female_angry               17\n",
       "female_calm                15\n",
       "female_fearful             14\n",
       "female_happy               22\n",
       "female_sad                 13\n",
       "male_angry                 22\n",
       "male_calm                  20\n",
       "male_fearful               24\n",
       "male_happy                 14\n",
       "male_sad                   13"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The file 'output10.wav' in the next cell is the file that was recorded live using the code in AudioRecoreder notebook found in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('14.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x2a263607f98>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# % pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#livedf= pd.DataFrame(columns=['feature'])\n",
    "X, sample_rate = librosa.load('14.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "featurelive = mfccs\n",
    "livedf2 = featurelive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2= pd.DataFrame(data=livedf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2 = livedf2.stack().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-19.0287</td>\n",
       "      <td>-17.235321</td>\n",
       "      <td>-17.130693</td>\n",
       "      <td>-14.276484</td>\n",
       "      <td>-16.29781</td>\n",
       "      <td>-18.208714</td>\n",
       "      <td>-17.485451</td>\n",
       "      <td>-16.065697</td>\n",
       "      <td>-14.752503</td>\n",
       "      <td>-14.033712</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.227779</td>\n",
       "      <td>-8.5263</td>\n",
       "      <td>-11.2081</td>\n",
       "      <td>-14.620745</td>\n",
       "      <td>-13.204439</td>\n",
       "      <td>-15.144588</td>\n",
       "      <td>-16.351946</td>\n",
       "      <td>-16.329029</td>\n",
       "      <td>-11.073838</td>\n",
       "      <td>-4.371945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1          2          3         4          5          6    \\\n",
       "         0          0          0          0         0          0          0   \n",
       "0 -19.0287 -17.235321 -17.130693 -14.276484 -16.29781 -18.208714 -17.485451   \n",
       "\n",
       "         7          8          9    ...        206     207      208  \\\n",
       "           0          0          0  ...          0       0        0   \n",
       "0 -16.065697 -14.752503 -14.033712  ... -11.227779 -8.5263 -11.2081   \n",
       "\n",
       "         209        210        211        212        213        214       215  \n",
       "           0          0          0          0          0          0         0  \n",
       "0 -14.620745 -13.204439 -15.144588 -16.351946 -16.329029 -11.073838 -4.371945  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livedf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "twodim= np.expand_dims(livedf2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "livepreds = loaded_model.predict(twodim, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.61741668e-01, 2.17086222e-06, 7.36440241e-01, 1.55930547e-03,\n",
       "        2.39971268e-04, 1.40450766e-05, 2.83696666e-09, 1.95218627e-06,\n",
       "        5.90840045e-07, 1.05576376e-07]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "livepreds1=livepreds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveabc = livepreds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female_fearful'], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepredictions = (lb.inverse_transform((liveabc)))\n",
    "livepredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
