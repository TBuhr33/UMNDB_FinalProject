{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiri\\Anaconda3\\envs\\Emotion\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist= os.listdir('Audio_Song_Actors_01-24')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-02-01-01-01-01-20.wav\n"
     ]
    }
   ],
   "source": [
    "print(mylist[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03\n"
     ]
    }
   ],
   "source": [
    "print(mylist[400][6:-16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the audio file's waveform and its spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('Audio_Song_Actors_01-24/03-02-06-02-02-01-15.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x20d699466a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# % pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wavio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-69a43c136ee7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwavfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwavio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wavio'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "import wavio\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "sr,x = scipy.io.wavfile.read('Audio_Song_Actors_01-24/03-02-06-02-02-01-15.wav')\n",
    "\n",
    "## Parameters: 10ms step, 30ms window\n",
    "nstep = int(sr * 0.01)\n",
    "nwin  = int(sr * 0.03)\n",
    "nfft = nwin\n",
    "\n",
    "window = np.hamming(nwin)\n",
    "\n",
    "## will take windows x[n1:n2].  generate\n",
    "## and loop over n2 such that all frames\n",
    "## fit within the waveform\n",
    "nn = range(nwin, len(x), nstep)\n",
    "\n",
    "X = np.zeros( (len(nn), nfft//2) )\n",
    "\n",
    "for i,n in enumerate(nn):\n",
    "    xseg = x[n-nwin:n]\n",
    "    z = np.fft.fft(window * xseg, nfft)\n",
    "    X[i,:] = np.log(np.abs(z[:nfft//2]))\n",
    "\n",
    "plt.imshow(X.T, interpolation='nearest',\n",
    "    origin='lower',\n",
    "    aspect='auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_calm')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_calm')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_sad')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='a':\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[:1]=='f':\n",
    "        feeling_list.append('male_fearful')\n",
    "    elif item[:1]=='h':\n",
    "        feeling_list.append('male_happy')\n",
    "    #elif item[:1]=='n':\n",
    "        #feeling_list.append('neutral')\n",
    "    elif item[:2]=='sa':\n",
    "        feeling_list.append('male_sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(feeling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    male_calm\n",
       "1  female_calm\n",
       "2    male_calm\n",
       "3  female_calm\n",
       "4    male_calm\n",
       "5  female_calm\n",
       "6    male_calm\n",
       "7  female_calm\n",
       "8    male_calm\n",
       "9  female_calm"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the features of audio files using librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "        X, sample_rate = librosa.load('Audio_Song_Actors_01-24/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        #[float(i) for i in feature]\n",
    "        #feature1=feature[:135]\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-61.542942, -61.67029, -61.663513, -61.675594...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-59.344055, -59.344055, -59.344055, -59.34405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-48.954494, -48.82861, -49.6816, -52.03216, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-60.07603, -60.313347, -59.857048, -57.80332,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-60.01485, -62.686897, -65.488106, -60.48127,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-61.542942, -61.67029, -61.663513, -61.675594...\n",
       "1  [-59.344055, -59.344055, -59.344055, -59.34405...\n",
       "2  [-48.954494, -48.82861, -49.6816, -52.03216, -...\n",
       "3  [-60.07603, -60.313347, -59.857048, -57.80332,...\n",
       "4  [-60.01485, -62.686897, -65.488106, -60.48127,..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-61.542942</td>\n",
       "      <td>-61.670292</td>\n",
       "      <td>-61.663513</td>\n",
       "      <td>-61.675594</td>\n",
       "      <td>-59.627464</td>\n",
       "      <td>-58.578274</td>\n",
       "      <td>-60.384644</td>\n",
       "      <td>-60.370815</td>\n",
       "      <td>-59.209068</td>\n",
       "      <td>-59.793682</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.029648</td>\n",
       "      <td>-28.536741</td>\n",
       "      <td>-27.502647</td>\n",
       "      <td>-26.418858</td>\n",
       "      <td>-27.831203</td>\n",
       "      <td>-28.752033</td>\n",
       "      <td>-28.786449</td>\n",
       "      <td>-21.615858</td>\n",
       "      <td>-17.308699</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.964802</td>\n",
       "      <td>-43.955097</td>\n",
       "      <td>-44.208008</td>\n",
       "      <td>-43.749870</td>\n",
       "      <td>-42.165371</td>\n",
       "      <td>-43.236347</td>\n",
       "      <td>-43.611912</td>\n",
       "      <td>-20.658558</td>\n",
       "      <td>-12.422130</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-48.954494</td>\n",
       "      <td>-48.828609</td>\n",
       "      <td>-49.681599</td>\n",
       "      <td>-52.032162</td>\n",
       "      <td>-48.399113</td>\n",
       "      <td>-47.975899</td>\n",
       "      <td>-49.650616</td>\n",
       "      <td>-51.260963</td>\n",
       "      <td>-49.758038</td>\n",
       "      <td>-50.975227</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.577650</td>\n",
       "      <td>-24.113667</td>\n",
       "      <td>-22.895826</td>\n",
       "      <td>-22.712572</td>\n",
       "      <td>-24.839592</td>\n",
       "      <td>-27.322344</td>\n",
       "      <td>-28.557560</td>\n",
       "      <td>-28.592690</td>\n",
       "      <td>-25.435741</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-60.076031</td>\n",
       "      <td>-60.313347</td>\n",
       "      <td>-59.857048</td>\n",
       "      <td>-57.803322</td>\n",
       "      <td>-58.947754</td>\n",
       "      <td>-59.264015</td>\n",
       "      <td>-57.992619</td>\n",
       "      <td>-57.401936</td>\n",
       "      <td>-57.059830</td>\n",
       "      <td>-57.166061</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.776798</td>\n",
       "      <td>-40.195335</td>\n",
       "      <td>-38.818481</td>\n",
       "      <td>-39.010696</td>\n",
       "      <td>-41.907330</td>\n",
       "      <td>-42.493778</td>\n",
       "      <td>-43.464279</td>\n",
       "      <td>-36.841316</td>\n",
       "      <td>-29.907366</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-60.014851</td>\n",
       "      <td>-62.686897</td>\n",
       "      <td>-65.488106</td>\n",
       "      <td>-60.481270</td>\n",
       "      <td>-60.038151</td>\n",
       "      <td>-64.788376</td>\n",
       "      <td>-66.386238</td>\n",
       "      <td>-61.152500</td>\n",
       "      <td>-58.949646</td>\n",
       "      <td>-59.597214</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.592575</td>\n",
       "      <td>-42.287838</td>\n",
       "      <td>-42.087948</td>\n",
       "      <td>-42.331047</td>\n",
       "      <td>-40.317867</td>\n",
       "      <td>-37.837944</td>\n",
       "      <td>-35.932858</td>\n",
       "      <td>-32.704998</td>\n",
       "      <td>-28.022449</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0 -61.542942 -61.670292 -61.663513 -61.675594 -59.627464 -58.578274   \n",
       "1 -59.344055 -59.344055 -59.344055 -59.344055 -59.344055 -59.344055   \n",
       "2 -48.954494 -48.828609 -49.681599 -52.032162 -48.399113 -47.975899   \n",
       "3 -60.076031 -60.313347 -59.857048 -57.803322 -58.947754 -59.264015   \n",
       "4 -60.014851 -62.686897 -65.488106 -60.481270 -60.038151 -64.788376   \n",
       "\n",
       "         6          7          8          9    ...        207        208  \\\n",
       "0 -60.384644 -60.370815 -59.209068 -59.793682  ... -32.029648 -28.536741   \n",
       "1 -59.344055 -59.344055 -59.344055 -59.344055  ... -42.964802 -43.955097   \n",
       "2 -49.650616 -51.260963 -49.758038 -50.975227  ... -23.577650 -24.113667   \n",
       "3 -57.992619 -57.401936 -57.059830 -57.166061  ... -42.776798 -40.195335   \n",
       "4 -66.386238 -61.152500 -58.949646 -59.597214  ... -43.592575 -42.287838   \n",
       "\n",
       "         209        210        211        212        213        214  \\\n",
       "0 -27.502647 -26.418858 -27.831203 -28.752033 -28.786449 -21.615858   \n",
       "1 -44.208008 -43.749870 -42.165371 -43.236347 -43.611912 -20.658558   \n",
       "2 -22.895826 -22.712572 -24.839592 -27.322344 -28.557560 -28.592690   \n",
       "3 -38.818481 -39.010696 -41.907330 -42.493778 -43.464279 -36.841316   \n",
       "4 -42.087948 -42.331047 -40.317867 -37.837944 -35.932858 -32.704998   \n",
       "\n",
       "         215          0    \n",
       "0 -17.308699    male_calm  \n",
       "1 -12.422130  female_calm  \n",
       "2 -25.435741    male_calm  \n",
       "3 -29.907366  female_calm  \n",
       "4 -28.022449    male_calm  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnewdf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>-51.775120</td>\n",
       "      <td>-51.744263</td>\n",
       "      <td>-51.376850</td>\n",
       "      <td>-51.233643</td>\n",
       "      <td>-50.877598</td>\n",
       "      <td>-50.888729</td>\n",
       "      <td>-53.720558</td>\n",
       "      <td>-53.869221</td>\n",
       "      <td>-53.331184</td>\n",
       "      <td>-53.013443</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.404564</td>\n",
       "      <td>-20.996796</td>\n",
       "      <td>-23.098145</td>\n",
       "      <td>-23.065769</td>\n",
       "      <td>-24.071766</td>\n",
       "      <td>-25.880318</td>\n",
       "      <td>-26.193195</td>\n",
       "      <td>-16.015278</td>\n",
       "      <td>-10.743226</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-54.252243</td>\n",
       "      <td>-54.165955</td>\n",
       "      <td>-51.046440</td>\n",
       "      <td>-49.469425</td>\n",
       "      <td>-49.588432</td>\n",
       "      <td>-49.514343</td>\n",
       "      <td>-49.238754</td>\n",
       "      <td>-50.535660</td>\n",
       "      <td>-53.040806</td>\n",
       "      <td>-51.091064</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.494053</td>\n",
       "      <td>-41.599468</td>\n",
       "      <td>-42.629753</td>\n",
       "      <td>-43.705139</td>\n",
       "      <td>-44.204227</td>\n",
       "      <td>-44.872639</td>\n",
       "      <td>-45.697636</td>\n",
       "      <td>-26.001448</td>\n",
       "      <td>-17.960152</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>-53.908073</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.159882</td>\n",
       "      <td>-38.130642</td>\n",
       "      <td>-38.236534</td>\n",
       "      <td>-39.302212</td>\n",
       "      <td>-39.813927</td>\n",
       "      <td>-40.463100</td>\n",
       "      <td>-40.369411</td>\n",
       "      <td>-44.137161</td>\n",
       "      <td>-49.557190</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>-49.211082</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.910286</td>\n",
       "      <td>-37.092831</td>\n",
       "      <td>-37.574394</td>\n",
       "      <td>-36.873039</td>\n",
       "      <td>-38.501839</td>\n",
       "      <td>-37.814377</td>\n",
       "      <td>-38.274197</td>\n",
       "      <td>-17.646601</td>\n",
       "      <td>-9.246959</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-55.456543</td>\n",
       "      <td>-53.724998</td>\n",
       "      <td>-52.878319</td>\n",
       "      <td>-52.075291</td>\n",
       "      <td>-49.407444</td>\n",
       "      <td>-48.776176</td>\n",
       "      <td>-49.279575</td>\n",
       "      <td>-50.695354</td>\n",
       "      <td>-54.263626</td>\n",
       "      <td>-56.399551</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.360159</td>\n",
       "      <td>-26.930798</td>\n",
       "      <td>-27.492725</td>\n",
       "      <td>-27.321016</td>\n",
       "      <td>-28.038013</td>\n",
       "      <td>-27.787350</td>\n",
       "      <td>-28.339529</td>\n",
       "      <td>-21.485685</td>\n",
       "      <td>-16.452255</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>-48.965492</td>\n",
       "      <td>-48.977024</td>\n",
       "      <td>-48.899982</td>\n",
       "      <td>-48.841892</td>\n",
       "      <td>-48.682598</td>\n",
       "      <td>-49.020527</td>\n",
       "      <td>-49.134983</td>\n",
       "      <td>-48.971500</td>\n",
       "      <td>-48.340958</td>\n",
       "      <td>-47.462322</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.893024</td>\n",
       "      <td>-35.790348</td>\n",
       "      <td>-32.123081</td>\n",
       "      <td>-33.405727</td>\n",
       "      <td>-38.024818</td>\n",
       "      <td>-37.358894</td>\n",
       "      <td>-36.790768</td>\n",
       "      <td>-24.093300</td>\n",
       "      <td>-15.974380</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>-49.922073</td>\n",
       "      <td>-47.908684</td>\n",
       "      <td>-48.660007</td>\n",
       "      <td>-50.301395</td>\n",
       "      <td>-50.301395</td>\n",
       "      <td>-48.814255</td>\n",
       "      <td>-49.249126</td>\n",
       "      <td>-50.301395</td>\n",
       "      <td>-50.099373</td>\n",
       "      <td>-47.030861</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.372486</td>\n",
       "      <td>-37.524803</td>\n",
       "      <td>-40.141777</td>\n",
       "      <td>-38.564377</td>\n",
       "      <td>-39.460606</td>\n",
       "      <td>-40.490608</td>\n",
       "      <td>-40.264980</td>\n",
       "      <td>-20.803297</td>\n",
       "      <td>-11.809550</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-47.497585</td>\n",
       "      <td>-48.283329</td>\n",
       "      <td>-48.539761</td>\n",
       "      <td>-50.245159</td>\n",
       "      <td>-49.729958</td>\n",
       "      <td>-49.125095</td>\n",
       "      <td>-50.152317</td>\n",
       "      <td>-51.284283</td>\n",
       "      <td>-50.023819</td>\n",
       "      <td>-49.314079</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.185711</td>\n",
       "      <td>-17.872257</td>\n",
       "      <td>-17.739674</td>\n",
       "      <td>-18.963360</td>\n",
       "      <td>-20.805248</td>\n",
       "      <td>-23.377369</td>\n",
       "      <td>-25.610783</td>\n",
       "      <td>-18.686062</td>\n",
       "      <td>-14.495777</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>-53.338070</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.393677</td>\n",
       "      <td>-30.596886</td>\n",
       "      <td>-29.207335</td>\n",
       "      <td>-29.441174</td>\n",
       "      <td>-29.159494</td>\n",
       "      <td>-29.937960</td>\n",
       "      <td>-29.780060</td>\n",
       "      <td>-22.211311</td>\n",
       "      <td>-16.684786</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-55.604927</td>\n",
       "      <td>-55.636600</td>\n",
       "      <td>-56.766270</td>\n",
       "      <td>-54.728760</td>\n",
       "      <td>-54.332371</td>\n",
       "      <td>-53.939487</td>\n",
       "      <td>-53.025986</td>\n",
       "      <td>-52.874657</td>\n",
       "      <td>-53.887451</td>\n",
       "      <td>-55.134102</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.218998</td>\n",
       "      <td>-26.019178</td>\n",
       "      <td>-25.813856</td>\n",
       "      <td>-28.464918</td>\n",
       "      <td>-31.025356</td>\n",
       "      <td>-29.192289</td>\n",
       "      <td>-29.069883</td>\n",
       "      <td>-31.586346</td>\n",
       "      <td>-30.823273</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "226 -51.775120 -51.744263 -51.376850 -51.233643 -50.877598 -50.888729   \n",
       "329 -54.252243 -54.165955 -51.046440 -49.469425 -49.588432 -49.514343   \n",
       "887 -53.908073 -53.908073 -53.908073 -53.908073 -53.908073 -53.908073   \n",
       "348 -49.211082 -49.211082 -49.211082 -49.211082 -49.211082 -49.211082   \n",
       "412 -55.456543 -53.724998 -52.878319 -52.075291 -49.407444 -48.776176   \n",
       "563 -48.965492 -48.977024 -48.899982 -48.841892 -48.682598 -49.020527   \n",
       "582 -49.922073 -47.908684 -48.660007 -50.301395 -50.301395 -48.814255   \n",
       "552 -47.497585 -48.283329 -48.539761 -50.245159 -49.729958 -49.125095   \n",
       "606 -53.338070 -53.338070 -53.338070 -53.338070 -53.338070 -53.338070   \n",
       "270 -55.604927 -55.636600 -56.766270 -54.728760 -54.332371 -53.939487   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "226 -53.720558 -53.869221 -53.331184 -53.013443  ... -18.404564 -20.996796   \n",
       "329 -49.238754 -50.535660 -53.040806 -51.091064  ... -41.494053 -41.599468   \n",
       "887 -53.908073 -53.908073 -53.908073 -53.908073  ... -37.159882 -38.130642   \n",
       "348 -49.211082 -49.211082 -49.211082 -49.211082  ... -37.910286 -37.092831   \n",
       "412 -49.279575 -50.695354 -54.263626 -56.399551  ... -27.360159 -26.930798   \n",
       "563 -49.134983 -48.971500 -48.340958 -47.462322  ... -37.893024 -35.790348   \n",
       "582 -49.249126 -50.301395 -50.099373 -47.030861  ... -37.372486 -37.524803   \n",
       "552 -50.152317 -51.284283 -50.023819 -49.314079  ... -21.185711 -17.872257   \n",
       "606 -53.338070 -53.338070 -53.338070 -53.338070  ... -29.393677 -30.596886   \n",
       "270 -53.025986 -52.874657 -53.887451 -55.134102  ... -26.218998 -26.019178   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "226 -23.098145 -23.065769 -24.071766 -25.880318 -26.193195 -16.015278   \n",
       "329 -42.629753 -43.705139 -44.204227 -44.872639 -45.697636 -26.001448   \n",
       "887 -38.236534 -39.302212 -39.813927 -40.463100 -40.369411 -44.137161   \n",
       "348 -37.574394 -36.873039 -38.501839 -37.814377 -38.274197 -17.646601   \n",
       "412 -27.492725 -27.321016 -28.038013 -27.787350 -28.339529 -21.485685   \n",
       "563 -32.123081 -33.405727 -38.024818 -37.358894 -36.790768 -24.093300   \n",
       "582 -40.141777 -38.564377 -39.460606 -40.490608 -40.264980 -20.803297   \n",
       "552 -17.739674 -18.963360 -20.805248 -23.377369 -25.610783 -18.686062   \n",
       "606 -29.207335 -29.441174 -29.159494 -29.937960 -29.780060 -22.211311   \n",
       "270 -25.813856 -28.464918 -31.025356 -29.192289 -29.069883 -31.586346   \n",
       "\n",
       "           215             0    \n",
       "226 -10.743226      male_happy  \n",
       "329 -17.960152    female_happy  \n",
       "887 -49.557190  female_fearful  \n",
       "348  -9.246959    female_happy  \n",
       "412 -16.452255        male_sad  \n",
       "563 -15.974380    female_angry  \n",
       "582 -11.809550    female_angry  \n",
       "552 -14.495777      male_angry  \n",
       "606 -16.684786      male_angry  \n",
       "270 -30.823273      male_happy  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>-59.344055</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.964802</td>\n",
       "      <td>-43.955097</td>\n",
       "      <td>-44.208008</td>\n",
       "      <td>-43.749870</td>\n",
       "      <td>-42.165371</td>\n",
       "      <td>-43.236347</td>\n",
       "      <td>-43.611912</td>\n",
       "      <td>-20.658558</td>\n",
       "      <td>-12.422130</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>-38.595726</td>\n",
       "      <td>-37.635605</td>\n",
       "      <td>-36.626736</td>\n",
       "      <td>-37.241695</td>\n",
       "      <td>-37.936386</td>\n",
       "      <td>-38.089886</td>\n",
       "      <td>-38.044682</td>\n",
       "      <td>-38.212322</td>\n",
       "      <td>-38.377998</td>\n",
       "      <td>-37.952991</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.813221</td>\n",
       "      <td>-15.169439</td>\n",
       "      <td>-13.346136</td>\n",
       "      <td>-13.066756</td>\n",
       "      <td>-12.980140</td>\n",
       "      <td>-12.389984</td>\n",
       "      <td>-12.315807</td>\n",
       "      <td>-7.452921</td>\n",
       "      <td>-2.566859</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>-52.339008</td>\n",
       "      <td>-52.158188</td>\n",
       "      <td>-52.653893</td>\n",
       "      <td>-54.046738</td>\n",
       "      <td>-51.626038</td>\n",
       "      <td>-51.841812</td>\n",
       "      <td>-54.211819</td>\n",
       "      <td>-54.059898</td>\n",
       "      <td>-52.251572</td>\n",
       "      <td>-53.206734</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.462666</td>\n",
       "      <td>-41.356987</td>\n",
       "      <td>-41.410133</td>\n",
       "      <td>-42.625168</td>\n",
       "      <td>-42.425133</td>\n",
       "      <td>-41.486446</td>\n",
       "      <td>-41.788094</td>\n",
       "      <td>-29.836355</td>\n",
       "      <td>-23.004784</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-63.900528</td>\n",
       "      <td>-63.900528</td>\n",
       "      <td>-63.900528</td>\n",
       "      <td>-63.900528</td>\n",
       "      <td>-63.900528</td>\n",
       "      <td>-63.900528</td>\n",
       "      <td>-63.900528</td>\n",
       "      <td>-63.051094</td>\n",
       "      <td>-63.718025</td>\n",
       "      <td>-63.900528</td>\n",
       "      <td>...</td>\n",
       "      <td>-33.900063</td>\n",
       "      <td>-33.359127</td>\n",
       "      <td>-32.235641</td>\n",
       "      <td>-31.744616</td>\n",
       "      <td>-31.905880</td>\n",
       "      <td>-32.334957</td>\n",
       "      <td>-32.017986</td>\n",
       "      <td>-31.560211</td>\n",
       "      <td>-29.717480</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>-55.677097</td>\n",
       "      <td>-55.424728</td>\n",
       "      <td>-55.242874</td>\n",
       "      <td>-54.337883</td>\n",
       "      <td>-51.845707</td>\n",
       "      <td>-50.900703</td>\n",
       "      <td>-51.864143</td>\n",
       "      <td>-53.123497</td>\n",
       "      <td>-51.652348</td>\n",
       "      <td>-52.188423</td>\n",
       "      <td>...</td>\n",
       "      <td>-36.282608</td>\n",
       "      <td>-37.351994</td>\n",
       "      <td>-36.989067</td>\n",
       "      <td>-36.189190</td>\n",
       "      <td>-38.254017</td>\n",
       "      <td>-42.123516</td>\n",
       "      <td>-41.551521</td>\n",
       "      <td>-19.894621</td>\n",
       "      <td>-10.708134</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>-48.457649</td>\n",
       "      <td>-45.691345</td>\n",
       "      <td>-44.433987</td>\n",
       "      <td>-44.424870</td>\n",
       "      <td>-45.392178</td>\n",
       "      <td>-46.041172</td>\n",
       "      <td>-45.941227</td>\n",
       "      <td>-46.854206</td>\n",
       "      <td>-47.851589</td>\n",
       "      <td>-45.668964</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.994068</td>\n",
       "      <td>-22.917280</td>\n",
       "      <td>-22.363436</td>\n",
       "      <td>-21.901358</td>\n",
       "      <td>-20.576220</td>\n",
       "      <td>-20.651808</td>\n",
       "      <td>-22.512478</td>\n",
       "      <td>-18.025717</td>\n",
       "      <td>-14.843410</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>-57.392025</td>\n",
       "      <td>-57.540535</td>\n",
       "      <td>-57.559242</td>\n",
       "      <td>-57.670753</td>\n",
       "      <td>-57.610111</td>\n",
       "      <td>-57.303230</td>\n",
       "      <td>-55.579941</td>\n",
       "      <td>-54.578674</td>\n",
       "      <td>-54.731106</td>\n",
       "      <td>-55.420002</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.993782</td>\n",
       "      <td>-43.915947</td>\n",
       "      <td>-42.337746</td>\n",
       "      <td>-43.234829</td>\n",
       "      <td>-44.069931</td>\n",
       "      <td>-44.475117</td>\n",
       "      <td>-45.245834</td>\n",
       "      <td>-29.845877</td>\n",
       "      <td>-21.235334</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>-61.850487</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.062740</td>\n",
       "      <td>-46.961887</td>\n",
       "      <td>-49.131477</td>\n",
       "      <td>-48.233181</td>\n",
       "      <td>-48.568222</td>\n",
       "      <td>-47.027996</td>\n",
       "      <td>-45.389091</td>\n",
       "      <td>-33.870029</td>\n",
       "      <td>-26.869381</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>-61.356525</td>\n",
       "      <td>-63.297955</td>\n",
       "      <td>-64.157372</td>\n",
       "      <td>-64.157372</td>\n",
       "      <td>-64.157372</td>\n",
       "      <td>-64.157372</td>\n",
       "      <td>-64.157372</td>\n",
       "      <td>-62.301552</td>\n",
       "      <td>-58.469883</td>\n",
       "      <td>-58.818184</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.385372</td>\n",
       "      <td>-30.864614</td>\n",
       "      <td>-32.768986</td>\n",
       "      <td>-34.310661</td>\n",
       "      <td>-36.808945</td>\n",
       "      <td>-38.075981</td>\n",
       "      <td>-40.742020</td>\n",
       "      <td>-35.532425</td>\n",
       "      <td>-31.268414</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>-54.408718</td>\n",
       "      <td>-53.039444</td>\n",
       "      <td>-55.203388</td>\n",
       "      <td>-59.015156</td>\n",
       "      <td>-58.867474</td>\n",
       "      <td>-59.455345</td>\n",
       "      <td>-59.350174</td>\n",
       "      <td>-58.846439</td>\n",
       "      <td>-58.235588</td>\n",
       "      <td>-57.366680</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.479200</td>\n",
       "      <td>-31.284288</td>\n",
       "      <td>-30.414249</td>\n",
       "      <td>-30.573660</td>\n",
       "      <td>-31.867994</td>\n",
       "      <td>-32.529099</td>\n",
       "      <td>-33.849579</td>\n",
       "      <td>-28.472576</td>\n",
       "      <td>-23.672495</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "1   -59.344055 -59.344055 -59.344055 -59.344055 -59.344055 -59.344055   \n",
       "729 -38.595726 -37.635605 -36.626736 -37.241695 -37.936386 -38.089886   \n",
       "375 -52.339008 -52.158188 -52.653893 -54.046738 -51.626038 -51.841812   \n",
       "399 -63.900528 -63.900528 -63.900528 -63.900528 -63.900528 -63.900528   \n",
       "360 -55.677097 -55.424728 -55.242874 -54.337883 -51.845707 -50.900703   \n",
       "704 -48.457649 -45.691345 -44.433987 -44.424870 -45.392178 -46.041172   \n",
       "749 -57.392025 -57.540535 -57.559242 -57.670753 -57.610111 -57.303230   \n",
       "64  -61.850487 -61.850487 -61.850487 -61.850487 -61.850487 -61.850487   \n",
       "127 -61.356525 -63.297955 -64.157372 -64.157372 -64.157372 -64.157372   \n",
       "449 -54.408718 -53.039444 -55.203388 -59.015156 -58.867474 -59.455345   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "1   -59.344055 -59.344055 -59.344055 -59.344055  ... -42.964802 -43.955097   \n",
       "729 -38.044682 -38.212322 -38.377998 -37.952991  ... -16.813221 -15.169439   \n",
       "375 -54.211819 -54.059898 -52.251572 -53.206734  ... -42.462666 -41.356987   \n",
       "399 -63.900528 -63.051094 -63.718025 -63.900528  ... -33.900063 -33.359127   \n",
       "360 -51.864143 -53.123497 -51.652348 -52.188423  ... -36.282608 -37.351994   \n",
       "704 -45.941227 -46.854206 -47.851589 -45.668964  ... -21.994068 -22.917280   \n",
       "749 -55.579941 -54.578674 -54.731106 -55.420002  ... -42.993782 -43.915947   \n",
       "64  -61.850487 -61.850487 -61.850487 -61.850487  ... -47.062740 -46.961887   \n",
       "127 -64.157372 -62.301552 -58.469883 -58.818184  ... -31.385372 -30.864614   \n",
       "449 -59.350174 -58.846439 -58.235588 -57.366680  ... -30.479200 -31.284288   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "1   -44.208008 -43.749870 -42.165371 -43.236347 -43.611912 -20.658558   \n",
       "729 -13.346136 -13.066756 -12.980140 -12.389984 -12.315807  -7.452921   \n",
       "375 -41.410133 -42.625168 -42.425133 -41.486446 -41.788094 -29.836355   \n",
       "399 -32.235641 -31.744616 -31.905880 -32.334957 -32.017986 -31.560211   \n",
       "360 -36.989067 -36.189190 -38.254017 -42.123516 -41.551521 -19.894621   \n",
       "704 -22.363436 -21.901358 -20.576220 -20.651808 -22.512478 -18.025717   \n",
       "749 -42.337746 -43.234829 -44.069931 -44.475117 -45.245834 -29.845877   \n",
       "64  -49.131477 -48.233181 -48.568222 -47.027996 -45.389091 -33.870029   \n",
       "127 -32.768986 -34.310661 -36.808945 -38.075981 -40.742020 -35.532425   \n",
       "449 -30.414249 -30.573660 -31.867994 -32.529099 -33.849579 -28.472576   \n",
       "\n",
       "           215             0    \n",
       "1   -12.422130     female_calm  \n",
       "729  -2.566859      male_angry  \n",
       "375 -23.004784      female_sad  \n",
       "399 -29.717480        male_sad  \n",
       "360 -10.708134    female_happy  \n",
       "704 -14.843410      male_angry  \n",
       "749 -21.235334  female_fearful  \n",
       "64  -26.869381     female_calm  \n",
       "127 -31.268414       male_calm  \n",
       "449 -23.672495        male_sad  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[250:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiri\\Anaconda3\\envs\\Emotion\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745, 216)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Conv1D(128, 5,padding='same',))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                34570     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 364,170\n",
      "Trainable params: 364,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removed the whole training part for avoiding unnecessary long epochs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 745 samples, validate on 175 samples\n",
      "Epoch 1/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 2.3287 - accuracy: 0.1423 - val_loss: 2.2669 - val_accuracy: 0.0857\n",
      "Epoch 2/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 2.2022 - accuracy: 0.2148 - val_loss: 2.2152 - val_accuracy: 0.1600\n",
      "Epoch 3/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 2.1621 - accuracy: 0.2094 - val_loss: 2.1747 - val_accuracy: 0.1314\n",
      "Epoch 4/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 2.1252 - accuracy: 0.2201 - val_loss: 2.1428 - val_accuracy: 0.1829\n",
      "Epoch 5/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 2.0900 - accuracy: 0.2430 - val_loss: 2.1294 - val_accuracy: 0.1486\n",
      "Epoch 6/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 2.0603 - accuracy: 0.2389 - val_loss: 2.0928 - val_accuracy: 0.1943\n",
      "Epoch 7/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 2.0362 - accuracy: 0.2698 - val_loss: 2.0616 - val_accuracy: 0.2057\n",
      "Epoch 8/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 2.0025 - accuracy: 0.2738 - val_loss: 2.0556 - val_accuracy: 0.1943\n",
      "Epoch 9/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.9740 - accuracy: 0.2899 - val_loss: 2.0070 - val_accuracy: 0.2286\n",
      "Epoch 10/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.9484 - accuracy: 0.3128 - val_loss: 1.9816 - val_accuracy: 0.2000\n",
      "Epoch 11/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.9197 - accuracy: 0.3087 - val_loss: 1.9573 - val_accuracy: 0.2571\n",
      "Epoch 12/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.8927 - accuracy: 0.3168 - val_loss: 1.9250 - val_accuracy: 0.2800\n",
      "Epoch 13/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 1.8715 - accuracy: 0.3275 - val_loss: 1.8936 - val_accuracy: 0.2914\n",
      "Epoch 14/700\n",
      "745/745 [==============================] - 9s 13ms/step - loss: 1.8469 - accuracy: 0.3221 - val_loss: 1.8901 - val_accuracy: 0.2629\n",
      "Epoch 15/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 1.8196 - accuracy: 0.3436 - val_loss: 1.8815 - val_accuracy: 0.2171\n",
      "Epoch 16/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 1.7967 - accuracy: 0.3611 - val_loss: 1.8460 - val_accuracy: 0.2629\n",
      "Epoch 17/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.7782 - accuracy: 0.3557 - val_loss: 1.8345 - val_accuracy: 0.2686\n",
      "Epoch 18/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.7514 - accuracy: 0.3772 - val_loss: 1.8588 - val_accuracy: 0.1771\n",
      "Epoch 19/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 1.7331 - accuracy: 0.3450 - val_loss: 1.8267 - val_accuracy: 0.2514\n",
      "Epoch 20/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.7130 - accuracy: 0.3758 - val_loss: 1.7522 - val_accuracy: 0.3257\n",
      "Epoch 21/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.6901 - accuracy: 0.3906 - val_loss: 1.7763 - val_accuracy: 0.2686\n",
      "Epoch 22/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 1.6696 - accuracy: 0.3826 - val_loss: 1.7556 - val_accuracy: 0.2571\n",
      "Epoch 23/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.6592 - accuracy: 0.4013 - val_loss: 1.7295 - val_accuracy: 0.2857\n",
      "Epoch 24/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.6324 - accuracy: 0.3960 - val_loss: 1.7301 - val_accuracy: 0.3086\n",
      "Epoch 25/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.6179 - accuracy: 0.4174 - val_loss: 1.6911 - val_accuracy: 0.3086\n",
      "Epoch 26/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.6019 - accuracy: 0.4215 - val_loss: 1.6861 - val_accuracy: 0.3200\n",
      "Epoch 27/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 1.5822 - accuracy: 0.4268 - val_loss: 1.6855 - val_accuracy: 0.2971\n",
      "Epoch 28/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 1.5760 - accuracy: 0.4188 - val_loss: 1.6577 - val_accuracy: 0.3029\n",
      "Epoch 29/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.5561 - accuracy: 0.4107 - val_loss: 1.6348 - val_accuracy: 0.3486\n",
      "Epoch 30/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.5420 - accuracy: 0.4282 - val_loss: 1.6243 - val_accuracy: 0.3600\n",
      "Epoch 31/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.5250 - accuracy: 0.4322 - val_loss: 1.6395 - val_accuracy: 0.3143\n",
      "Epoch 32/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.5128 - accuracy: 0.4336 - val_loss: 1.5837 - val_accuracy: 0.3714\n",
      "Epoch 33/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 1.4994 - accuracy: 0.4537 - val_loss: 1.6200 - val_accuracy: 0.3200\n",
      "Epoch 34/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 1.4824 - accuracy: 0.4497 - val_loss: 1.6136 - val_accuracy: 0.3143\n",
      "Epoch 35/700\n",
      "745/745 [==============================] - 8s 10ms/step - loss: 1.4855 - accuracy: 0.4510 - val_loss: 1.5997 - val_accuracy: 0.3314\n",
      "Epoch 36/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.4628 - accuracy: 0.4470 - val_loss: 1.5919 - val_accuracy: 0.3086\n",
      "Epoch 37/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 1.4498 - accuracy: 0.4577 - val_loss: 1.6428 - val_accuracy: 0.3029\n",
      "Epoch 38/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 1.4406 - accuracy: 0.4523 - val_loss: 1.5743 - val_accuracy: 0.3543\n",
      "Epoch 39/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.4334 - accuracy: 0.4497 - val_loss: 1.5306 - val_accuracy: 0.3714\n",
      "Epoch 40/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.4179 - accuracy: 0.4483 - val_loss: 1.5404 - val_accuracy: 0.3829\n",
      "Epoch 41/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.4143 - accuracy: 0.4765 - val_loss: 1.5526 - val_accuracy: 0.3429\n",
      "Epoch 42/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.3966 - accuracy: 0.4899 - val_loss: 1.5351 - val_accuracy: 0.3657\n",
      "Epoch 43/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.3899 - accuracy: 0.4819 - val_loss: 1.5014 - val_accuracy: 0.4000\n",
      "Epoch 44/700\n",
      "745/745 [==============================] - 8s 10ms/step - loss: 1.3788 - accuracy: 0.4658 - val_loss: 1.5374 - val_accuracy: 0.3714\n",
      "Epoch 45/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 1.3694 - accuracy: 0.4765 - val_loss: 1.4925 - val_accuracy: 0.3657\n",
      "Epoch 46/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.3645 - accuracy: 0.4913 - val_loss: 1.5459 - val_accuracy: 0.3543\n",
      "Epoch 47/700\n",
      "745/745 [==============================] - 9s 12ms/step - loss: 1.3563 - accuracy: 0.4805 - val_loss: 1.5187 - val_accuracy: 0.3886\n",
      "Epoch 48/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 1.3480 - accuracy: 0.4886 - val_loss: 1.5038 - val_accuracy: 0.3771\n",
      "Epoch 49/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.3325 - accuracy: 0.4913 - val_loss: 1.4661 - val_accuracy: 0.4114\n",
      "Epoch 50/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.3266 - accuracy: 0.4940 - val_loss: 1.4590 - val_accuracy: 0.4286\n",
      "Epoch 51/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 1.3234 - accuracy: 0.5047 - val_loss: 1.4910 - val_accuracy: 0.3714\n",
      "Epoch 52/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.3125 - accuracy: 0.5101 - val_loss: 1.4642 - val_accuracy: 0.4114\n",
      "Epoch 53/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.3077 - accuracy: 0.5087 - val_loss: 1.4808 - val_accuracy: 0.3371\n",
      "Epoch 54/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2928 - accuracy: 0.5235 - val_loss: 1.4757 - val_accuracy: 0.3657\n",
      "Epoch 55/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.2862 - accuracy: 0.5114 - val_loss: 1.4866 - val_accuracy: 0.3771.2\n",
      "Epoch 56/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 1.2902 - accuracy: 0.5154 - val_loss: 1.4505 - val_accuracy: 0.4057\n",
      "Epoch 57/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 6s 8ms/step - loss: 1.2802 - accuracy: 0.5248 - val_loss: 1.4818 - val_accuracy: 0.3429\n",
      "Epoch 58/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 1.2687 - accuracy: 0.5101 - val_loss: 1.4045 - val_accuracy: 0.4571\n",
      "Epoch 59/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2672 - accuracy: 0.5289 - val_loss: 1.4654 - val_accuracy: 0.3714\n",
      "Epoch 60/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2557 - accuracy: 0.5141 - val_loss: 1.3920 - val_accuracy: 0.4457\n",
      "Epoch 61/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2520 - accuracy: 0.5315 - val_loss: 1.4125 - val_accuracy: 0.4229\n",
      "Epoch 62/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2362 - accuracy: 0.5423 - val_loss: 1.4612 - val_accuracy: 0.3600\n",
      "Epoch 63/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2377 - accuracy: 0.5275 - val_loss: 1.4489 - val_accuracy: 0.3886\n",
      "Epoch 64/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2285 - accuracy: 0.5275 - val_loss: 1.4195 - val_accuracy: 0.3943\n",
      "Epoch 65/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.2235 - accuracy: 0.5369 - val_loss: 1.4118 - val_accuracy: 0.4057\n",
      "Epoch 66/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.2266 - accuracy: 0.5302 - val_loss: 1.4249 - val_accuracy: 0.4057\n",
      "Epoch 67/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2126 - accuracy: 0.5289 - val_loss: 1.3978 - val_accuracy: 0.4286\n",
      "Epoch 68/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.2140 - accuracy: 0.5235 - val_loss: 1.4075 - val_accuracy: 0.3829\n",
      "Epoch 69/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.2001 - accuracy: 0.5342 - val_loss: 1.4638 - val_accuracy: 0.3714\n",
      "Epoch 70/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.1905 - accuracy: 0.5624 - val_loss: 1.3576 - val_accuracy: 0.4286\n",
      "Epoch 71/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.1845 - accuracy: 0.5705 - val_loss: 1.4219 - val_accuracy: 0.4114\n",
      "Epoch 72/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.1875 - accuracy: 0.5490 - val_loss: 1.4045 - val_accuracy: 0.4171\n",
      "Epoch 73/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.1802 - accuracy: 0.5409 - val_loss: 1.3541 - val_accuracy: 0.4286\n",
      "Epoch 74/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1789 - accuracy: 0.5315 - val_loss: 1.3419 - val_accuracy: 0.4514\n",
      "Epoch 75/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1679 - accuracy: 0.5477 - val_loss: 1.3818 - val_accuracy: 0.3829\n",
      "Epoch 76/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1542 - accuracy: 0.5664 - val_loss: 1.4288 - val_accuracy: 0.3829\n",
      "Epoch 77/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1608 - accuracy: 0.5651 - val_loss: 1.3276 - val_accuracy: 0.4800\n",
      "Epoch 78/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1470 - accuracy: 0.5638 - val_loss: 1.3439 - val_accuracy: 0.4857\n",
      "Epoch 79/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1505 - accuracy: 0.5275 - val_loss: 1.3650 - val_accuracy: 0.4229\n",
      "Epoch 80/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.1520 - accuracy: 0.5678 - val_loss: 1.3434 - val_accuracy: 0.4343\n",
      "Epoch 81/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 1.1317 - accuracy: 0.5678 - val_loss: 1.4098 - val_accuracy: 0.4057\n",
      "Epoch 82/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 1.1327 - accuracy: 0.5718 - val_loss: 1.3778 - val_accuracy: 0.4286\n",
      "Epoch 83/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1290 - accuracy: 0.5611 - val_loss: 1.3403 - val_accuracy: 0.4229\n",
      "Epoch 84/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1333 - accuracy: 0.5611 - val_loss: 1.3470 - val_accuracy: 0.4114\n",
      "Epoch 85/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1245 - accuracy: 0.5490 - val_loss: 1.3571 - val_accuracy: 0.4286\n",
      "Epoch 86/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.1211 - accuracy: 0.5597 - val_loss: 1.3239 - val_accuracy: 0.4286\n",
      "Epoch 87/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1181 - accuracy: 0.5705 - val_loss: 1.3204 - val_accuracy: 0.4571\n",
      "Epoch 88/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1165 - accuracy: 0.5664 - val_loss: 1.4009 - val_accuracy: 0.3829\n",
      "Epoch 89/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.1074 - accuracy: 0.5785 - val_loss: 1.3610 - val_accuracy: 0.4286\n",
      "Epoch 90/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 1.1059 - accuracy: 0.5624 - val_loss: 1.3457 - val_accuracy: 0.4457\n",
      "Epoch 91/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0984 - accuracy: 0.5678 - val_loss: 1.3164 - val_accuracy: 0.4800\n",
      "Epoch 92/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0910 - accuracy: 0.5785 - val_loss: 1.3252 - val_accuracy: 0.4457\n",
      "Epoch 93/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.0875 - accuracy: 0.5772 - val_loss: 1.3134 - val_accuracy: 0.4571\n",
      "Epoch 94/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.0900 - accuracy: 0.5718 - val_loss: 1.3907 - val_accuracy: 0.4343\n",
      "Epoch 95/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0907 - accuracy: 0.5852 - val_loss: 1.4051 - val_accuracy: 0.3829\n",
      "Epoch 96/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0748 - accuracy: 0.5893 - val_loss: 1.3131 - val_accuracy: 0.4629\n",
      "Epoch 97/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 1.0810 - accuracy: 0.5772 - val_loss: 1.2904 - val_accuracy: 0.4686\n",
      "Epoch 98/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0702 - accuracy: 0.5919 - val_loss: 1.3041 - val_accuracy: 0.4457\n",
      "Epoch 99/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0721 - accuracy: 0.5960 - val_loss: 1.3330 - val_accuracy: 0.4286\n",
      "Epoch 100/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0691 - accuracy: 0.5732 - val_loss: 1.3236 - val_accuracy: 0.4400\n",
      "Epoch 101/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0656 - accuracy: 0.5960 - val_loss: 1.3775 - val_accuracy: 0.3829\n",
      "Epoch 102/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0608 - accuracy: 0.5718 - val_loss: 1.3422 - val_accuracy: 0.4457\n",
      "Epoch 103/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0554 - accuracy: 0.5826 - val_loss: 1.3213 - val_accuracy: 0.4800\n",
      "Epoch 104/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0529 - accuracy: 0.5785 - val_loss: 1.3668 - val_accuracy: 0.4000\n",
      "Epoch 105/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0456 - accuracy: 0.6094 - val_loss: 1.3086 - val_accuracy: 0.4457\n",
      "Epoch 106/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0419 - accuracy: 0.6000 - val_loss: 1.2847 - val_accuracy: 0.4571\n",
      "Epoch 107/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0362 - accuracy: 0.5973 - val_loss: 1.4167 - val_accuracy: 0.4286\n",
      "Epoch 108/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0418 - accuracy: 0.6000 - val_loss: 1.3045 - val_accuracy: 0.4514\n",
      "Epoch 109/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 1.0436 - accuracy: 0.5812 - val_loss: 1.2737 - val_accuracy: 0.4857\n",
      "Epoch 110/700\n",
      "745/745 [==============================] - 10s 13ms/step - loss: 1.0406 - accuracy: 0.5919 - val_loss: 1.3291 - val_accuracy: 0.4343\n",
      "Epoch 111/700\n",
      "745/745 [==============================] - 12s 16ms/step - loss: 1.0277 - accuracy: 0.6027 - val_loss: 1.3596 - val_accuracy: 0.4171\n",
      "Epoch 112/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0336 - accuracy: 0.6027 - val_loss: 1.2961 - val_accuracy: 0.4514\n",
      "Epoch 113/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 1.0243 - accuracy: 0.6148 - val_loss: 1.2789 - val_accuracy: 0.4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0225 - accuracy: 0.6148 - val_loss: 1.2849 - val_accuracy: 0.4800\n",
      "Epoch 115/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 1.0194 - accuracy: 0.6054 - val_loss: 1.2742 - val_accuracy: 0.4743\n",
      "Epoch 116/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0142 - accuracy: 0.5919 - val_loss: 1.3035 - val_accuracy: 0.4286\n",
      "Epoch 117/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0123 - accuracy: 0.5960 - val_loss: 1.3050 - val_accuracy: 0.4514\n",
      "Epoch 118/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0135 - accuracy: 0.6161 - val_loss: 1.2719 - val_accuracy: 0.4857\n",
      "Epoch 119/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 1.0081 - accuracy: 0.6215 - val_loss: 1.2944 - val_accuracy: 0.4571\n",
      "Epoch 120/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0149 - accuracy: 0.6027 - val_loss: 1.2860 - val_accuracy: 0.4457\n",
      "Epoch 121/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 1.0015 - accuracy: 0.5946 - val_loss: 1.2391 - val_accuracy: 0.5029\n",
      "Epoch 122/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.0069 - accuracy: 0.6054 - val_loss: 1.2676 - val_accuracy: 0.4629\n",
      "Epoch 123/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.0023 - accuracy: 0.5960 - val_loss: 1.3269 - val_accuracy: 0.4400\n",
      "Epoch 124/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 1.0062 - accuracy: 0.6148 - val_loss: 1.2705 - val_accuracy: 0.5086\n",
      "Epoch 125/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9954 - accuracy: 0.6174 - val_loss: 1.3759 - val_accuracy: 0.4057\n",
      "Epoch 126/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9794 - accuracy: 0.6148 - val_loss: 1.3247 - val_accuracy: 0.4400\n",
      "Epoch 127/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.9910 - accuracy: 0.6201 - val_loss: 1.3579 - val_accuracy: 0.4057\n",
      "Epoch 128/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9804 - accuracy: 0.6389 - val_loss: 1.3481 - val_accuracy: 0.3829\n",
      "Epoch 129/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9880 - accuracy: 0.6027 - val_loss: 1.2584 - val_accuracy: 0.4686\n",
      "Epoch 130/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9793 - accuracy: 0.6161 - val_loss: 1.3228 - val_accuracy: 0.4057\n",
      "Epoch 131/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9803 - accuracy: 0.6107 - val_loss: 1.3337 - val_accuracy: 0.3886\n",
      "Epoch 132/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9731 - accuracy: 0.6349 - val_loss: 1.3205 - val_accuracy: 0.4457\n",
      "Epoch 133/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9765 - accuracy: 0.6322 - val_loss: 1.3292 - val_accuracy: 0.4171\n",
      "Epoch 134/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.9746 - accuracy: 0.6215 - val_loss: 1.2577 - val_accuracy: 0.4857\n",
      "Epoch 135/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.9764 - accuracy: 0.6255 - val_loss: 1.2684 - val_accuracy: 0.4514\n",
      "Epoch 136/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9693 - accuracy: 0.6228 - val_loss: 1.2623 - val_accuracy: 0.4800\n",
      "Epoch 137/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.9715 - accuracy: 0.6282 - val_loss: 1.2652 - val_accuracy: 0.4800\n",
      "Epoch 138/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9715 - accuracy: 0.6255 - val_loss: 1.3797 - val_accuracy: 0.3657\n",
      "Epoch 139/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9587 - accuracy: 0.6188 - val_loss: 1.2580 - val_accuracy: 0.4743\n",
      "Epoch 140/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9597 - accuracy: 0.6336 - val_loss: 1.3363 - val_accuracy: 0.4571\n",
      "Epoch 141/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.9507 - accuracy: 0.6295 - val_loss: 1.3394 - val_accuracy: 0.4400\n",
      "Epoch 142/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9680 - accuracy: 0.6309 - val_loss: 1.2728 - val_accuracy: 0.4629\n",
      "Epoch 143/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9550 - accuracy: 0.6282 - val_loss: 1.2291 - val_accuracy: 0.5086\n",
      "Epoch 144/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9604 - accuracy: 0.6322 - val_loss: 1.2484 - val_accuracy: 0.4743\n",
      "Epoch 145/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9463 - accuracy: 0.6322 - val_loss: 1.2701 - val_accuracy: 0.4343\n",
      "Epoch 146/700\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 0.9435 - accuracy: 0.6430 - val_loss: 1.2695 - val_accuracy: 0.4629\n",
      "Epoch 147/700\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 0.9436 - accuracy: 0.6322 - val_loss: 1.3165 - val_accuracy: 0.4571\n",
      "Epoch 148/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.9423 - accuracy: 0.6282 - val_loss: 1.2518 - val_accuracy: 0.4914\n",
      "Epoch 149/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9413 - accuracy: 0.6107 - val_loss: 1.2237 - val_accuracy: 0.4857\n",
      "Epoch 150/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9346 - accuracy: 0.6322 - val_loss: 1.3088 - val_accuracy: 0.4171\n",
      "Epoch 151/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9357 - accuracy: 0.6295 - val_loss: 1.2872 - val_accuracy: 0.4800\n",
      "Epoch 152/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9383 - accuracy: 0.6362 - val_loss: 1.3203 - val_accuracy: 0.4171\n",
      "Epoch 153/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9312 - accuracy: 0.6201 - val_loss: 1.2980 - val_accuracy: 0.4229\n",
      "Epoch 154/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9394 - accuracy: 0.6349 - val_loss: 1.2831 - val_accuracy: 0.4571\n",
      "Epoch 155/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9312 - accuracy: 0.6443 - val_loss: 1.2725 - val_accuracy: 0.4686\n",
      "Epoch 156/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9237 - accuracy: 0.6416 - val_loss: 1.3308 - val_accuracy: 0.4514\n",
      "Epoch 157/700\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 0.9301 - accuracy: 0.6282 - val_loss: 1.2765 - val_accuracy: 0.4286\n",
      "Epoch 158/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9146 - accuracy: 0.6617 - val_loss: 1.3341 - val_accuracy: 0.4171\n",
      "Epoch 159/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9333 - accuracy: 0.6389 - val_loss: 1.2428 - val_accuracy: 0.4914\n",
      "Epoch 160/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9026 - accuracy: 0.6617 - val_loss: 1.3210 - val_accuracy: 0.4743\n",
      "Epoch 161/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9232 - accuracy: 0.6510 - val_loss: 1.3189 - val_accuracy: 0.4229\n",
      "Epoch 162/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9232 - accuracy: 0.6483 - val_loss: 1.2373 - val_accuracy: 0.4971\n",
      "Epoch 163/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9171 - accuracy: 0.6658 - val_loss: 1.3121 - val_accuracy: 0.4229\n",
      "Epoch 164/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9188 - accuracy: 0.6483 - val_loss: 1.3660 - val_accuracy: 0.4171\n",
      "Epoch 165/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9163 - accuracy: 0.6376 - val_loss: 1.2503 - val_accuracy: 0.4800\n",
      "Epoch 166/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.8972 - accuracy: 0.6631 - val_loss: 1.3086 - val_accuracy: 0.3943\n",
      "Epoch 167/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.9037 - accuracy: 0.6577 - val_loss: 1.2620 - val_accuracy: 0.4629\n",
      "Epoch 168/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9119 - accuracy: 0.6523 - val_loss: 1.2993 - val_accuracy: 0.4629\n",
      "Epoch 169/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9114 - accuracy: 0.6349 - val_loss: 1.2469 - val_accuracy: 0.4914\n",
      "Epoch 170/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 6s 8ms/step - loss: 0.9052 - accuracy: 0.6349 - val_loss: 1.3344 - val_accuracy: 0.4400\n",
      "Epoch 171/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.9034 - accuracy: 0.6604 - val_loss: 1.2477 - val_accuracy: 0.4571\n",
      "Epoch 172/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.8976 - accuracy: 0.6510 - val_loss: 1.2281 - val_accuracy: 0.4743\n",
      "Epoch 173/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8942 - accuracy: 0.6564 - val_loss: 1.3229 - val_accuracy: 0.4229\n",
      "Epoch 174/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8904 - accuracy: 0.6537 - val_loss: 1.2475 - val_accuracy: 0.4686\n",
      "Epoch 175/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.8903 - accuracy: 0.6537 - val_loss: 1.2383 - val_accuracy: 0.5086\n",
      "Epoch 176/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8868 - accuracy: 0.6604 - val_loss: 1.2825 - val_accuracy: 0.4514\n",
      "Epoch 177/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.8903 - accuracy: 0.6483 - val_loss: 1.2405 - val_accuracy: 0.4857\n",
      "Epoch 178/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8796 - accuracy: 0.6738 - val_loss: 1.2790 - val_accuracy: 0.4457\n",
      "Epoch 179/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8854 - accuracy: 0.6658 - val_loss: 1.2680 - val_accuracy: 0.4457\n",
      "Epoch 180/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.8866 - accuracy: 0.6631 - val_loss: 1.3075 - val_accuracy: 0.4686\n",
      "Epoch 181/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.8790 - accuracy: 0.6725 - val_loss: 1.3827 - val_accuracy: 0.4571\n",
      "Epoch 182/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.8804 - accuracy: 0.6658 - val_loss: 1.2237 - val_accuracy: 0.5143\n",
      "Epoch 183/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.8791 - accuracy: 0.6617 - val_loss: 1.2433 - val_accuracy: 0.5086\n",
      "Epoch 184/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8777 - accuracy: 0.6523 - val_loss: 1.2580 - val_accuracy: 0.4629\n",
      "Epoch 185/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8803 - accuracy: 0.6591 - val_loss: 1.2638 - val_accuracy: 0.4971\n",
      "Epoch 186/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8702 - accuracy: 0.6537 - val_loss: 1.2538 - val_accuracy: 0.4629\n",
      "Epoch 187/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.8752 - accuracy: 0.6792 - val_loss: 1.2150 - val_accuracy: 0.4743\n",
      "Epoch 188/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8767 - accuracy: 0.6805 - val_loss: 1.2341 - val_accuracy: 0.4743\n",
      "Epoch 189/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8677 - accuracy: 0.6711 - val_loss: 1.2321 - val_accuracy: 0.4686\n",
      "Epoch 190/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8660 - accuracy: 0.6819 - val_loss: 1.2532 - val_accuracy: 0.4743\n",
      "Epoch 191/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8676 - accuracy: 0.6779 - val_loss: 1.2391 - val_accuracy: 0.4629\n",
      "Epoch 192/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8618 - accuracy: 0.6698 - val_loss: 1.2130 - val_accuracy: 0.5200\n",
      "Epoch 193/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.8680 - accuracy: 0.6577 - val_loss: 1.2348 - val_accuracy: 0.4971\n",
      "Epoch 194/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8560 - accuracy: 0.6859 - val_loss: 1.3123 - val_accuracy: 0.4286\n",
      "Epoch 195/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8626 - accuracy: 0.6631 - val_loss: 1.2311 - val_accuracy: 0.4857\n",
      "Epoch 196/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8558 - accuracy: 0.6644 - val_loss: 1.2411 - val_accuracy: 0.5086\n",
      "Epoch 197/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8605 - accuracy: 0.6738 - val_loss: 1.3409 - val_accuracy: 0.4286\n",
      "Epoch 198/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.8434 - accuracy: 0.6765 - val_loss: 1.2221 - val_accuracy: 0.4857\n",
      "Epoch 199/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.8429 - accuracy: 0.6792 - val_loss: 1.3246 - val_accuracy: 0.3943\n",
      "Epoch 200/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8372 - accuracy: 0.6765 - val_loss: 1.2538 - val_accuracy: 0.4514\n",
      "Epoch 201/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8557 - accuracy: 0.6711 - val_loss: 1.2121 - val_accuracy: 0.4857\n",
      "Epoch 202/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.8433 - accuracy: 0.6819 - val_loss: 1.3909 - val_accuracy: 0.4229\n",
      "Epoch 203/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8479 - accuracy: 0.6805 - val_loss: 1.2950 - val_accuracy: 0.4629\n",
      "Epoch 204/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8419 - accuracy: 0.6698 - val_loss: 1.2265 - val_accuracy: 0.4971\n",
      "Epoch 205/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8396 - accuracy: 0.6604 - val_loss: 1.2689 - val_accuracy: 0.4686\n",
      "Epoch 206/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.8379 - accuracy: 0.6859 - val_loss: 1.2764 - val_accuracy: 0.4571\n",
      "Epoch 207/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8452 - accuracy: 0.6832 - val_loss: 1.2312 - val_accuracy: 0.5314\n",
      "Epoch 208/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8354 - accuracy: 0.6779 - val_loss: 1.2255 - val_accuracy: 0.5029\n",
      "Epoch 209/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8355 - accuracy: 0.6953 - val_loss: 1.3093 - val_accuracy: 0.4229\n",
      "Epoch 210/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8312 - accuracy: 0.6886 - val_loss: 1.2639 - val_accuracy: 0.4571\n",
      "Epoch 211/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.8392 - accuracy: 0.6846 - val_loss: 1.2152 - val_accuracy: 0.5029\n",
      "Epoch 212/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8214 - accuracy: 0.6846 - val_loss: 1.2458 - val_accuracy: 0.4686\n",
      "Epoch 213/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.8250 - accuracy: 0.7060 - val_loss: 1.2623 - val_accuracy: 0.4743\n",
      "Epoch 214/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8301 - accuracy: 0.6805 - val_loss: 1.2313 - val_accuracy: 0.5143\n",
      "Epoch 215/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8279 - accuracy: 0.6819 - val_loss: 1.2367 - val_accuracy: 0.5029\n",
      "Epoch 216/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8191 - accuracy: 0.6886 - val_loss: 1.2773 - val_accuracy: 0.4800\n",
      "Epoch 217/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8281 - accuracy: 0.6846 - val_loss: 1.2568 - val_accuracy: 0.4800\n",
      "Epoch 218/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8134 - accuracy: 0.6805 - val_loss: 1.2462 - val_accuracy: 0.4914\n",
      "Epoch 219/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8140 - accuracy: 0.6993 - val_loss: 1.2909 - val_accuracy: 0.4400\n",
      "Epoch 220/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8158 - accuracy: 0.6846 - val_loss: 1.2607 - val_accuracy: 0.4514\n",
      "Epoch 221/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8083 - accuracy: 0.7154 - val_loss: 1.3198 - val_accuracy: 0.4343\n",
      "Epoch 222/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.8173 - accuracy: 0.6886 - val_loss: 1.2268 - val_accuracy: 0.4971\n",
      "Epoch 223/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8118 - accuracy: 0.7007 - val_loss: 1.2680 - val_accuracy: 0.4686\n",
      "Epoch 224/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8170 - accuracy: 0.6859 - val_loss: 1.1996 - val_accuracy: 0.4971\n",
      "Epoch 225/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8117 - accuracy: 0.6940 - val_loss: 1.2895 - val_accuracy: 0.4457\n",
      "Epoch 226/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8133 - accuracy: 0.6940 - val_loss: 1.2934 - val_accuracy: 0.4686\n",
      "Epoch 227/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7963 - accuracy: 0.7181 - val_loss: 1.3712 - val_accuracy: 0.4057\n",
      "Epoch 228/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8103 - accuracy: 0.6913 - val_loss: 1.2365 - val_accuracy: 0.4629\n",
      "Epoch 229/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.8055 - accuracy: 0.7020 - val_loss: 1.2554 - val_accuracy: 0.4800\n",
      "Epoch 230/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.7980 - accuracy: 0.6872 - val_loss: 1.3058 - val_accuracy: 0.4457\n",
      "Epoch 231/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7993 - accuracy: 0.7128 - val_loss: 1.2702 - val_accuracy: 0.4514\n",
      "Epoch 232/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7987 - accuracy: 0.7060 - val_loss: 1.4719 - val_accuracy: 0.4343\n",
      "Epoch 233/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.8053 - accuracy: 0.7020 - val_loss: 1.2605 - val_accuracy: 0.4743\n",
      "Epoch 234/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.7978 - accuracy: 0.6953 - val_loss: 1.2635 - val_accuracy: 0.4800\n",
      "Epoch 235/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7884 - accuracy: 0.6899 - val_loss: 1.3615 - val_accuracy: 0.4343\n",
      "Epoch 236/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7971 - accuracy: 0.6886 - val_loss: 1.2615 - val_accuracy: 0.4400\n",
      "Epoch 237/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7889 - accuracy: 0.7087 - val_loss: 1.3104 - val_accuracy: 0.4743\n",
      "Epoch 238/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7833 - accuracy: 0.6980 - val_loss: 1.2709 - val_accuracy: 0.4571\n",
      "Epoch 239/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7893 - accuracy: 0.6940 - val_loss: 1.3016 - val_accuracy: 0.4343\n",
      "Epoch 240/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7876 - accuracy: 0.7020 - val_loss: 1.3599 - val_accuracy: 0.4343\n",
      "Epoch 241/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7858 - accuracy: 0.7047 - val_loss: 1.2963 - val_accuracy: 0.4571\n",
      "Epoch 242/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.7771 - accuracy: 0.7007 - val_loss: 1.2519 - val_accuracy: 0.4857\n",
      "Epoch 243/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7861 - accuracy: 0.6993 - val_loss: 1.2391 - val_accuracy: 0.4857\n",
      "Epoch 244/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7856 - accuracy: 0.6913 - val_loss: 1.2397 - val_accuracy: 0.4457\n",
      "Epoch 245/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7823 - accuracy: 0.7114 - val_loss: 1.2642 - val_accuracy: 0.4286\n",
      "Epoch 246/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7681 - accuracy: 0.6993 - val_loss: 1.3341 - val_accuracy: 0.4800\n",
      "Epoch 247/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7761 - accuracy: 0.7101 - val_loss: 1.3053 - val_accuracy: 0.4343\n",
      "Epoch 248/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7755 - accuracy: 0.7087 - val_loss: 1.2378 - val_accuracy: 0.4743\n",
      "Epoch 249/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7652 - accuracy: 0.7047 - val_loss: 1.3033 - val_accuracy: 0.4686\n",
      "Epoch 250/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7765 - accuracy: 0.7087 - val_loss: 1.3023 - val_accuracy: 0.4286\n",
      "Epoch 251/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7600 - accuracy: 0.7195 - val_loss: 1.2222 - val_accuracy: 0.4629\n",
      "Epoch 252/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.7751 - accuracy: 0.7074 - val_loss: 1.2550 - val_accuracy: 0.4343\n",
      "Epoch 253/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7658 - accuracy: 0.7235 - val_loss: 1.2793 - val_accuracy: 0.4743\n",
      "Epoch 254/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7652 - accuracy: 0.7087 - val_loss: 1.2268 - val_accuracy: 0.4857\n",
      "Epoch 255/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7632 - accuracy: 0.7060 - val_loss: 1.3116 - val_accuracy: 0.4743\n",
      "Epoch 256/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7622 - accuracy: 0.7101 - val_loss: 1.3422 - val_accuracy: 0.4286\n",
      "Epoch 257/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7656 - accuracy: 0.7141 - val_loss: 1.3588 - val_accuracy: 0.4800\n",
      "Epoch 258/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7469 - accuracy: 0.7195 - val_loss: 1.2373 - val_accuracy: 0.5029\n",
      "Epoch 259/700\n",
      "745/745 [==============================] - 11s 15ms/step - loss: 0.7600 - accuracy: 0.7141 - val_loss: 1.2454 - val_accuracy: 0.4571\n",
      "Epoch 260/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7499 - accuracy: 0.7315 - val_loss: 1.2277 - val_accuracy: 0.5029\n",
      "Epoch 261/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7553 - accuracy: 0.7289 - val_loss: 1.2678 - val_accuracy: 0.4800\n",
      "Epoch 262/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7640 - accuracy: 0.7128 - val_loss: 1.2819 - val_accuracy: 0.4343\n",
      "Epoch 263/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7503 - accuracy: 0.7221 - val_loss: 1.3061 - val_accuracy: 0.4743\n",
      "Epoch 264/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7482 - accuracy: 0.7315 - val_loss: 1.3296 - val_accuracy: 0.4286\n",
      "Epoch 265/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7441 - accuracy: 0.7181 - val_loss: 1.3540 - val_accuracy: 0.4286\n",
      "Epoch 266/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7566 - accuracy: 0.7114 - val_loss: 1.2453 - val_accuracy: 0.4971\n",
      "Epoch 267/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7305 - accuracy: 0.7168 - val_loss: 1.2654 - val_accuracy: 0.4743\n",
      "Epoch 268/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7311 - accuracy: 0.7235 - val_loss: 1.2857 - val_accuracy: 0.4743\n",
      "Epoch 269/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7510 - accuracy: 0.7235 - val_loss: 1.2720 - val_accuracy: 0.4743\n",
      "Epoch 270/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7399 - accuracy: 0.7101 - val_loss: 1.2402 - val_accuracy: 0.5257\n",
      "Epoch 271/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.7455 - accuracy: 0.7235 - val_loss: 1.3427 - val_accuracy: 0.4286\n",
      "Epoch 272/700\n",
      "745/745 [==============================] - 10s 13ms/step - loss: 0.7339 - accuracy: 0.7248 - val_loss: 1.2460 - val_accuracy: 0.4914\n",
      "Epoch 273/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 0.7327 - accuracy: 0.7342 - val_loss: 1.3392 - val_accuracy: 0.4171\n",
      "Epoch 274/700\n",
      "745/745 [==============================] - 9s 11ms/step - loss: 0.7402 - accuracy: 0.7315 - val_loss: 1.3371 - val_accuracy: 0.4686\n",
      "Epoch 275/700\n",
      "745/745 [==============================] - 9s 12ms/step - loss: 0.7358 - accuracy: 0.7128 - val_loss: 1.2506 - val_accuracy: 0.4343\n",
      "Epoch 276/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.7265 - accuracy: 0.7383 - val_loss: 1.2399 - val_accuracy: 0.4857\n",
      "Epoch 277/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.7315 - accuracy: 0.7356 - val_loss: 1.2585 - val_accuracy: 0.4571\n",
      "Epoch 278/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.7318 - accuracy: 0.7181 - val_loss: 1.2947 - val_accuracy: 0.4629\n",
      "Epoch 279/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7226 - accuracy: 0.7329 - val_loss: 1.2355 - val_accuracy: 0.4800\n",
      "Epoch 280/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7321 - accuracy: 0.7275 - val_loss: 1.3531 - val_accuracy: 0.4743\n",
      "Epoch 281/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7248 - accuracy: 0.7356 - val_loss: 1.3677 - val_accuracy: 0.4686\n",
      "Epoch 282/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7265 - accuracy: 0.7181 - val_loss: 1.3189 - val_accuracy: 0.4114\n",
      "Epoch 283/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7172 - accuracy: 0.7248 - val_loss: 1.2746 - val_accuracy: 0.5143\n",
      "Epoch 284/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7178 - accuracy: 0.7302 - val_loss: 1.2628 - val_accuracy: 0.4457\n",
      "Epoch 285/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7253 - accuracy: 0.7262 - val_loss: 1.2547 - val_accuracy: 0.4457\n",
      "Epoch 286/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7210 - accuracy: 0.7248 - val_loss: 1.2886 - val_accuracy: 0.4343\n",
      "Epoch 287/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7186 - accuracy: 0.7356 - val_loss: 1.2640 - val_accuracy: 0.4629\n",
      "Epoch 288/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7054 - accuracy: 0.7329 - val_loss: 1.3341 - val_accuracy: 0.4514\n",
      "Epoch 289/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7156 - accuracy: 0.7235 - val_loss: 1.2954 - val_accuracy: 0.4400\n",
      "Epoch 290/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7078 - accuracy: 0.7383 - val_loss: 1.3100 - val_accuracy: 0.4343\n",
      "Epoch 291/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7095 - accuracy: 0.7289 - val_loss: 1.2618 - val_accuracy: 0.4914\n",
      "Epoch 292/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6972 - accuracy: 0.7409 - val_loss: 1.3098 - val_accuracy: 0.4457\n",
      "Epoch 293/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.7010 - accuracy: 0.7383 - val_loss: 1.2599 - val_accuracy: 0.4514\n",
      "Epoch 294/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7046 - accuracy: 0.7383 - val_loss: 1.3955 - val_accuracy: 0.4457\n",
      "Epoch 295/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.7038 - accuracy: 0.7262 - val_loss: 1.3154 - val_accuracy: 0.4686\n",
      "Epoch 296/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7102 - accuracy: 0.7369 - val_loss: 1.2775 - val_accuracy: 0.4743\n",
      "Epoch 297/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.7032 - accuracy: 0.7383 - val_loss: 1.3311 - val_accuracy: 0.4514\n",
      "Epoch 298/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6927 - accuracy: 0.7302 - val_loss: 1.2821 - val_accuracy: 0.4800\n",
      "Epoch 299/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.7017 - accuracy: 0.7503 - val_loss: 1.2484 - val_accuracy: 0.4857\n",
      "Epoch 300/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.6985 - accuracy: 0.7383 - val_loss: 1.2297 - val_accuracy: 0.5086\n",
      "Epoch 301/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6961 - accuracy: 0.7490 - val_loss: 1.4326 - val_accuracy: 0.4571\n",
      "Epoch 302/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6915 - accuracy: 0.7436 - val_loss: 1.3433 - val_accuracy: 0.4457\n",
      "Epoch 303/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6949 - accuracy: 0.7517 - val_loss: 1.4236 - val_accuracy: 0.4686\n",
      "Epoch 304/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6965 - accuracy: 0.7436 - val_loss: 1.3471 - val_accuracy: 0.4800\n",
      "Epoch 305/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6944 - accuracy: 0.7423 - val_loss: 1.2850 - val_accuracy: 0.4571\n",
      "Epoch 306/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6870 - accuracy: 0.7436 - val_loss: 1.3303 - val_accuracy: 0.4800\n",
      "Epoch 307/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6884 - accuracy: 0.7490 - val_loss: 1.3373 - val_accuracy: 0.4914\n",
      "Epoch 308/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6928 - accuracy: 0.7409 - val_loss: 1.3804 - val_accuracy: 0.4286\n",
      "Epoch 309/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6846 - accuracy: 0.7369 - val_loss: 1.3122 - val_accuracy: 0.4286\n",
      "Epoch 310/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6846 - accuracy: 0.7342 - val_loss: 1.4019 - val_accuracy: 0.4743\n",
      "Epoch 311/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6841 - accuracy: 0.7383 - val_loss: 1.2778 - val_accuracy: 0.5143\n",
      "Epoch 312/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.6819 - accuracy: 0.7544 - val_loss: 1.3219 - val_accuracy: 0.4857\n",
      "Epoch 313/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6784 - accuracy: 0.7517 - val_loss: 1.3055 - val_accuracy: 0.4629\n",
      "Epoch 314/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6786 - accuracy: 0.7436 - val_loss: 1.2925 - val_accuracy: 0.4800\n",
      "Epoch 315/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.6699 - accuracy: 0.7584 - val_loss: 1.3381 - val_accuracy: 0.4571\n",
      "Epoch 316/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6817 - accuracy: 0.7396 - val_loss: 1.3182 - val_accuracy: 0.4686\n",
      "Epoch 317/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6721 - accuracy: 0.7544 - val_loss: 1.3679 - val_accuracy: 0.4114\n",
      "Epoch 318/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6799 - accuracy: 0.7503 - val_loss: 1.3054 - val_accuracy: 0.4457\n",
      "Epoch 319/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6610 - accuracy: 0.7570 - val_loss: 1.3167 - val_accuracy: 0.4286\n",
      "Epoch 320/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6653 - accuracy: 0.7651 - val_loss: 1.2606 - val_accuracy: 0.4800\n",
      "Epoch 321/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6722 - accuracy: 0.7450 - val_loss: 1.2565 - val_accuracy: 0.4686\n",
      "Epoch 322/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6583 - accuracy: 0.7651 - val_loss: 1.3578 - val_accuracy: 0.4686\n",
      "Epoch 323/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6573 - accuracy: 0.7732 - val_loss: 1.2635 - val_accuracy: 0.4971\n",
      "Epoch 324/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6591 - accuracy: 0.7517 - val_loss: 1.3003 - val_accuracy: 0.4971\n",
      "Epoch 325/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6559 - accuracy: 0.7624 - val_loss: 1.2793 - val_accuracy: 0.4629\n",
      "Epoch 326/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6545 - accuracy: 0.7570 - val_loss: 1.3128 - val_accuracy: 0.4629\n",
      "Epoch 327/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6670 - accuracy: 0.7651 - val_loss: 1.2714 - val_accuracy: 0.4571\n",
      "Epoch 328/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6529 - accuracy: 0.7651 - val_loss: 1.2991 - val_accuracy: 0.4743\n",
      "Epoch 329/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6574 - accuracy: 0.7638 - val_loss: 1.3306 - val_accuracy: 0.4686\n",
      "Epoch 330/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6527 - accuracy: 0.7490 - val_loss: 1.2719 - val_accuracy: 0.4914\n",
      "Epoch 331/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.6518 - accuracy: 0.7570 - val_loss: 1.2798 - val_accuracy: 0.4629\n",
      "Epoch 332/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6473 - accuracy: 0.7705 - val_loss: 1.3371 - val_accuracy: 0.4286\n",
      "Epoch 333/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6471 - accuracy: 0.7584 - val_loss: 1.3224 - val_accuracy: 0.4629\n",
      "Epoch 334/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6435 - accuracy: 0.7651 - val_loss: 1.4138 - val_accuracy: 0.4686\n",
      "Epoch 335/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6513 - accuracy: 0.7611 - val_loss: 1.2870 - val_accuracy: 0.4857\n",
      "Epoch 336/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.6454 - accuracy: 0.7503 - val_loss: 1.3231 - val_accuracy: 0.4686\n",
      "Epoch 337/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6511 - accuracy: 0.7638 - val_loss: 1.2591 - val_accuracy: 0.4857\n",
      "Epoch 338/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6353 - accuracy: 0.7651 - val_loss: 1.3198 - val_accuracy: 0.4629\n",
      "Epoch 339/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6543 - accuracy: 0.7517 - val_loss: 1.2808 - val_accuracy: 0.4800\n",
      "Epoch 340/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6409 - accuracy: 0.7691 - val_loss: 1.3150 - val_accuracy: 0.4800\n",
      "Epoch 341/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.6389 - accuracy: 0.7664 - val_loss: 1.3260 - val_accuracy: 0.4914\n",
      "Epoch 342/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6265 - accuracy: 0.7624 - val_loss: 1.3286 - val_accuracy: 0.4857\n",
      "Epoch 343/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6392 - accuracy: 0.7758 - val_loss: 1.2670 - val_accuracy: 0.4914\n",
      "Epoch 344/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6254 - accuracy: 0.7664 - val_loss: 1.3020 - val_accuracy: 0.4914\n",
      "Epoch 345/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6369 - accuracy: 0.7718 - val_loss: 1.3087 - val_accuracy: 0.4514\n",
      "Epoch 346/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6289 - accuracy: 0.7651 - val_loss: 1.2601 - val_accuracy: 0.4857\n",
      "Epoch 347/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6220 - accuracy: 0.7745 - val_loss: 1.2508 - val_accuracy: 0.5086\n",
      "Epoch 348/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6259 - accuracy: 0.7450 - val_loss: 1.3627 - val_accuracy: 0.4800\n",
      "Epoch 349/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6256 - accuracy: 0.7638 - val_loss: 1.2886 - val_accuracy: 0.4857\n",
      "Epoch 350/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6278 - accuracy: 0.7745 - val_loss: 1.3670 - val_accuracy: 0.4400\n",
      "Epoch 351/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6186 - accuracy: 0.7772 - val_loss: 1.3566 - val_accuracy: 0.4400\n",
      "Epoch 352/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6196 - accuracy: 0.7799 - val_loss: 1.3340 - val_accuracy: 0.4400\n",
      "Epoch 353/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.6255 - accuracy: 0.7745 - val_loss: 1.3291 - val_accuracy: 0.4800\n",
      "Epoch 354/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6161 - accuracy: 0.7826 - val_loss: 1.3578 - val_accuracy: 0.4571\n",
      "Epoch 355/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6275 - accuracy: 0.7919 - val_loss: 1.3045 - val_accuracy: 0.4514\n",
      "Epoch 356/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6135 - accuracy: 0.7718 - val_loss: 1.3367 - val_accuracy: 0.4743\n",
      "Epoch 357/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6150 - accuracy: 0.7866 - val_loss: 1.3262 - val_accuracy: 0.4629\n",
      "Epoch 358/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6231 - accuracy: 0.7651 - val_loss: 1.3243 - val_accuracy: 0.4743\n",
      "Epoch 359/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6127 - accuracy: 0.7839 - val_loss: 1.3437 - val_accuracy: 0.4286\n",
      "Epoch 360/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6119 - accuracy: 0.7785 - val_loss: 1.2976 - val_accuracy: 0.4971\n",
      "Epoch 361/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.6117 - accuracy: 0.7718 - val_loss: 1.3435 - val_accuracy: 0.4514\n",
      "Epoch 362/700\n",
      "745/745 [==============================] - 9s 13ms/step - loss: 0.6087 - accuracy: 0.7852 - val_loss: 1.3243 - val_accuracy: 0.5143\n",
      "Epoch 363/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 0.6053 - accuracy: 0.7879 - val_loss: 1.3229 - val_accuracy: 0.4286\n",
      "Epoch 364/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5989 - accuracy: 0.7906 - val_loss: 1.3067 - val_accuracy: 0.5086\n",
      "Epoch 365/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6120 - accuracy: 0.7705 - val_loss: 1.3168 - val_accuracy: 0.4571\n",
      "Epoch 366/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6079 - accuracy: 0.7772 - val_loss: 1.3900 - val_accuracy: 0.4400\n",
      "Epoch 367/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5982 - accuracy: 0.7893 - val_loss: 1.2942 - val_accuracy: 0.4800\n",
      "Epoch 368/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5978 - accuracy: 0.7691 - val_loss: 1.3355 - val_accuracy: 0.4686\n",
      "Epoch 369/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.6093 - accuracy: 0.7772 - val_loss: 1.3298 - val_accuracy: 0.4571\n",
      "Epoch 370/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.6015 - accuracy: 0.7866 - val_loss: 1.3384 - val_accuracy: 0.4743\n",
      "Epoch 371/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.5947 - accuracy: 0.7812 - val_loss: 1.3298 - val_accuracy: 0.4629\n",
      "Epoch 372/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.5922 - accuracy: 0.7812 - val_loss: 1.4032 - val_accuracy: 0.4286\n",
      "Epoch 373/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5926 - accuracy: 0.7919 - val_loss: 1.3798 - val_accuracy: 0.4400\n",
      "Epoch 374/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5932 - accuracy: 0.7866 - val_loss: 1.2761 - val_accuracy: 0.4971\n",
      "Epoch 375/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5964 - accuracy: 0.7826 - val_loss: 1.4040 - val_accuracy: 0.4629\n",
      "Epoch 376/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.5935 - accuracy: 0.7839 - val_loss: 1.3277 - val_accuracy: 0.4800\n",
      "Epoch 377/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.5964 - accuracy: 0.7826 - val_loss: 1.3717 - val_accuracy: 0.4686\n",
      "Epoch 378/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5841 - accuracy: 0.7906 - val_loss: 1.3098 - val_accuracy: 0.4343\n",
      "Epoch 379/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5910 - accuracy: 0.8000 - val_loss: 1.3895 - val_accuracy: 0.4743\n",
      "Epoch 380/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.5876 - accuracy: 0.7919 - val_loss: 1.2911 - val_accuracy: 0.4800\n",
      "Epoch 381/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5829 - accuracy: 0.7919 - val_loss: 1.3835 - val_accuracy: 0.4686\n",
      "Epoch 382/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5762 - accuracy: 0.7987 - val_loss: 1.3537 - val_accuracy: 0.4229\n",
      "Epoch 383/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5817 - accuracy: 0.8000 - val_loss: 1.3093 - val_accuracy: 0.5086\n",
      "Epoch 384/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5810 - accuracy: 0.7946 - val_loss: 1.4271 - val_accuracy: 0.4286\n",
      "Epoch 385/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5852 - accuracy: 0.7812 - val_loss: 1.2686 - val_accuracy: 0.4743\n",
      "Epoch 386/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5758 - accuracy: 0.7960 - val_loss: 1.3474 - val_accuracy: 0.4857\n",
      "Epoch 387/700\n",
      "745/745 [==============================] - 9s 12ms/step - loss: 0.5755 - accuracy: 0.7946 - val_loss: 1.3013 - val_accuracy: 0.5086\n",
      "Epoch 388/700\n",
      "745/745 [==============================] - 8s 10ms/step - loss: 0.5721 - accuracy: 0.8000 - val_loss: 1.3011 - val_accuracy: 0.5086\n",
      "Epoch 389/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.5748 - accuracy: 0.7933 - val_loss: 1.4579 - val_accuracy: 0.4400\n",
      "Epoch 390/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.5721 - accuracy: 0.7919 - val_loss: 1.3070 - val_accuracy: 0.4457\n",
      "Epoch 391/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.5691 - accuracy: 0.7987 - val_loss: 1.3105 - val_accuracy: 0.4743\n",
      "Epoch 392/700\n",
      "745/745 [==============================] - 8s 10ms/step - loss: 0.5716 - accuracy: 0.7799 - val_loss: 1.2950 - val_accuracy: 0.4571\n",
      "Epoch 393/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5770 - accuracy: 0.7919 - val_loss: 1.3134 - val_accuracy: 0.4629\n",
      "Epoch 394/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5523 - accuracy: 0.8094 - val_loss: 1.3748 - val_accuracy: 0.4629\n",
      "Epoch 395/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5603 - accuracy: 0.8027 - val_loss: 1.3296 - val_accuracy: 0.4343\n",
      "Epoch 396/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5697 - accuracy: 0.7946 - val_loss: 1.3928 - val_accuracy: 0.4686\n",
      "Epoch 397/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5676 - accuracy: 0.8067 - val_loss: 1.3713 - val_accuracy: 0.4571\n",
      "Epoch 398/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5623 - accuracy: 0.7973 - val_loss: 1.2908 - val_accuracy: 0.5029\n",
      "Epoch 399/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5507 - accuracy: 0.8040 - val_loss: 1.3320 - val_accuracy: 0.4857\n",
      "Epoch 400/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.5611 - accuracy: 0.7919 - val_loss: 1.2902 - val_accuracy: 0.4857\n",
      "Epoch 401/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5509 - accuracy: 0.8054 - val_loss: 1.5129 - val_accuracy: 0.4171\n",
      "Epoch 402/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5571 - accuracy: 0.7960 - val_loss: 1.3639 - val_accuracy: 0.4686\n",
      "Epoch 403/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5542 - accuracy: 0.8121 - val_loss: 1.4375 - val_accuracy: 0.4571\n",
      "Epoch 404/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.5498 - accuracy: 0.8013 - val_loss: 1.3309 - val_accuracy: 0.4800\n",
      "Epoch 405/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5485 - accuracy: 0.7973 - val_loss: 1.3375 - val_accuracy: 0.4400\n",
      "Epoch 406/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5554 - accuracy: 0.8054 - val_loss: 1.3835 - val_accuracy: 0.4629\n",
      "Epoch 407/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5466 - accuracy: 0.7960 - val_loss: 1.4078 - val_accuracy: 0.4571\n",
      "Epoch 408/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5356 - accuracy: 0.8148 - val_loss: 1.2912 - val_accuracy: 0.5086\n",
      "Epoch 409/700\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 0.5473 - accuracy: 0.8121 - val_loss: 1.3520 - val_accuracy: 0.4914\n",
      "Epoch 410/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5456 - accuracy: 0.8148 - val_loss: 1.2838 - val_accuracy: 0.5086\n",
      "Epoch 411/700\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 0.5451 - accuracy: 0.8107 - val_loss: 1.3271 - val_accuracy: 0.4629\n",
      "Epoch 412/700\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 0.5472 - accuracy: 0.7960 - val_loss: 1.4182 - val_accuracy: 0.4171\n",
      "Epoch 413/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5434 - accuracy: 0.8000 - val_loss: 1.4314 - val_accuracy: 0.4686\n",
      "Epoch 414/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5343 - accuracy: 0.8094 - val_loss: 1.3052 - val_accuracy: 0.5086\n",
      "Epoch 415/700\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 0.5513 - accuracy: 0.8054 - val_loss: 1.3904 - val_accuracy: 0.4171\n",
      "Epoch 416/700\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 0.5429 - accuracy: 0.8148 - val_loss: 1.3349 - val_accuracy: 0.4629\n",
      "Epoch 417/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5380 - accuracy: 0.8174 - val_loss: 1.3437 - val_accuracy: 0.4400\n",
      "Epoch 418/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5310 - accuracy: 0.8121 - val_loss: 1.3734 - val_accuracy: 0.4514\n",
      "Epoch 419/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5349 - accuracy: 0.8188 - val_loss: 1.3613 - val_accuracy: 0.4686\n",
      "Epoch 420/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5339 - accuracy: 0.8268 - val_loss: 1.3177 - val_accuracy: 0.4971\n",
      "Epoch 421/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5318 - accuracy: 0.8134 - val_loss: 1.3008 - val_accuracy: 0.4800\n",
      "Epoch 422/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.5280 - accuracy: 0.8174 - val_loss: 1.3535 - val_accuracy: 0.4743\n",
      "Epoch 423/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5277 - accuracy: 0.8094 - val_loss: 1.3739 - val_accuracy: 0.4514\n",
      "Epoch 424/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.5305 - accuracy: 0.8134 - val_loss: 1.3081 - val_accuracy: 0.5029\n",
      "Epoch 425/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5325 - accuracy: 0.8148 - val_loss: 1.3465 - val_accuracy: 0.4457\n",
      "Epoch 426/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5232 - accuracy: 0.8201 - val_loss: 1.3071 - val_accuracy: 0.4971\n",
      "Epoch 427/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5222 - accuracy: 0.8282 - val_loss: 1.2972 - val_accuracy: 0.5029\n",
      "Epoch 428/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5143 - accuracy: 0.8322 - val_loss: 1.3588 - val_accuracy: 0.4571\n",
      "Epoch 429/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.5150 - accuracy: 0.8201 - val_loss: 1.3019 - val_accuracy: 0.4686\n",
      "Epoch 430/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.5109 - accuracy: 0.8309 - val_loss: 1.3414 - val_accuracy: 0.4914\n",
      "Epoch 431/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5142 - accuracy: 0.8362 - val_loss: 1.3093 - val_accuracy: 0.4971\n",
      "Epoch 432/700\n",
      "745/745 [==============================] - 10s 13ms/step - loss: 0.5142 - accuracy: 0.8174 - val_loss: 1.3086 - val_accuracy: 0.4857\n",
      "Epoch 433/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.5120 - accuracy: 0.8336 - val_loss: 1.3595 - val_accuracy: 0.4457\n",
      "Epoch 434/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.5184 - accuracy: 0.8161 - val_loss: 1.3858 - val_accuracy: 0.4971\n",
      "Epoch 435/700\n",
      "745/745 [==============================] - 8s 10ms/step - loss: 0.5024 - accuracy: 0.8242 - val_loss: 1.3700 - val_accuracy: 0.4514\n",
      "Epoch 436/700\n",
      "745/745 [==============================] - 13s 17ms/step - loss: 0.5081 - accuracy: 0.8403 - val_loss: 1.3437 - val_accuracy: 0.4971\n",
      "Epoch 437/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.5133 - accuracy: 0.8174 - val_loss: 1.3571 - val_accuracy: 0.4514\n",
      "Epoch 438/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.4963 - accuracy: 0.8309 - val_loss: 1.3342 - val_accuracy: 0.4800\n",
      "Epoch 439/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.5117 - accuracy: 0.8268 - val_loss: 1.5449 - val_accuracy: 0.4343\n",
      "Epoch 440/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.4928 - accuracy: 0.8174 - val_loss: 1.3702 - val_accuracy: 0.4914\n",
      "Epoch 441/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.5050 - accuracy: 0.8336 - val_loss: 1.3677 - val_accuracy: 0.4686\n",
      "Epoch 442/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4978 - accuracy: 0.8188 - val_loss: 1.4261 - val_accuracy: 0.4743\n",
      "Epoch 443/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.5149 - accuracy: 0.8107 - val_loss: 1.3437 - val_accuracy: 0.4914\n",
      "Epoch 444/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.5064 - accuracy: 0.8242 - val_loss: 1.3753 - val_accuracy: 0.4400\n",
      "Epoch 445/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4989 - accuracy: 0.8268 - val_loss: 1.3560 - val_accuracy: 0.4914\n",
      "Epoch 446/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.4974 - accuracy: 0.8282 - val_loss: 1.3265 - val_accuracy: 0.4857\n",
      "Epoch 447/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4887 - accuracy: 0.8309 - val_loss: 1.3911 - val_accuracy: 0.4514\n",
      "Epoch 448/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4941 - accuracy: 0.8362 - val_loss: 1.3763 - val_accuracy: 0.4629\n",
      "Epoch 449/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.4877 - accuracy: 0.8336 - val_loss: 1.3819 - val_accuracy: 0.4514\n",
      "Epoch 450/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4912 - accuracy: 0.8376 - val_loss: 1.5195 - val_accuracy: 0.4571\n",
      "Epoch 451/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4939 - accuracy: 0.8161 - val_loss: 1.4410 - val_accuracy: 0.4686\n",
      "Epoch 452/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4894 - accuracy: 0.8295 - val_loss: 1.3620 - val_accuracy: 0.4743\n",
      "Epoch 453/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4874 - accuracy: 0.8389 - val_loss: 1.3468 - val_accuracy: 0.4743\n",
      "Epoch 454/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4800 - accuracy: 0.8362 - val_loss: 1.3806 - val_accuracy: 0.4286\n",
      "Epoch 455/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4852 - accuracy: 0.8376 - val_loss: 1.3929 - val_accuracy: 0.5029\n",
      "Epoch 456/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4851 - accuracy: 0.8295 - val_loss: 1.3329 - val_accuracy: 0.4914\n",
      "Epoch 457/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4870 - accuracy: 0.8389 - val_loss: 1.4079 - val_accuracy: 0.4343\n",
      "Epoch 458/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4907 - accuracy: 0.8228 - val_loss: 1.3529 - val_accuracy: 0.4800\n",
      "Epoch 459/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4857 - accuracy: 0.8443 - val_loss: 1.3565 - val_accuracy: 0.4971\n",
      "Epoch 460/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.4863 - accuracy: 0.8255 - val_loss: 1.3341 - val_accuracy: 0.4857\n",
      "Epoch 461/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.4765 - accuracy: 0.8376 - val_loss: 1.3835 - val_accuracy: 0.4686\n",
      "Epoch 462/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4793 - accuracy: 0.8376 - val_loss: 1.4491 - val_accuracy: 0.4743\n",
      "Epoch 463/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.4761 - accuracy: 0.8389 - val_loss: 1.4246 - val_accuracy: 0.4857\n",
      "Epoch 464/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4790 - accuracy: 0.8322 - val_loss: 1.3480 - val_accuracy: 0.4800\n",
      "Epoch 465/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4757 - accuracy: 0.8416 - val_loss: 1.4292 - val_accuracy: 0.4457\n",
      "Epoch 466/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.4709 - accuracy: 0.8362 - val_loss: 1.3497 - val_accuracy: 0.4914\n",
      "Epoch 467/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4670 - accuracy: 0.8483 - val_loss: 1.3750 - val_accuracy: 0.4857\n",
      "Epoch 468/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.4749 - accuracy: 0.8322 - val_loss: 1.3591 - val_accuracy: 0.5200\n",
      "Epoch 469/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.4587 - accuracy: 0.8510 - val_loss: 1.4608 - val_accuracy: 0.4800\n",
      "Epoch 470/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.4693 - accuracy: 0.8430 - val_loss: 1.3593 - val_accuracy: 0.4629\n",
      "Epoch 471/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 0.4578 - accuracy: 0.8523 - val_loss: 1.4122 - val_accuracy: 0.4629\n",
      "Epoch 472/700\n",
      "745/745 [==============================] - 9s 12ms/step - loss: 0.4631 - accuracy: 0.8537 - val_loss: 1.3580 - val_accuracy: 0.4629\n",
      "Epoch 473/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.4724 - accuracy: 0.8362 - val_loss: 1.3572 - val_accuracy: 0.4457\n",
      "Epoch 474/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 0.4616 - accuracy: 0.8497 - val_loss: 1.3783 - val_accuracy: 0.4914\n",
      "Epoch 475/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.4631 - accuracy: 0.8577 - val_loss: 1.4109 - val_accuracy: 0.4914\n",
      "Epoch 476/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.4685 - accuracy: 0.8322 - val_loss: 1.4716 - val_accuracy: 0.4857\n",
      "Epoch 477/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4544 - accuracy: 0.8510 - val_loss: 1.4300 - val_accuracy: 0.4514\n",
      "Epoch 478/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.4591 - accuracy: 0.8537 - val_loss: 1.3959 - val_accuracy: 0.4629\n",
      "Epoch 479/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4626 - accuracy: 0.8416 - val_loss: 1.3605 - val_accuracy: 0.4686\n",
      "Epoch 480/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4590 - accuracy: 0.8483 - val_loss: 1.3915 - val_accuracy: 0.4571\n",
      "Epoch 481/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4551 - accuracy: 0.8564 - val_loss: 1.3752 - val_accuracy: 0.4971\n",
      "Epoch 482/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4542 - accuracy: 0.8591 - val_loss: 1.4529 - val_accuracy: 0.4686\n",
      "Epoch 483/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.4517 - accuracy: 0.8443 - val_loss: 1.3750 - val_accuracy: 0.4800\n",
      "Epoch 484/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4432 - accuracy: 0.8537 - val_loss: 1.4099 - val_accuracy: 0.4629\n",
      "Epoch 485/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4509 - accuracy: 0.8617 - val_loss: 1.3669 - val_accuracy: 0.4629\n",
      "Epoch 486/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4408 - accuracy: 0.8591 - val_loss: 1.4315 - val_accuracy: 0.4571\n",
      "Epoch 487/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4298 - accuracy: 0.8644 - val_loss: 1.3738 - val_accuracy: 0.4971\n",
      "Epoch 488/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4428 - accuracy: 0.8523 - val_loss: 1.4472 - val_accuracy: 0.4514\n",
      "Epoch 489/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.4430 - accuracy: 0.8523 - val_loss: 1.4083 - val_accuracy: 0.4686\n",
      "Epoch 490/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.4474 - accuracy: 0.8523 - val_loss: 1.4324 - val_accuracy: 0.4457\n",
      "Epoch 491/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4364 - accuracy: 0.8617 - val_loss: 1.5414 - val_accuracy: 0.4800\n",
      "Epoch 492/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.4404 - accuracy: 0.8550 - val_loss: 1.4659 - val_accuracy: 0.4514\n",
      "Epoch 493/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4440 - accuracy: 0.8483 - val_loss: 1.4226 - val_accuracy: 0.4857\n",
      "Epoch 494/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4442 - accuracy: 0.8631 - val_loss: 1.3968 - val_accuracy: 0.4857\n",
      "Epoch 495/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4324 - accuracy: 0.8685 - val_loss: 1.4113 - val_accuracy: 0.4800\n",
      "Epoch 496/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4369 - accuracy: 0.8671 - val_loss: 1.4195 - val_accuracy: 0.4743\n",
      "Epoch 497/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4417 - accuracy: 0.8617 - val_loss: 1.3712 - val_accuracy: 0.4743\n",
      "Epoch 498/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4333 - accuracy: 0.8537 - val_loss: 1.3832 - val_accuracy: 0.5086\n",
      "Epoch 499/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4423 - accuracy: 0.8537 - val_loss: 1.4815 - val_accuracy: 0.4400\n",
      "Epoch 500/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4293 - accuracy: 0.8658 - val_loss: 1.4044 - val_accuracy: 0.4857\n",
      "Epoch 501/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4271 - accuracy: 0.8483 - val_loss: 1.4996 - val_accuracy: 0.4457\n",
      "Epoch 502/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4213 - accuracy: 0.8644 - val_loss: 1.4448 - val_accuracy: 0.4686\n",
      "Epoch 503/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4263 - accuracy: 0.8685 - val_loss: 1.4666 - val_accuracy: 0.4686\n",
      "Epoch 504/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4210 - accuracy: 0.8658 - val_loss: 1.4559 - val_accuracy: 0.4457\n",
      "Epoch 505/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4218 - accuracy: 0.8631 - val_loss: 1.4898 - val_accuracy: 0.4686\n",
      "Epoch 506/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4377 - accuracy: 0.8617 - val_loss: 1.3949 - val_accuracy: 0.4914\n",
      "Epoch 507/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.4224 - accuracy: 0.8591 - val_loss: 1.3868 - val_accuracy: 0.4686\n",
      "Epoch 508/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.4137 - accuracy: 0.8725 - val_loss: 1.4123 - val_accuracy: 0.4457\n",
      "Epoch 509/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4078 - accuracy: 0.8671 - val_loss: 1.3980 - val_accuracy: 0.4914\n",
      "Epoch 510/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4157 - accuracy: 0.8725 - val_loss: 1.4167 - val_accuracy: 0.4914\n",
      "Epoch 511/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4190 - accuracy: 0.8685 - val_loss: 1.4818 - val_accuracy: 0.4457\n",
      "Epoch 512/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4218 - accuracy: 0.8711 - val_loss: 1.4825 - val_accuracy: 0.4457\n",
      "Epoch 513/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4102 - accuracy: 0.8577 - val_loss: 1.4424 - val_accuracy: 0.4686\n",
      "Epoch 514/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4097 - accuracy: 0.8711 - val_loss: 1.4683 - val_accuracy: 0.4571\n",
      "Epoch 515/700\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 0.4109 - accuracy: 0.8564 - val_loss: 1.4364 - val_accuracy: 0.4571\n",
      "Epoch 516/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4168 - accuracy: 0.8631 - val_loss: 1.4913 - val_accuracy: 0.4571\n",
      "Epoch 517/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.4077 - accuracy: 0.8591 - val_loss: 1.4526 - val_accuracy: 0.4686\n",
      "Epoch 518/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 0.4036 - accuracy: 0.8685 - val_loss: 1.4941 - val_accuracy: 0.4457\n",
      "Epoch 519/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3993 - accuracy: 0.8738 - val_loss: 1.4325 - val_accuracy: 0.4743\n",
      "Epoch 520/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4010 - accuracy: 0.8671 - val_loss: 1.4789 - val_accuracy: 0.4743\n",
      "Epoch 521/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4105 - accuracy: 0.8631 - val_loss: 1.5674 - val_accuracy: 0.4514\n",
      "Epoch 522/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4015 - accuracy: 0.8752 - val_loss: 1.4788 - val_accuracy: 0.4571\n",
      "Epoch 523/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4030 - accuracy: 0.8752 - val_loss: 1.4742 - val_accuracy: 0.4514\n",
      "Epoch 524/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3916 - accuracy: 0.8725 - val_loss: 1.4351 - val_accuracy: 0.4743\n",
      "Epoch 525/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3968 - accuracy: 0.8765 - val_loss: 1.4166 - val_accuracy: 0.4514\n",
      "Epoch 526/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3931 - accuracy: 0.8886 - val_loss: 1.5056 - val_accuracy: 0.4457\n",
      "Epoch 527/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4047 - accuracy: 0.8631 - val_loss: 1.4220 - val_accuracy: 0.4457\n",
      "Epoch 528/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3964 - accuracy: 0.8658 - val_loss: 1.4753 - val_accuracy: 0.4857\n",
      "Epoch 529/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.4000 - accuracy: 0.8658 - val_loss: 1.4314 - val_accuracy: 0.5200\n",
      "Epoch 530/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3891 - accuracy: 0.8765 - val_loss: 1.5462 - val_accuracy: 0.4514\n",
      "Epoch 531/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3824 - accuracy: 0.8926 - val_loss: 1.4770 - val_accuracy: 0.5086\n",
      "Epoch 532/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3950 - accuracy: 0.8671 - val_loss: 1.4542 - val_accuracy: 0.4686\n",
      "Epoch 533/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3983 - accuracy: 0.8711 - val_loss: 1.5339 - val_accuracy: 0.4686\n",
      "Epoch 534/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3840 - accuracy: 0.8819 - val_loss: 1.5279 - val_accuracy: 0.4457\n",
      "Epoch 535/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3891 - accuracy: 0.8738 - val_loss: 1.3988 - val_accuracy: 0.4971\n",
      "Epoch 536/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3877 - accuracy: 0.8671 - val_loss: 1.4945 - val_accuracy: 0.4514\n",
      "Epoch 537/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3929 - accuracy: 0.8765 - val_loss: 1.4949 - val_accuracy: 0.4629\n",
      "Epoch 538/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3828 - accuracy: 0.8832 - val_loss: 1.4814 - val_accuracy: 0.4514\n",
      "Epoch 539/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3757 - accuracy: 0.8832 - val_loss: 1.6742 - val_accuracy: 0.4343\n",
      "Epoch 540/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3869 - accuracy: 0.8779 - val_loss: 1.4643 - val_accuracy: 0.4686\n",
      "Epoch 541/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3785 - accuracy: 0.8832 - val_loss: 1.4710 - val_accuracy: 0.4629\n",
      "Epoch 542/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3895 - accuracy: 0.8792 - val_loss: 1.4685 - val_accuracy: 0.4629\n",
      "Epoch 543/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.3737 - accuracy: 0.8926 - val_loss: 1.5447 - val_accuracy: 0.4514\n",
      "Epoch 544/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3794 - accuracy: 0.8792 - val_loss: 1.5381 - val_accuracy: 0.4629\n",
      "Epoch 545/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3798 - accuracy: 0.8792 - val_loss: 1.5272 - val_accuracy: 0.4571\n",
      "Epoch 546/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3789 - accuracy: 0.8738 - val_loss: 1.4655 - val_accuracy: 0.4514\n",
      "Epoch 547/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3737 - accuracy: 0.8872 - val_loss: 1.4837 - val_accuracy: 0.5029\n",
      "Epoch 548/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3738 - accuracy: 0.8752 - val_loss: 1.4420 - val_accuracy: 0.4686\n",
      "Epoch 549/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3706 - accuracy: 0.8738 - val_loss: 1.4590 - val_accuracy: 0.4800\n",
      "Epoch 550/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3774 - accuracy: 0.8779 - val_loss: 1.4953 - val_accuracy: 0.4457\n",
      "Epoch 551/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3629 - accuracy: 0.8899 - val_loss: 1.4659 - val_accuracy: 0.4743\n",
      "Epoch 552/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3675 - accuracy: 0.8792 - val_loss: 1.4432 - val_accuracy: 0.4914\n",
      "Epoch 553/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3710 - accuracy: 0.8819 - val_loss: 1.4745 - val_accuracy: 0.4743\n",
      "Epoch 554/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3610 - accuracy: 0.8899 - val_loss: 1.4705 - val_accuracy: 0.4514\n",
      "Epoch 555/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3696 - accuracy: 0.8805 - val_loss: 1.4634 - val_accuracy: 0.4686\n",
      "Epoch 556/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3700 - accuracy: 0.8846 - val_loss: 1.4351 - val_accuracy: 0.4800\n",
      "Epoch 557/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3661 - accuracy: 0.8832 - val_loss: 1.5498 - val_accuracy: 0.4800\n",
      "Epoch 558/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3649 - accuracy: 0.8805 - val_loss: 1.4831 - val_accuracy: 0.4857\n",
      "Epoch 559/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3642 - accuracy: 0.8913 - val_loss: 1.4730 - val_accuracy: 0.4571\n",
      "Epoch 560/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3564 - accuracy: 0.8926 - val_loss: 1.5099 - val_accuracy: 0.4514\n",
      "Epoch 561/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3602 - accuracy: 0.8899 - val_loss: 1.4228 - val_accuracy: 0.4971\n",
      "Epoch 562/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3556 - accuracy: 0.8926 - val_loss: 1.5067 - val_accuracy: 0.4686\n",
      "Epoch 563/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3564 - accuracy: 0.8819 - val_loss: 1.4782 - val_accuracy: 0.4743\n",
      "Epoch 564/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3520 - accuracy: 0.8966 - val_loss: 1.5323 - val_accuracy: 0.4400\n",
      "Epoch 565/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3544 - accuracy: 0.8966 - val_loss: 1.5920 - val_accuracy: 0.4629\n",
      "Epoch 566/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3559 - accuracy: 0.8899 - val_loss: 1.5086 - val_accuracy: 0.4686\n",
      "Epoch 567/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3439 - accuracy: 0.9047 - val_loss: 1.4648 - val_accuracy: 0.4743\n",
      "Epoch 568/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3466 - accuracy: 0.8980 - val_loss: 1.5295 - val_accuracy: 0.4686\n",
      "Epoch 569/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3558 - accuracy: 0.8832 - val_loss: 1.4888 - val_accuracy: 0.4514\n",
      "Epoch 570/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.3488 - accuracy: 0.8940 - val_loss: 1.5466 - val_accuracy: 0.4629\n",
      "Epoch 571/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3391 - accuracy: 0.8953 - val_loss: 1.4799 - val_accuracy: 0.4914\n",
      "Epoch 572/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3466 - accuracy: 0.8926 - val_loss: 1.4781 - val_accuracy: 0.4743\n",
      "Epoch 573/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3429 - accuracy: 0.8993 - val_loss: 1.4875 - val_accuracy: 0.4629\n",
      "Epoch 574/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3321 - accuracy: 0.8993 - val_loss: 1.5013 - val_accuracy: 0.4457\n",
      "Epoch 575/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3413 - accuracy: 0.8940 - val_loss: 1.5151 - val_accuracy: 0.4571\n",
      "Epoch 576/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3423 - accuracy: 0.8966 - val_loss: 1.5643 - val_accuracy: 0.4400\n",
      "Epoch 577/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3399 - accuracy: 0.8940 - val_loss: 1.5618 - val_accuracy: 0.4629\n",
      "Epoch 578/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3281 - accuracy: 0.9007 - val_loss: 1.5222 - val_accuracy: 0.4800\n",
      "Epoch 579/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3446 - accuracy: 0.9034 - val_loss: 1.4856 - val_accuracy: 0.4971\n",
      "Epoch 580/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3310 - accuracy: 0.8980 - val_loss: 1.4520 - val_accuracy: 0.4857\n",
      "Epoch 581/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3319 - accuracy: 0.9020 - val_loss: 1.4763 - val_accuracy: 0.4514\n",
      "Epoch 582/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3361 - accuracy: 0.8899 - val_loss: 1.5155 - val_accuracy: 0.4514\n",
      "Epoch 583/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3402 - accuracy: 0.8993 - val_loss: 1.5680 - val_accuracy: 0.4686\n",
      "Epoch 584/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3293 - accuracy: 0.9020 - val_loss: 1.4774 - val_accuracy: 0.4686\n",
      "Epoch 585/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3296 - accuracy: 0.8993 - val_loss: 1.5864 - val_accuracy: 0.4686\n",
      "Epoch 586/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3247 - accuracy: 0.9060 - val_loss: 1.4698 - val_accuracy: 0.4800\n",
      "Epoch 587/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3341 - accuracy: 0.9020 - val_loss: 1.5635 - val_accuracy: 0.4286\n",
      "Epoch 588/700\n",
      "745/745 [==============================] - 10s 13ms/step - loss: 0.3270 - accuracy: 0.9007 - val_loss: 1.5145 - val_accuracy: 0.4514\n",
      "Epoch 589/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.3304 - accuracy: 0.8980 - val_loss: 1.5265 - val_accuracy: 0.4400\n",
      "Epoch 590/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3196 - accuracy: 0.8993 - val_loss: 1.5732 - val_accuracy: 0.4457\n",
      "Epoch 591/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3176 - accuracy: 0.9181 - val_loss: 1.5255 - val_accuracy: 0.4686\n",
      "Epoch 592/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3178 - accuracy: 0.9007 - val_loss: 1.4940 - val_accuracy: 0.4800\n",
      "Epoch 593/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3034 - accuracy: 0.9235 - val_loss: 1.4727 - val_accuracy: 0.4743\n",
      "Epoch 594/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3168 - accuracy: 0.9087 - val_loss: 1.5230 - val_accuracy: 0.4743\n",
      "Epoch 595/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3196 - accuracy: 0.8966 - val_loss: 1.5417 - val_accuracy: 0.4457\n",
      "Epoch 596/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3152 - accuracy: 0.9020 - val_loss: 1.4971 - val_accuracy: 0.4971\n",
      "Epoch 597/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3182 - accuracy: 0.9034 - val_loss: 1.6904 - val_accuracy: 0.4514\n",
      "Epoch 598/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3228 - accuracy: 0.8940 - val_loss: 1.5115 - val_accuracy: 0.4629\n",
      "Epoch 599/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3100 - accuracy: 0.9168 - val_loss: 1.5834 - val_accuracy: 0.4743\n",
      "Epoch 600/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3197 - accuracy: 0.9034 - val_loss: 1.5034 - val_accuracy: 0.4857\n",
      "Epoch 601/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3140 - accuracy: 0.9141 - val_loss: 1.5224 - val_accuracy: 0.4571\n",
      "Epoch 602/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3213 - accuracy: 0.9101 - val_loss: 1.5232 - val_accuracy: 0.4971\n",
      "Epoch 603/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3089 - accuracy: 0.9074 - val_loss: 1.5355 - val_accuracy: 0.4914\n",
      "Epoch 604/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3036 - accuracy: 0.9114 - val_loss: 1.5476 - val_accuracy: 0.4971\n",
      "Epoch 605/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3085 - accuracy: 0.9128 - val_loss: 1.5792 - val_accuracy: 0.4514\n",
      "Epoch 606/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3168 - accuracy: 0.9020 - val_loss: 1.5087 - val_accuracy: 0.4571\n",
      "Epoch 607/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.3055 - accuracy: 0.9154 - val_loss: 1.5556 - val_accuracy: 0.4743\n",
      "Epoch 608/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3046 - accuracy: 0.9074 - val_loss: 1.5559 - val_accuracy: 0.4629\n",
      "Epoch 609/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3112 - accuracy: 0.8993 - val_loss: 1.5397 - val_accuracy: 0.4971\n",
      "Epoch 610/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2990 - accuracy: 0.9195 - val_loss: 1.5835 - val_accuracy: 0.4571\n",
      "Epoch 611/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3042 - accuracy: 0.9101 - val_loss: 1.5382 - val_accuracy: 0.4971\n",
      "Epoch 612/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.3012 - accuracy: 0.9114 - val_loss: 1.5449 - val_accuracy: 0.4629\n",
      "Epoch 613/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2956 - accuracy: 0.9114 - val_loss: 1.5350 - val_accuracy: 0.4914\n",
      "Epoch 614/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2999 - accuracy: 0.9195 - val_loss: 1.5766 - val_accuracy: 0.4914\n",
      "Epoch 615/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2997 - accuracy: 0.9101 - val_loss: 1.6895 - val_accuracy: 0.4800\n",
      "Epoch 616/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2974 - accuracy: 0.9114 - val_loss: 1.5380 - val_accuracy: 0.4971\n",
      "Epoch 617/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.2926 - accuracy: 0.9128 - val_loss: 1.5296 - val_accuracy: 0.4800\n",
      "Epoch 618/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2927 - accuracy: 0.9074 - val_loss: 1.5734 - val_accuracy: 0.4571\n",
      "Epoch 619/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2930 - accuracy: 0.9168 - val_loss: 1.5393 - val_accuracy: 0.4514\n",
      "Epoch 620/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2895 - accuracy: 0.9248 - val_loss: 1.5686 - val_accuracy: 0.4686\n",
      "Epoch 621/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2914 - accuracy: 0.9221 - val_loss: 1.6381 - val_accuracy: 0.4629\n",
      "Epoch 622/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2909 - accuracy: 0.9208 - val_loss: 1.5134 - val_accuracy: 0.4914\n",
      "Epoch 623/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2896 - accuracy: 0.9235 - val_loss: 1.7243 - val_accuracy: 0.4343\n",
      "Epoch 624/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2909 - accuracy: 0.9101 - val_loss: 1.5623 - val_accuracy: 0.4457\n",
      "Epoch 625/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2827 - accuracy: 0.9248 - val_loss: 1.6038 - val_accuracy: 0.4800\n",
      "Epoch 626/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2810 - accuracy: 0.9262 - val_loss: 1.6560 - val_accuracy: 0.4800\n",
      "Epoch 627/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2863 - accuracy: 0.9235 - val_loss: 1.7171 - val_accuracy: 0.4457\n",
      "Epoch 628/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2797 - accuracy: 0.9195 - val_loss: 1.5892 - val_accuracy: 0.4857\n",
      "Epoch 629/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2850 - accuracy: 0.9168 - val_loss: 1.6037 - val_accuracy: 0.4571\n",
      "Epoch 630/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2855 - accuracy: 0.9262 - val_loss: 1.5908 - val_accuracy: 0.4629\n",
      "Epoch 631/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2797 - accuracy: 0.9141 - val_loss: 1.5529 - val_accuracy: 0.4971\n",
      "Epoch 632/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2750 - accuracy: 0.9262 - val_loss: 1.6248 - val_accuracy: 0.4686\n",
      "Epoch 633/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2765 - accuracy: 0.9262 - val_loss: 1.6163 - val_accuracy: 0.4914\n",
      "Epoch 634/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2789 - accuracy: 0.9315 - val_loss: 1.5861 - val_accuracy: 0.4743\n",
      "Epoch 635/700\n",
      "745/745 [==============================] - 8s 11ms/step - loss: 0.2782 - accuracy: 0.9208 - val_loss: 1.6110 - val_accuracy: 0.4800\n",
      "Epoch 636/700\n",
      "745/745 [==============================] - 6s 9ms/step - loss: 0.2785 - accuracy: 0.9248 - val_loss: 1.5907 - val_accuracy: 0.4857\n",
      "Epoch 637/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.2808 - accuracy: 0.9235 - val_loss: 1.5851 - val_accuracy: 0.4800\n",
      "Epoch 638/700\n",
      "745/745 [==============================] - 7s 9ms/step - loss: 0.2693 - accuracy: 0.9342 - val_loss: 1.5703 - val_accuracy: 0.4514\n",
      "Epoch 639/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2736 - accuracy: 0.9168 - val_loss: 1.5730 - val_accuracy: 0.4571\n",
      "Epoch 640/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2735 - accuracy: 0.9302 - val_loss: 1.5739 - val_accuracy: 0.4971\n",
      "Epoch 641/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2696 - accuracy: 0.9329 - val_loss: 1.6244 - val_accuracy: 0.4400\n",
      "Epoch 642/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2732 - accuracy: 0.9208 - val_loss: 1.6488 - val_accuracy: 0.5029\n",
      "Epoch 643/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2686 - accuracy: 0.9275 - val_loss: 1.6543 - val_accuracy: 0.4743\n",
      "Epoch 644/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2684 - accuracy: 0.9409 - val_loss: 1.5758 - val_accuracy: 0.4743\n",
      "Epoch 645/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2653 - accuracy: 0.9289 - val_loss: 1.5348 - val_accuracy: 0.4914\n",
      "Epoch 646/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2685 - accuracy: 0.9208 - val_loss: 1.6280 - val_accuracy: 0.4514\n",
      "Epoch 647/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2705 - accuracy: 0.9168 - val_loss: 1.6238 - val_accuracy: 0.4629\n",
      "Epoch 648/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2661 - accuracy: 0.9302 - val_loss: 1.6833 - val_accuracy: 0.4629\n",
      "Epoch 649/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2596 - accuracy: 0.9168 - val_loss: 1.5560 - val_accuracy: 0.4571\n",
      "Epoch 650/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2548 - accuracy: 0.9356 - val_loss: 1.6343 - val_accuracy: 0.4686\n",
      "Epoch 651/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2612 - accuracy: 0.9342 - val_loss: 1.6114 - val_accuracy: 0.4514\n",
      "Epoch 652/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2663 - accuracy: 0.9289 - val_loss: 1.6477 - val_accuracy: 0.4686\n",
      "Epoch 653/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2523 - accuracy: 0.9235 - val_loss: 1.5860 - val_accuracy: 0.5143\n",
      "Epoch 654/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2605 - accuracy: 0.9275 - val_loss: 1.5904 - val_accuracy: 0.5257\n",
      "Epoch 655/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2651 - accuracy: 0.9315 - val_loss: 1.6355 - val_accuracy: 0.4857\n",
      "Epoch 656/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2598 - accuracy: 0.9315 - val_loss: 1.6243 - val_accuracy: 0.4514\n",
      "Epoch 657/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2565 - accuracy: 0.9369 - val_loss: 1.6326 - val_accuracy: 0.4400\n",
      "Epoch 658/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2565 - accuracy: 0.9262 - val_loss: 1.8472 - val_accuracy: 0.4743\n",
      "Epoch 659/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2574 - accuracy: 0.9356 - val_loss: 1.5788 - val_accuracy: 0.4857\n",
      "Epoch 660/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2516 - accuracy: 0.9342 - val_loss: 1.6398 - val_accuracy: 0.4914\n",
      "Epoch 661/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2527 - accuracy: 0.9329 - val_loss: 1.6605 - val_accuracy: 0.4400\n",
      "Epoch 662/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2439 - accuracy: 0.9423 - val_loss: 1.6167 - val_accuracy: 0.4571\n",
      "Epoch 663/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.2446 - accuracy: 0.9436 - val_loss: 1.6064 - val_accuracy: 0.4571\n",
      "Epoch 664/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2562 - accuracy: 0.9208 - val_loss: 1.5680 - val_accuracy: 0.4571\n",
      "Epoch 665/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2361 - accuracy: 0.9436 - val_loss: 1.6267 - val_accuracy: 0.4629\n",
      "Epoch 666/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2416 - accuracy: 0.9396 - val_loss: 1.6716 - val_accuracy: 0.4857\n",
      "Epoch 667/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2407 - accuracy: 0.9383 - val_loss: 1.5791 - val_accuracy: 0.4857\n",
      "Epoch 668/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2516 - accuracy: 0.9302 - val_loss: 1.6255 - val_accuracy: 0.4629\n",
      "Epoch 669/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2487 - accuracy: 0.9356 - val_loss: 1.6061 - val_accuracy: 0.5086\n",
      "Epoch 670/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2398 - accuracy: 0.9369 - val_loss: 1.7664 - val_accuracy: 0.4800\n",
      "Epoch 671/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2443 - accuracy: 0.9383 - val_loss: 1.6519 - val_accuracy: 0.4857\n",
      "Epoch 672/700\n",
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2388 - accuracy: 0.9342 - val_loss: 1.6400 - val_accuracy: 0.4686\n",
      "Epoch 673/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2341 - accuracy: 0.9477 - val_loss: 1.6676 - val_accuracy: 0.4514\n",
      "Epoch 674/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745/745 [==============================] - 6s 7ms/step - loss: 0.2449 - accuracy: 0.9262 - val_loss: 1.6443 - val_accuracy: 0.4629\n",
      "Epoch 675/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2330 - accuracy: 0.9517 - val_loss: 1.7372 - val_accuracy: 0.4514\n",
      "Epoch 676/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2366 - accuracy: 0.9342 - val_loss: 1.5952 - val_accuracy: 0.5086\n",
      "Epoch 677/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2343 - accuracy: 0.9396 - val_loss: 1.6707 - val_accuracy: 0.4857\n",
      "Epoch 678/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2349 - accuracy: 0.9275 - val_loss: 1.6859 - val_accuracy: 0.4629\n",
      "Epoch 679/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2360 - accuracy: 0.9329 - val_loss: 1.5994 - val_accuracy: 0.5143\n",
      "Epoch 680/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2328 - accuracy: 0.9383 - val_loss: 1.6824 - val_accuracy: 0.4286\n",
      "Epoch 681/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2298 - accuracy: 0.9369 - val_loss: 1.6826 - val_accuracy: 0.5086\n",
      "Epoch 682/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2297 - accuracy: 0.9409 - val_loss: 1.6397 - val_accuracy: 0.4571\n",
      "Epoch 683/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2317 - accuracy: 0.9450 - val_loss: 1.8355 - val_accuracy: 0.4571\n",
      "Epoch 684/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2317 - accuracy: 0.9356 - val_loss: 1.6517 - val_accuracy: 0.4971\n",
      "Epoch 685/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2239 - accuracy: 0.9503 - val_loss: 1.6498 - val_accuracy: 0.4743\n",
      "Epoch 686/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2264 - accuracy: 0.9409 - val_loss: 1.7597 - val_accuracy: 0.4457\n",
      "Epoch 687/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2295 - accuracy: 0.9423 - val_loss: 1.6556 - val_accuracy: 0.4571\n",
      "Epoch 688/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2182 - accuracy: 0.9517 - val_loss: 1.6651 - val_accuracy: 0.4971\n",
      "Epoch 689/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2235 - accuracy: 0.9477 - val_loss: 1.7581 - val_accuracy: 0.4914\n",
      "Epoch 690/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2251 - accuracy: 0.9450 - val_loss: 1.6984 - val_accuracy: 0.4571\n",
      "Epoch 691/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2216 - accuracy: 0.9503 - val_loss: 1.6804 - val_accuracy: 0.4800\n",
      "Epoch 692/700\n",
      "745/745 [==============================] - 6s 8ms/step - loss: 0.2191 - accuracy: 0.9450 - val_loss: 1.6763 - val_accuracy: 0.4914\n",
      "Epoch 693/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2217 - accuracy: 0.9463 - val_loss: 1.6992 - val_accuracy: 0.4743\n",
      "Epoch 694/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2207 - accuracy: 0.9463 - val_loss: 1.7069 - val_accuracy: 0.4514\n",
      "Epoch 695/700\n",
      "745/745 [==============================] - 8s 10ms/step - loss: 0.2148 - accuracy: 0.9477 - val_loss: 1.6184 - val_accuracy: 0.4743\n",
      "Epoch 696/700\n",
      "745/745 [==============================] - 7s 10ms/step - loss: 0.2128 - accuracy: 0.9436 - val_loss: 1.6360 - val_accuracy: 0.5029\n",
      "Epoch 697/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2195 - accuracy: 0.9544 - val_loss: 1.6241 - val_accuracy: 0.4914\n",
      "Epoch 698/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2237 - accuracy: 0.9530 - val_loss: 1.6356 - val_accuracy: 0.4800\n",
      "Epoch 699/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2175 - accuracy: 0.9423 - val_loss: 1.7308 - val_accuracy: 0.4686\n",
      "Epoch 700/700\n",
      "745/745 [==============================] - 5s 7ms/step - loss: 0.2111 - accuracy: 0.9557 - val_loss: 1.6973 - val_accuracy: 0.4686\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hUVfrA8e+Z9N4DIYTeexNFpSgKgr2s3bWsi67rquuqK7q2Xfenu7pr74p9UeyooIiCDVCKoFTpEEIJJY305Pz+OHeYO5NJMoFMZpJ5P8+TJzP33pl5A8l97z3lPUprjRBCiNDlCHQAQgghAksSgRBChDhJBEIIEeIkEQghRIiTRCCEECFOEoEQQoQ4SQRC+Egp9YpS6n4fj92ilDrpSN9HiJYgiUAIIUKcJAIhhAhxkghEm2I1ydyqlPpZKXVQKfWSUqqdUmq2UqpYKTVXKZViO/4MpdQqpVSBUmq+Uqqvbd9QpdQy63VvA9Een3WaUmq59doFSqlBhxnz75VSG5RS+5VSM5VSHaztSin1iFJqj1Kq0PqZBlj7JiulVlux7VBK3XJY/2BCIIlAtE3nAicDvYDTgdnAHUA65nf+BgClVC9gOnATkAHMAj5WSkUqpSKBD4HXgVTgHet9sV47DJgGXAOkAc8BM5VSUU0JVCl1IvAAcD6QBWwF3rJ2TwDGWD9HMnABsM/a9xJwjdY6ARgAfNWUzxXCThKBaIue0Frv1lrvAL4FftBa/6S1rgA+AIZax10AfKq1/kJrXQU8DMQAxwLHABHAo1rrKq31u8Bi22f8HnhOa/2D1rpGa/0qUGG9rikuAaZprZdZ8U0FRimlugBVQALQB1Ba6zVa653W66qAfkqpRK31Aa31siZ+rhCHSCIQbdFu2+MyL8/jrccdMFfgAGita4HtQLa1b4d2r8q41fa4M/AXq1moQClVAORYr2sKzxhKMFf92Vrrr4AngaeA3Uqp55VSidah5wKTga1Kqa+VUqOa+LlCHCKJQISyPMwJHTBt8piT+Q5gJ5BtbXPqZHu8Hfin1jrZ9hWrtZ5+hDHEYZqadgBorR/XWg8H+mOaiG61ti/WWp8JZGKasGY08XOFOEQSgQhlM4BTlVLjlVIRwF8wzTsLgIVANXCDUipcKXUOMNL22heAa5VSR1udunFKqVOVUglNjOF/wJVKqSFW/8L/YZqytiiljrLePwI4CJQDNVYfxiVKqSSrSasIqDmCfwcR4iQRiJCltV4HXAo8AezFdCyfrrWu1FpXAucAVwAHMP0J79teuwTTT/CktX+DdWxTY/gSuAt4D3MX0h240NqdiEk4BzDNR/sw/RgAlwFblFJFwLXWzyHEYVGyMI0QQoQ2uSMQQogQJ4lACCFCnCQCIYQIcZIIhBAixIUHOoCmSk9P1126dAl0GEII0aosXbp0r9Y6w9u+VpcIunTpwpIlSwIdhhBCtCpKqa317ZOmISGECHGSCIQQIsRJIhBCiBDX6voIvKmqqiI3N5fy8vJAh+J30dHRdOzYkYiIiECHIoRoI9pEIsjNzSUhIYEuXbrgXiyybdFas2/fPnJzc+natWugwxFCtBFtommovLyctLS0Np0EAJRSpKWlhcSdjxCi5bSJRAC0+STgFCo/pxCi5bSZRNCY8qoadhWWU11TG+hQhBAiqIRMIqioqmFPcTlVNc1fdrugoICnn366ya+bPHkyBQUFzR6PEEI0RcgkAmeTij/WX6gvEdTUNLxo1KxZs0hOTm72eIQQoinaxKghXzispvVaP6zDc/vtt7Nx40aGDBlCREQE8fHxZGVlsXz5clavXs1ZZ53F9u3bKS8v58Ybb2TKlCmAq1xGSUkJkyZN4vjjj2fBggVkZ2fz0UcfERMT0/zBCiGEhzaXCO77eBWr84rqbK/VmrLKGqIjwghzNK3DtV+HRO45vX+9+x988EFWrlzJ8uXLmT9/PqeeeiorV648NMRz2rRppKamUlZWxlFHHcW5555LWlqa23usX7+e6dOn88ILL3D++efz3nvvcemlsvqgEML/2lwiCAYjR450G+f/+OOP88EHHwCwfft21q9fXycRdO3alSFDhgAwfPhwtmzZ0mLxCiFCW5tLBPVduVeVFlJxII+apE4kxcf5NYa4ONf7z58/n7lz57Jw4UJiY2MZN26c13kAUVFRhx6HhYVRVlbm1xiFEMIpdDqL0cSrcqipavb3TkhIoLi42Ou+wsJCUlJSiI2NZe3atSxatKjZP18IIY5Em7sjqI8KM7V5VG3zJ4K0tDSOO+44BgwYQExMDO3atTu075RTTuHZZ59l0KBB9O7dm2OOOabZP18IIY6E8sdwSn8aMWKE9lyYZs2aNfTt27fB19VWV+HYs5LiqPYkpGX5M0S/8+XnFUIIO6XUUq31CG/7QqdpKCycWu2fOwIhhGjNQicRKEU14ThqqwMdihBCBJWQSQQA1SoMh5Y7AiGEsAupRFBDOA4tdwRCCGEXUolAO8IJk0QghBBuQiwRRBBGLdQ2XAxOCCFCSUglAsLN7N3a6opmfdvDLUMN8Oijj1JaWtqs8QghRFOEVCJwRJhEUF3ZvEs9SiIQQrRmITOzGCAsIhoAXdm8dXzsZahPPvlkMjMzmTFjBhUVFZx99tncd999HDx4kPPPP5/c3Fxqamq466672L17N3l5eZxwwgmkp6czb968Zo1LCCF80fYSwezbYdcvXndFo6mpLCUSILIJhefaD4RJD9a7216Ges6cObz77rv8+OOPaK0544wz+Oabb8jPz6dDhw58+umngKlBlJSUxH//+1/mzZtHenp6E35IIYRoPiHVNKSAGhxALeCf0hpz5sxhzpw5DB06lGHDhrF27VrWr1/PwIEDmTt3Ln/961/59ttvSUpK8svnCyFEU7W9O4IGrtwVsG/nDrL0HsjsC+HRzf7xWmumTp3KNddcU2ff0qVLmTVrFlOnTmXChAncfffdzf75QgjRVCF1RwCgwyLNg+rKZntPexnqiRMnMm3aNEpKSgDYsWMHe/bsIS8vj9jYWC699FJuueUWli1bVue1QggRCG3vjqARKjwKqoGa5htCai9DPWnSJC6++GJGjRoFQHx8PG+88QYbNmzg1ltvxeFwEBERwTPPPAPAlClTmDRpEllZWdJZLIQIiJApQ+2UX1xOatFaVFw6juSO/gjR76QMtRCiqaQMtU10RBiVRFBbJUtBCiEEhGAiiAoPo5QowqpKoJlnGAshRGvUZhKBr01cEWGKQhJQANXNO8O4JbS2pjwhRPBrE4kgOjqaffv2+XSSVErhCLdGDvlhIXt/0lqzb98+oqObf9irECJ0+W3UkFIqB3gNaI+ZwfW81voxj2MU8BgwGSgFrtBaL2vqZ3Xs2JHc3Fzy8/N9Ov7AwQrKqvZAdAVE+/aaYBEdHU3Hjq2zk1sIEZz8OXy0GviL1nqZUioBWKqU+kJrvdp2zCSgp/V1NPCM9b1JIiIi6Nq1q8/HP//NRs7/cjIxwy4g6sxHmvpxQgjRpvitaUhrvdN5da+1LgbWANkeh50JvKaNRUCyUirLXzE59cxMYKdOpSx/i78/Sgghgl6L9BEopboAQ4EfPHZlA9ttz3OpmyxQSk1RSi1RSi3xtfmnIT3bxbNedyR837ojfi8hhGjt/J4IlFLxwHvATVrrIs/dXl5Sp8dXa/281nqE1npERkbGEcfUISmGzaoT8WU7oKLkiN9PCCFaM78mAqVUBCYJvKm1ft/LIblAju15RyDPnzEBOByKkqSe5km+3BUIIUKb3xKBNSLoJWCN1vq/9Rw2E/itMo4BCrXWO/0Vk1t87awSDXtWN3ygEEK0cf4cNXQccBnwi1JqubXtDqATgNb6WWAWZujoBszw0Sv9GI+b1OxelK2PxJG3kqhhLfWpQggRfPyWCLTW3+G9D8B+jAb+6K8YGtKzfRLrdTZd8lYSFYgAhBAiSLSJmcWHo2dmAr/qHBk5JIQIeSGbCDqmxLBVdSS2Ih/KPQczCSFE6AjZROBwKMoTrdnI+zcGNhghhAigkE0EAOGZ1hDS1TMDG4gQQgRQSCeC1M4DmV8zGL3gCSjY3vgLhBCiDQrpRDAoJ4V/V1+Aqq2C3MWBDkcIIQIipBNB/+wkttLePPniHtjR5ArYQgjR6oV0IoiPCqdDRjrlKhoKt8ELJwQ6JCFEW1JTBYueCfpFsEI6EQAMzE4CXRvoMIQQbdHCp+Cz22HJtMaPrSyF1R/5PyYvQj4R9M1K5P6qSwIdhhCiLSovMN8rihs/dtatMOO3kPeTf2PyIuQTQb8OibxRczLb+l9nNlSVBTYgIUTb4VxHXTVYbcco2Gq+B2CCa8gngr5ZiQBsrUoyG2SWsRCi2TiXV/EhEQRQyCeC1LhI2idGs7nEqr9XXhjYgIQQbUdT7ghcL/JLKA0J+UQAMCQnmZ/3Wv/4kgiEEM2mCXcETUoWzUsSATCqexqbiq07gpcnBTYYIUTbcTh3BFruCAJiQHYihcSZJ7VVUFYQ2ICEEG2Lsp1qa6rg3iRY+LTnQebblu+gcAeUHWix8CQRAL3aJVCiY1wbdiwNXDBCiLZDe2kaqiwx3+f9n/fXfPswPNIP/tXFn5G5kUQAJERHEJOSxc+xR5sNu1cGNiAhRBvhpWmoptraVdPiV/71kURgGdEtg8vLb0EnZMEXd0N1ZaBDEkK0doeqFtgSQXW5+V5bY678H/dh0fQDW8x5qbamuSMEJBEcMrJrKgdKqyhN7m02SPOQEAJMQcp7kyD/V9i7vmmvPdQ0ZOsArrEuMrV1Ui/bb75761B2vv7Tv8D3j/mtSrIkAssxXdMA+LLzTWZDYW4AoxFCBI3vHzPfnzoKnhzRxBdbJ/Laatem6gprmw9X97t+gY1fQViUeV68q4mf7xtJBJac1BjS4yNZuNfqNC7cFtiAhBDBQR3BaVJ7SwTlzp2eH1T39c+NhtfPhvgM89xPF6iSCCxKKYbkJPPjjnKITYNVH0DRzkCHJYTwh+kXw2dT69//9qWwbrZ53JREUFHscdVunexrbImgxkv/46oPYf+m+t/XEWG+O0ccNTNJBDZDcpLZmH+QslE3m1uyRZ7jfIUQfrf5W6jwzwnvkHWf1v/3XVsDaz6G6Rea502ZDPbcWPhPb/f3AtcdQVWZ93pm71zuKjrnTeleSOwI4273PZYmkERgMyQnBYAF6b+B9gNNMhBCtJyinfDqafDhtYGLoarU/XlT7gj2b3R/XmstSFNZArW18H8d4H+/8e29uox2PS7eBVEJvsfRROF+e+dW6KiuKaTHRzFjyXbGtx8E6+cEOiQhQkvlQfN99+rAxeBZit6XRLD2U4hOrrvduTLZoqdNk1BTFsE6+e+w91f44Boo3gmx6b6/tonkjsAmKjyM0T3TWbG9ENoNgIP5kL/O7Mz/FbYtCmyAQrR5LV9npw5nMnJqLBHk/wpvXWyad5xePQO+ech9icrFL/oew1FXQ/Yw111A0U6Iivf99U0kdwQeerdP4IOfdlCS3Id4gKdGwpT58Pw4c8C9Up1UCL8JQMG1OpxNQ8phOnE9O2hra8AR5nq+baH5bp+Euvlr82UXGe9bZ++Ur6HDENdrAGoqXI/9QO4IPAzMNgvULKnq4tq4fHpgghEi1Djb1ANYkvlQ05BymIXnPa36AD75sytp7frZfK9o5CLRMwn89iPofJzreWJHuHWTKwmA+11Aek/f4j8Mkgg8jOiSQnxUOJ9vKIFx1vCyH59zHVArC90L4Tfehla2NGfTkAozV+KeZt1iFqOfcZkZFnqggdE+DWk/yP3nTcyCuDT3Y+z9Dsf88fA+xweSCDxEhYcxtlcGc9fsofbYG+se0FjWF0IcvkNt6n68I2jsYs55R+AIc80CtnMWiVvzMSx7FUp21/9efU6rf19EjG1yWT3SusMfFsDdB1yTyvxAEoEX43pnkF9cwfr91XV3yloFQviP8wrZ16ahn95svOn24N7GJ3TZVdnuCLwlArvdq8ygkvokZHnf3vtUkwhSuri2Db/S+7Ht+oPDv6dqSQRejOyaCsD8dXtcG6Osxe2DoGSsEG1WYydeTx9d1/Ccg4oSeKg7fGabiGVPBD88Z4758QUoyYcHOsGm+Wafw9F4PMteM0M7o5O8788Z6X17vzPN9zOfgoveNoNQhl7S8Gf5kSQCLzqlxjKySyrPfL2R2ks/gmu+hYvfNjslEQhxZLb9UH/NnOZoGqo86LoDWPuJ+b7qA3j2eJh9u/uQztm3wWd/Ne3+Xz9omn6XvWb2lRdCkS1OFQYXv2MeRyXCJe+6Orcz+rjH0O0E+P08GHQ+ZI+AAee5v0+3seZxdBL0PuXwf9ZmIsNHvVBKceHIHG6esYJf44+hT/tE2GfNGPRT9T8hQsa0CRARC3d6qeXVlKYhb0NNtYYnR5qr+Zt+MZOxwJRoKN1rqgUc59H355y89vOMhj8vazAkdzKPw6Ogx0lmvH9kPHQ8Ct62XdFHJ5p5AAC//9K1LXcJXPtt4z9bC5NEUI+jupjmoe/W7zWJILGD2fHRdXBgMwz8jZklmNk3gFEK4YOD+6C8wHQ8Bprz5G0v47DxKzOBMz7TlQhqq81JM3u4e1IoOwAfXgenP2aSidP+zaa8Q8eRrqv4+i7aPPsISvea7xVeagDZXfKOadcHyOxn4jr1P67Pt+t/Tt3Xn/ZIw+8fQNI0VI+c1Fj6tE9gzmprRECEbU3jbx4yE82ePiYwwQnRFE8Ohyd8WAXrcNybBPP/5fvxnm3utbWmzPITI8zJ1Nlss28DvDgeFjzhfvzSV2HdLLNGgPMEDvDkUfDGuVBi69erb3Gp1892f17gY8n5uHSIjIMrZ8P5r7rvc14oAty1F/qf5dt7Bgm/JQKl1DSl1B6llNcFgJVS45RShUqp5dbX3f6K5XBN6N+eJVv2s7ekgQ4jPy0dJ0Sz8Ve/lvN3f349i7B74zmpqtoaqllRCI8Pqdt3MO+f7k1A4dYCLdUV5k7nUCxWArG36ecu8R6DZ2E4u6wh9e9z6nwsxKS4b3PGNfgiCIto/D2CjD/vCF4BGusF+VZrPcT6+rsfYzksE/u3o1bDXOddwe++gONvdj9oXwO/VEI0h+0/Nv8Fx7RT4KPrj+w9PGvy+MKz+cWzwFveT+7Pq8uhdL/rufOEW1PhfkfglP+r67GvyzomZrseX/M13L0f7toHJ90Hf/m1/td5uvsAnOVlJnIr4LdEoLX+Btjf6IFBrF9WIh1TYvh8ldXWmDMS+nvcVm78suUDE6Fj+2J46WT4ugnNL77YthB+ev3I3sOzXDOYpp4aL/NvnOzrDKz9FJb/z2O/l3b6MttpxGF1ay57Df53ft1jN35pFnFRDtj+Q/1x2J35lPtzRxiEhcPxN0FCO7Nt0IWNv4/DEdjSGEcg0H0Eo5RSK5RSs5VS/QMcSx1KKSb2b8/3G/ZRXG7deqZ2dT/o18/lrkD4T4l1EdIca2M0d0E3b3cE0y+Ef6SZiZdVHrNmc5fA53e4nr91MXxxl/sxW7yMqNm3ET6+yaz+5fmenn79DHqMh8z+dTuF/7TM/blz1a8uo+HiGfDHH72/5z0FcM5z3ve1EYFMBMuAzlrrwcATwIf1HaiUmqKUWqKUWpKf38AsPj+Y2L89lTW1THjkG7MhKsE0ETltmmc64qZNgjfPh6K8Fo1PtHHKqnLZHE1D9vHzzcHzjqB0P6z/3Dz+V2d47UzTlv/Dc2bZxxfHez/RN2b6BbD0ZdNRXOVDc1T/syGlc93tKbaLuOFXwtRcM5ErLBx6TYSM3nVfA632Kr8pApYItNZFWusS6/EsIEIp5XXlBa3181rrEVrrERkZ/qu34c3wzqZTaGdhObuLrKuRnJHmF8g+JXzbAvNH8EoDtUWEu+2LzZeon7MWflMWNKmPtwJqvijaCWtn1d1e6ZEIPJtqti+Crd+bSVvTfWha8eS5DsCcO2HpK428Jgz6nu4a729nL9Mw+WGIiG56TG1UwBKBUqq9UibVKqVGWrHsa/hVLS/MoXjvD6MAWLHdo86Qt1+2/Rth7r2uRWx+esNMXxd1vXSS+RJGbW3dse/OuvfNkgisOwJfmogKtsMGq//rjXPhrYvqnvg9r853/lz3fQ566dBtTLJ1NZ9zdN19B7a4P5/8sOvx1V/CNd+YIZ7Ov017mWeAM54w5R3CZAqVnT+Hj04HFgK9lVK5SqnfKaWuVUo5C4OcB6xUSq0AHgcu1DoYVqWoq3+HJOIiw/hyzR6PHbaOY3txqe8egWkTze38R38009eFaMy3D5uFzwu2u7Y5myWaIxE4x/Dbm4jsj4t3wc4V5vGzx8Mb1qSo/ZvM98Jc+PY/sH6ueW7vG6socV+sxam+oaveLqKcTnsEjr4WLngDuo/3foyzySxnJJz9HPxuLnQcAe0HmO3OTuXUbmZc/x1Wk+2w38L5r9X/2SHKb2lRa31RI/ufBJ701+c3p+iIME4dlMWHy3dww0k9yU62JpeldoXbNpt6IZvmu/5wnHZ7nUIhhHfONbKL8iA5xzx29g3kLfP+mqZwNg1V24ZsVhRDrJlFz4snQ+E20zlaXuD6/MhY85rCbfClNcr7gjfcL3CKd7pOzk6Z/etPBPHt3SdyDbkUlr9hHvcYb74ARt9cz8g865oxKgEGe2l2GnCuGcgxbqoZ198Kx/a3pECPGmo1bjypFwCPfuExrjg21VwJ9Rhf9w9hh8cf7+5VsHWBH6MUPvnmYZh1W6CjcCk74Fob25Pzir280NVUA6b5cdPXXl9Sr73rzXf77N5y2/oahdaJec7fXNuqSk1TC7gvwPL2pe7vXZTnfkfQ70wzeay0nhHkzuTjNO5278dlD4eB58Pln8BY2zHOxoOoxPrf/9J3ISnb+37hRhKBj7KTYzhjcAc+W7mLgxX1jJPWHiM7PrnJ9fjHF+CZY+HlSU3/8C3fyQzm5vTVP8yqc+9e1fTX+uP/4cWTTMkSbxU37UMgnVfQe9aa5scPGii/7M2b55nOefskLvu4/TBrstZC24165UHX9vqSFZgmI+ddRHJniE0ziaDsgKm5f8dOuHEFnP+6qdppX3YxPNp9UpddRAyc+wJ0HQ0nTDWF5P6w0NW05FzcXRwRSQRNcNbQbIorqnnE867AF/bb6B3L4It76nba1dbAnjXu2zZ/C6+cCt/+t+mfKRq28r0mHv8+/D31yOaN1NaYK3J7k8m+De7H2C8oam0XHYXbzWLqudZ4d885Lb7Yv8l9VazyItj8jSkNHRZZ9/iXJ7lO8LtX1f++9oXada2pyFm6D36ZAXGZpnkppQv0OwN6nmyu8sEs13j7dt8XXknuBO36wRWfwjkvumYaiyMiiaAJjuuRztheGXy1dg9e+7V7T3Y9vuTd+t/ojXPh+0fNyWDDXHjmeKiuNFP+nz7GfaSFcxRJ/hrv7yV8s29j/SfwaafUberw5hfr/3TP6sOP47EhcH8m/KuLl3H91u+Us+mmosT9mG//A+9cbtr1wb0Qoq/Cwt3vCEr3wqunm9LQ3jqk929yrcC128uktvFeSoR1P9EkAqeY5LrHZA2CO3eZkszhXhJQY5JzYNBvmv464ZUkgiaa2L89m/YeZNYvXkrcnjfN9bjHSXWnrjs5x0cf2Awf/9n8gRVsgxXWdHv71WJzjho5XKX7TaJqyKunw4f+W1z7iD0xrP4KnNsWmvVnG+O8Onc0cYzF1gXw9LHmBFxo6yCdey98Yqtd5TzpV1eYK/8HsmHn8rrv50wEG+bCus/q/9xtP0Cex+tL98PzY13P37nC9vkN/B9HxLr3JziN/guMtt3tdj7ODOmMz3RtO/FvdV8HdRPZSffCmU/XH4PwG0kETXTBUTn0yIznyXkb6t4VRMTAjT/DlPnmBD70Uvc/EqdIq476gS1msQpwlRIA84f+0xtmVaXGEkF5ESx6pu6C3F/cDW9f1sSfrh7/7up+wvBm8zeuUR+Nqa5sfAHxlvLxjY0f4+RssvEcFNCYWbfCnlWuzlqnhU/Ckpdcz50n4uoyV1Pi2k/rvp99jdzpF0DhDrPMouc4/mkT3E/64F7iwVNtAzOPu59Y/77xd7l+zzN6myv8QedDp2PhgjfNgi6+OP7PAV2uMZRJImiiMIdiyuhurNlZxAc/7ah7QEpn6DDU9dzbbE5np9/+za61Tu3ldytLzPyDd66Ar+432+qbYvHlfWY9VufUfqfvH4M1M336mSjJh6/+6b0j1HmVus7LCelw3Z8B79pmZTfnqm95y+GdK30vp+A5U3XhU/D9496Pdd4ReJ4wtTb9DTNv8F5/p7aBImx2ziahX951neyLvPyOlex2f/5IP7PmwHOjXds8J385OZNNQ+P4vel8bN1t0bYmH+cooJ4TzffIOLhqNvSVmfatgSSCw3DW0GxGdE7hnpmr2NfQWgXgvQPO6at/mCn44D4iw16h0TmZZ81MswiI5x+48/n0C+uW9PXVxzfAN/92zYa2K29k1aamcia01bbSUv/pDb/OMT+fZxlip+fGmgWBwDRRLHvNe3J88SRY9X7dGai++vwOUwht+f/gTY82aGei9Px3XjPTjEBa9io80t8USPP2utJGJs47E0GxlyUc7XK9LLjibLZZ8wn8I6PuvAPPu5iL3m74M+yiEl11eCb80/R/jb4FbrX1uRx1tVmwJQjW3xVNJ4ngMESGO3jgnIGUVtbw7NeNjCA5/mbvzUOeVr3velxeUP9xBz2K7jnHeIP3UTAVJXW3eXJekXubdOOMxbPui9O+jU2rS++tdDG4+kc2zqu7r2inaSt33h0tew1m/sncWe382YzCct4BOK/WPa+anXydvP7hH1wTvJycJ/RqjwqYzmQNpn9n6cumueazO2D1TNuiKV6u7u2ci6o01h9T3EBhw7cvMVf9Pzzrvn3QBe7PPcfxezNuqim/fNbTps/r8o/hmOvMqJ/xd7mXaQiP8n7XIFoFKbhxmHq2S+CE3pl8+vNOpk7qi8NRT4XCqHjzR1O0A1ZMr/8N7VewDQ1rLNvvXlnRnggWPWtOAoNtk7of6Giu3OLS3N9n7wb46TUYcJ7r5FxbbfoltIYB1ixp55VmuJcCXVqbDtiG2o89efUpeCQAACAASURBVOtwBNdVtnKYZFCYC8OsPo7t1p1KnNUB6SyDUFniag4JjzHVJJ2Kd5mvH56FE2ydlRu/qj+2z6bW3VZTZU78O5aawoL2WKvKrdr1Xu76Hulnvi96CmKtWoof+diZXtIMTWWend9710HPCa7kFpNi6vK8eb775130lkmiPSdCYpb7e3Qdc+RxiaDk0x2BUupGpVSiMl5SSi1TSk3wd3DB7owhHcgrLOfumT6UkjjzaTOZBswMyam5MPav3o/dMLf+97GPKNq/yQxDddr9C3zyZ4+OXe2+fF9Jvqlt/+Rw04/w3GjIX2v2VZWa1757JSx40pzoDyUCL+O1nSfEhk6uTuVFZvWo+pqa7Hcur58FM693Xb07O1md7dqHEoHt7qK6zD3JFO80J/bvHjHlP5ycZUAy+9WNYZGXESsVxfDGeaakstPnd5gT7T/bmU75hpr/wPtKWg3xvOsDU67BG8+FkjzdkWdm+U76t1l83Sk8ynTi/m6OmTA26SFTlqHnRBh+Rd0kINo0X5uGrtJaFwETgAzgSuBBv0XVSpw+KIuLj+7EG4u28dO2RtaFdTigz2mm4NXY28yMyCEXm331Fdbyxj5l/9c53o/Z8p3787IDZr2EaZPg4R6moJg3u23j4+fcaa7K67sjqCg2x3iqqTJNNp5rz752Bjx1lPcVqAC2WjHb9zvnU9hH21QedD33rH5ZUeQa2lm8yzXSyrOZBNyHNzbkxxdcdyRONZWueQebv3GfENZYM+BV9fyfeQqLclXhBPj9V3Cll6GipzYy0TAyzvzOdRxhnl+/1NQJckrpDHftgaOnmOHPvk7sEm2Kr//rznaPycDLWusVeJ0PH1qUUvz1lD5kJEQx9X0fVpByOMzVmbMmS0oXuHO36Xwbf7e5dXc68S5XxUS73Svh6VHw9UP1L5jhebVbdsA0a2xrpM6R52pR9hmwnolg/oOwZBp1VJbAowNNp6mdsxO4vtoz9lidHh1gmomcbevV5bBrJYcmXnl2nJcdcI3QKd7lKj+w4QvqiPMxETS2MPvule6JJmuQ+d6rnlIimX19+9zkTu61eyKi3ZsBnRoqseDtrie9h6nXL4SNr4lgqVJqDiYRfK6USgCCZCB4YCXFRHDduO6s3VXM7e/9TE1tEytpR0SbBDH6L+637p2P9f6H//MMM7N13v2w4Im6+9N71+1srq8CZGMqCl0rrnnODnVOaqrzGi+d04W2TlLnKKn62EfWVJeb5ivnXUJVqatZCOqOrrEvClS8q+EmNvsdwVFXux53PKrh+BrT+1STxM+ympkG/sYsgwgmmdr/T4dYY+ad5RbAtYpWu351/y3tQ2Kdd5dhEXDey9BuIFxruxM87VFThkEIH/jaWfw7YAiwSWtdqpRKxTQPCeD0wR247+PVvLV4O2N7ZTBp4BG0r577kplMlnOM9/32kSeF2+vuT+0KWxe6bytsZLRKfV6wdQLXmWNQT8LbscT9ecE29/b15W82/Jmecwry17lGyVSVmUSgwszkrk9vdj/W3lS01aN5zJNzDHxqN7O+LkBchjmBfv+YqZHTVDnHmJE0Y6zmoZvXmI7i8Ejz/9phqPtV/phbzM836ALzeR2Gwu/nmcEC3U80d1FvnGMmZgG0s91l5Yw0d5dgOvadnfs3rzUXFzEpTY9fhCxf7whGAeu01gVKqUuBvwH1DP8IPenxUXx72wnERITx8Jx1lNRXndQXA8+D337oaqu98WezuDZAtxMaf31KV3Mlb2evJqkc9TdbNKS6wrdJWvaO6opi00xkH17Z2Fh6e416cB8qWVFimnkaG6YY48PQyPBI015/1RxTCA3MWtTtB0Cc1xVTjatsE/eckwGdfucxqS+xg6uOzsDzIK27a1/2CJOEfv+lq9RCeLRp7ht4nhne2WO8WRL1qtlmf0Q03LUPTv2PGcbpTWKWJAHRZL4mgmeAUqXUYOA2YCsgy/zY5KTGcv9ZA9iYf5D/zGmgXG9TpXSGS9+Hc16Ayz4wnX0XvwMZfVzH2OuzeGsGso97j02Dc56vv/5Lffaugwc7mzb76grfah890LFpn9H/nIYnU1UWm6GNjY2U6Xem9+3Dr4Aka+RRWCR0OhriM8zx9xS4qnnG2obadjsBRl0PY26FPy2DtB5me2SC94JrvrhlvRmT79Suv0kC9dXktwsLN01ZstCKaEa+JoJqaxnJM4HHtNaPAVII3MO5wztyxuAOvLpgS931jY+Es3aLUqazr9cE04QB5oQ09BI45V9m9NEQaw7B4IvNCBrnVauzc7Sm0tQ3GnOr758/1BohU3XQVMC8P9M0Xx2pcVNhxO/MifZPy6BTPc1hnpyzXOuTc7Rr9NBNv8CE+6HrWBh3h2vlL88Tqb3j3VlFts9pZlz9xH+axJnW3dxt9D0DLppuTsh3HsaY//hMV70pMP0vf9sN3cY1/b2EaAa+9hEUK6WmApcBo5VSYYBcknhx7xn9mbkijzOf+p7Vf59IbKSf5uzFZZjvSdZV9zHXmi8wzQkAZz8Djw02Q0AHnW+aiOxj7bMGuzpfI+PhrGdghpdCdTW2pq4t3x5evN1OgE0es4Z7ToBsW0VQzxm79UnKaXh/dZlZQrS6wlzxH/sn8wXmZL71+/pr8YDpqL1rr/erbocDLnjd9TwiBi77sOHZ4EIEOV/vCC4AKjDzCXYB2cBDfouqFUuNi+TUQaaz+MSHv2ZTvg8lHg7rg7qZK+kLG+l8dU52GnZ53X2/nWmam9oNgD8sMG3l9ivcjiPh0vdcC6G0G3h4sV79pbkqd8oabIbOth/kfly7/nDcTeZO4USPoaz2MfWJHcyJ+m97zJX61B2m7d5ZRqHz8eauJz6jbizO/hZvk7bsmtL00v2ExpurhAhiyusCK94OVKod4Bxb96PWeo/fomrAiBEj9JIlSxo/MMD+MmMF7y3LJTrCwU93TSAmsomli5tL/jqz1u2o60xRtz6nNZ48vn/cjHfvebJ5/sU9ZgbzgHOt8hcK0OYuIjzafebs0MvM5zk7eX87E7qNNVfn91vNU2NvN8sONuajP5omqPYD4bxXoGCrWQnr5L838R/BprbGlO0ecrFv9XaEaCOUUku11iO87vMlESilzsfcAczHnAVGA7dqrRtYhss/Wksi0Fpz3ZvLmL1yF3dM7sOUMd0bf5G/VZWbK11HE5NSba0pp52/FqZfDOe+CK9MNkMie51iKnXOvtV0avewZkm/fg50OR5G24Z4zv+XmaA1+hZTf8mXeIvzzN2PEOKINEciWAGc7LwLUEplAHO11j6uONF8WksiAKisrmXcQ/NIjIlg9o2jUfXNBG6NKg+6T44q3AFJ9SxA7vTzO/D+1XD64zDcS1OVEMJvGkoEvvYRODyagvY14bUhKzLcwV8m9GbtrmJ63DmbDXvqmY3bGnnOem4sCYAZH3/ZBzDst/6JSQhxWHw9mX+mlPpcKXWFUuoK4FNglv/CajvOHprNOUOzqanVXPj8IsoqvawCFiqUMjNm29KdkRBtgE+JQGt9K/A8MAgYDDyvta6nhrKwczgU/71gCM9cMoy9JZVc8fKPVFSHcDIQQgQdn5t3tNbvaa1v1lr/WWv9gT+Daosm9m8PwA+b9zP4vjks3dpIFU4hhGghDSYCpVSxUqrIy1exUqqZF7Nt2xwOxfTfm5mz5VW1PPf1pkZeIYQQLaPBRKC1TtBaJ3r5StBaJ7ZUkG3FqO5p/HDHeMb2ymDO6t30v/uz5i1FIYQQh0FG/rSwdonR3DC+J33aJ3Cwsobr3lzGvHUBmZsnhBCAJIKAGN45hc9uGsOHfzwOgCtfXsxnKxuouimEEH4kiSCAhuQkM+uG0WQlRXPD9OVs2OOnukRCCNEASQQBlhQbwYd/PI7oCAcn/fdrxv9nPkXlPiwAI4QQzUQSQRBolxjNExcPIzrCwcb8gwy6dw75xRWBDksIESIkEQSJsb0yWHnvxEPPj/rnXD5afphrDQshRBNIIggi4WEONj8wmX+fN4hBHZP489vLeevHbY2/UAghjoCfls8Sh0spxfkjcjhtUBZXvLyY29//hbzCcuKjwjh3WEfS4qMCHaIQoo3xeWGaYNGaylAfqfKqGi58fhHLbZPO5t48hh6Zsly0EKJpmqMM9eF86DSl1B6l1Mp69iul1ONKqQ1KqZ+VUsO8HRfKoiPCePWqkVw3rjuje6YDcPZTC/h1dxsqZy2ECDi/3REopcYAJcBrWusBXvZPBv4ETAaOBh7TWh/d2PuG0h2BXWllNQ/OXsvMFXlUVtdSWlnDkJxk3ppyDFHhjra16I0QotkF5I5Aa/0N0FCJzTMxSUJrrRcByUqpLH/F09rFRobz9zMH8PH1xzMgOwmA5dsL6HPXZ9zw1vIARyeEaM0COWooG9hue55rbatDKTVFKbVEKbUkPz+/RYILVjmpscy4ZhRzbx5Dr3bxAHy8Io9rX1/atlZAE0K0mEAmAm9tGV7bqbTWz2utR2itR2RkZPg5rNahR2YCc/48lvm3jAPgs1W7OOm/3/Dw5+tYuHFfaK+EJoRokkAOH80FcmzPOwJ5AYql1eqSHsfxPdL5bsNeAJ6ct4En520A4Jqx3Ti6ayo9MhLolBYbyDCFEEEskIlgJnC9UuotTGdxodZaSnAehjeuNn3sxeVVvL5oK0u2HOCrtXt47utNhxbA+fSG4+nfISmQYQohgpTfEoFSajowDkhXSuUC9wARAFrrZ4FZmBFDG4BS4Ep/xRIqEqIjuG5cDwC27y9l9L/nHdr3tw9X8tTFw+iQHBOo8IQQQUomlLVhOwvL+N8P28g9UMYHP5m6Rd0z4thRUMaUMd25blx3DpRWkpUkyUGItq6h4aOSCEJAba3mxy37mbF4O+//VLeQ3ZtXH82obmk4HDIXQYi2ShKBAEBrTUFpFd9v3Mv1//vJbV9cZBiPXzSUrKQY+nWQ5aiFaGskEYg6Siur6Xf35173XXpMJ+45vT8RYVKcVoi2IiAzi0Vwi40MZ9ldJwPwjzP7M7aXmZ8RExHGG4u2ceNbP7Eqr5ADBysDGaYQogVIGeoQlhoXya/3TyIy3MEx3dI4plsa147txrNfb+Lfn69l1i+7AOiUGsttp/SmfWI0wzunSF0jIdoYaRoSXq3bVcyfpi/j190ldfbdML4nU8Z0I9yhiI4IC0B0Qoimkj4Ccdi27y/lYGU1m/IPct2by+rsv+LYLtwwviepcZEBiE4I4StJBKJZVFTXUF5Zy1PzN/D8N5sObR+YncT6PcU8eM4gzhqajdZamo+ECDKSCESzq6yu5d2ludzxwS9u26MjHPRql8CfT+pF1/Q4uqTHBShCIYSdJALhN8u2HeCcpxcAEOZQ1NS6/z798YTudEuP5+yh2TJhTYgAaigRyKghcUSGdUph5X0TqayuJTUukn0lFcxeuYu/fWhWKH1q3kYANu0toV9WEhrNhH7tiQyXkctCBAu5IxB+sX53MW/+sI2isiqvZS3G9srg8YuGkl9cTo/MhABEKERokaYhEVBLtuznmfkb+WZ9PkkxEewtcZ+kNmlAe+46rZ9URhXCjyQRiKChtWbMQ/PYVVhOl7Q41u9xzVM4qW8mXdPj6NchkTMHS5+CEM1JEoEIWsu3F3Dpiz9QUlHttj09PpKT+rYjPiqca8Z2JyMhKkARCtE2SCIQQW/7/lJ2F5Xz+Fcb+ObX/Dr7rz+hByf0ySQ+KpyDldUM65QSgCiFaL0kEYhW5au1u3lv2Q4+/bn+lUuvOq4rR3dLZXjnFNLj5W5BiMZIIhCtUkFpJSt3FDGyayoTHvmaLftKvR734DkDGds7Q1ZaE6IBkghEq7d130FeWbCFs4Zks2TrAf7xyeo6x5w5pAMDs5M4sU8m3TLiAxClEMFLEoFoc56at4GHPl/HuN4ZrNxRWGdIaqfUWI7plsqdk/uRFBsRoCiFCB6SCESbU11Ty66icrKTY1BKsW5XMW8t3sbL32+pc+yEfu149MIhrNlZTPukaLJlvoIIQZIIREjZVVjOwk17+WptPh+vyKuz/8bxPbl2bHfKq2pIkfLZIkRIIhAhqbC0ineWbuel7zazs7Cc6AgH5VW1bsd0TInh1IFZ3D6pj5TOFm2aJAIR0orKqygqq6JDUgz3f7qG+Ohwlm7dT1FZNb/sKAQgNjKMMT0zrOJ4ifzrvEFEhcvqa6LtkEQghBflVTVs2XeQpVsPsHxbAe8szXXb/+ylwxnXO4MlWw5wfM/0AEUpRPOQRCCED6b/uI1/f7aWA6VVdfZddVxX7jqt76Hmo12F5bRLjJLmJNFqSCIQogneXryNr9bu4fNVu922d0uPY9Peg4ee33dGfy4/tksLRyfE4ZFEIMRh2rCnhK37DrJ8ewEvf7+lTnG8lNgI/nRiT646vmuAIhTCN5IIhGgGVTW1bNhTwivfb+HtJdvd9vXNSqRvVgI9MuNZvq2A34/pRq/MBJnMJoKGJAIh/ODmGct5f1nd1decerdL4MXLRxATGUZUuIOEaEkKInAkEQjhR/tKKjhYUcMXa3Yz/cdtbLAtthPmUNTUmr+xuMgw/nHWAM4Z1jFQoYoQJolAiBZUXVNLrYZfdxdz38erWLzlgNv+q47ryrfr8+mblcgdk/vSPik6QJGKUCKJQIgAKa+qYdYvO1EKVu0oYuaKPPYUV7gdc/XxXdlZVM5N43vSs11CgCIVbZ0kAiGCRHVNLVU1mtLKas57diGbbcNRAcb1zuBgRTXxUeFcf2IPBndMJjzMEaBoRVsiiUCIILV9fykzV+TRIzOeR+euZ83OIrf9HVNimDqpLyf1y5SSF+KISCIQopUoq6zhtYVbeGD22jr7UuMiD63dHO5QzPplJ5MHZpGTGtvygYpWRxKBEK3IgYOV3DxjObdM7M0lL/5AgZeSF04xEWEsv+dkuVsQjZJEIEQrV1VTy+yVu7hh+k+kxEbUqYc0umc6ybGRdEiOZuqkvgGKUgSzhhJBuJ8/+BTgMSAMeFFr/aDH/nHAR8Bma9P7Wuu/+zMmIVqjiDAHZwzuQHp8JMM6pbD/YCXLtxewfncJS7buZ/m2Aoqt8hdllTX86cSeLN26n4yEaIbmJONwKApKK4mOCCM6Qu4ehDu/3REopcKAX4GTgVxgMXCR1nq17ZhxwC1a69N8fV+5IxCirrLKGkorq7nxreV8t2Fvnf2juqWxcNM++rRP4LObxgQgQhFoDd0R+HNc2khgg9Z6k9a6EngLONOPnydEyIqJDCMtPornfzucOyf35fJRnYkMd/15L9y0D4C1u4r512dr2VNUztZ9B+t7OxFi/HlHcB5witb6auv5ZcDRWuvrbceMA97D3DHkYe4OVnl5rynAFIBOnToN37p1q19iFqItKa+qYeaKPG579+dD2zxLaU/s346u6fF8vmoXFx6VwzVjuwciVNECAtJZrJT6DTDRIxGM1Fr/yXZMIlCrtS5RSk0GHtNa92zofaVpSIimW7BxL0d3TaOsqobLXvqBNTuLyEyIZtv+0jrHnj00m3G9MzimWxqRYQ7Cw5QUzGsDApUIRgH3aq0nWs+nAmitH2jgNVuAEVrruo2cFkkEQjSPmlrNG4u2cnS3VDqnxvHbaT+wZOsBvJ0STh2UxRXHdmFITjIRMtO5VQpUIgjHdBaPB3ZgOosvtjf9KKXaA7u11lopNRJ4F+isGwhKEoEQ/jVv7R6ufGWx133DOiVz3bgeDOqYRGaiFMtrTQIyfFRrXa2Uuh74HDN8dJrWepVS6lpr/7PAecAflFLVQBlwYUNJQAjhfyf0yWTuzWN4Zv4mjuqSQqfUWB6YvZZe7RL4cu1urn7NXIhdeVwXftpWwPDOKfTMjCctPoqYiDCO75ke4J9ANJVMKBNC+KygtJIhf/+iwWO+vnUcq/OK+L/Za/jsxjHERfl1upLwUcAmlAkh2pbk2Eg2PzCZEffPpaSimttO6UO4Q/HM/I3sKioHYOxD8w8d/82v+Tgcio4pMfTLSkQpFaDIRUPkjkAI0WSFpVVU19aSFh/ltn3Oql1MeX2p19e0S4zijsl9SY+PIicllk5pUiyvJUmtISFEi9FaU1Ormbkij5tnrCAhKvxQ+Qu7207pzYvfbuaaMd04e2g21bWaDskxAYg4NEgiEEIExLpdxfTMjOdAaSWFZVVc8/pS1tvWdPY0umc65wzLJiYijKykGAbnJLdgtG2bJAIhRNCoqdXMXrmT//t0DSf3a8erC+uvFHDN2G5cMCKHvIJyjuuRJn0MR0ASgRAiaC3YsJdFm/aRmRiNUnDnByu9HpcSG0GntDhO7pvJecNzaJ8k8xiaQhKBEKLVWJ1XRIfkaOas2s3gnGRe/HYT7yzNrXNcz8x4pk7uQ0xEOKlxkXRKjSUmUkps10cSgRCiVfth0z7W7iqmsKyKE/tkcvm0H9l3sNLtmIgwxbQrjmJk11QOVpiy3B1TZGSSkyQCIUSbUlldy/6Dlby3LJeHPl9X73Fje2UweWB7hnZKoUdGPA5H6PYxSCIQQrRZuwrL0Wge/3ID03/c1uCx828ZR5f0OKpratlZWE5WUjTVtTokVm2TRCCECAnrdxcTEebgyXkbSIgOZ2inFF76dhMrcgsBSIwOp6SimlrbaS87OYbzR+TQNyuBkV1TSY6NDFD0/iWJQAgR0mprNZ/8spMbpv/U6LGPXzSUUd3SSIuLbFNNSVJrSAgR0hwOxRmDO7BxTwlvLd7GgtvH88PmfXRIiuG2935m8Zb9h9ZhcCaLXu3iOWNwB7JTYkiLi+K4HumEtaHEYCd3BEKIkGY/B36+ajfz1u6hVms+W7nLa2mM0wd34P6zBnCwoprdReUM7ZTSkuEeNmkaEkKIJqqqqWXb/lIKSiv5eMVOXlmw5dC+qHAHFdW1AGQlRTO4YzLXjutOQWklQ3NSSIoNvqU9JREIIcQRKiit5EBpFVv2HmT2yp10TInlv1/8Wue4Pu0TSIyJYE1eEUd1TeX2SX3onhEf8GYlSQRCCOEH+cUVRIY72L6/lK/W7mHHgTLeXZZLTa37eTUhKpzYqDCyk2O44KgckmMjmdi/fYvGKp3FQgjhBxkJZj2GpOwkBmQnATChfzsWbznApvwSpozpxmcrd/Hid5sprqhmd1EFy7YVHHp9dISDZy4ZTr8OiWQmRAWsqJ7cEQghhJ+tziviro9WsnTrgXqPGZyTTHxUGD0y4hnVPZ3jeqSREG36GrTWR5wkpGlICCECTGvNkq0HGJqTTHiYg6Vb9/Pu0h1EhTtIjo1gxuLt5BWWu70mOzmGoZ2S2bCnhP4dknj4N4MOOyFIIhBCiFZgV2E5by3exjtLcumWEceqvCL224rr3X/WAC49pvNhvbf0EQghRCvQPimam07qxU0n9QLMXcTnq3YTFxXGjCW5pHusEd1cJBEIIUSQUkpxygAzumh0zwy/fY7Db+8shBCiVZBEIIQQIU4SgRBChDhJBEIIEeIkEQghRIiTRCCEECFOEoEQQoQ4SQRCCBHiWl2JCaVUPrD1MF+eDuxtxnD8TeL1n9YUK7SueFtTrNC64j2SWDtrrb3OSmt1ieBIKKWW1FdrIxhJvP7TmmKF1hVva4oVWle8/opVmoaEECLESSIQQogQF2qJ4PlAB9BEEq//tKZYoXXF25pihdYVr19iDak+AiGEEHWF2h2BEEIID5IIhBAixIVMIlBKnaKUWqeU2qCUuj3Q8QAopaYppfYopVbatqUqpb5QSq23vqfY9k214l+nlJrYwrHmKKXmKaXWKKVWKaVuDNZ4lVLRSqkflVIrrFjvC9ZYbZ8fppT6SSn1SSuIdYtS6hel1HKl1JJWEG+yUupdpdRa6/d3VDDGq5Tqbf2bOr+KlFI3tUisWus2/wWEARuBbkAksALoFwRxjQGGAStt2/4N3G49vh34l/W4nxV3FNDV+nnCWjDWLGCY9TgB+NWKKejiBRQQbz2OAH4AjgnGWG0x3wz8D/gkmH8PrBi2AOke24I53leBq63HkUByMMdrxREG7AI6t0SsLfrDBeoLGAV8bns+FZga6LisWLrgngjWAVnW4yxgnbeYgc+BUQGM+yPg5GCPF4gFlgFHB2usQEfgS+BEWyIIylitz/SWCIIyXiAR2Iw1MCbY47V97gTg+5aKNVSahrKB7bbnuda2YNROa70TwPqeaW0Pmp9BKdUFGIq50g7KeK2mluXAHuALrXXQxgo8CtwG1Nq2BWusABqYo5RaqpSaYm0L1ni7AfnAy1bT24tKqbggjtfpQmC69djvsYZKIlBetrW2cbNB8TMopeKB94CbtNZFDR3qZVuLxau1rtFaD8FcbY9USg1o4PCAxaqUOg3Yo7Ve6utLvGxr6d+D47TWw4BJwB+VUmMaODbQ8YZjml+f0VoPBQ5imlfqE+h4UUpFAmcA7zR2qJdthxVrqCSCXCDH9rwjkBegWBqzWymVBWB932NtD/jPoJSKwCSBN7XW71ubgzZeAK11ATAfOIXgjPU44Ayl1BbgLeBEpdQbQRorAFrrPOv7HuADYCTBG28ukGvdEQK8i0kMwRovmAS7TGu923ru91hDJREsBnoqpbpa2fZCYGaAY6rPTOBy6/HlmLZ45/YLlVJRSqmuQE/gx5YKSimlgJeANVrr/wZzvEqpDKVUsvU4BjgJWBuMsWqtp2qtO2qtu2B+L7/SWl8ajLECKKXilFIJzseYtuyVwRqv1noXsF0p1dvaNB5YHazxWi7C1SzkjMm/sbZ0J0igvoDJmJEuG4E7Ax2PFdN0YCdQhcnuvwPSMB2H663vqbbj77TiXwdMauFYj8fcdv4MLLe+JgdjvMAg4Ccr1pXA3db2oIvVI+5xuDqLgzJWTJv7CutrlfNvKVjjtT5/CLDE+n34EEgJ1ngxgxv2AUm2bX6PVUpMCCFEiAuVpiEhhBD1kEQghBAhThKBEEKEOEkEQggRaJk4nQAAAcZJREFU4iQRCCFEiJNEIEQLUkqNc1YYFSJYSCIQQogQJ4lACC+UUpdaaxosV0o9ZxWxK1FK/UcptUwp9aVSKsM6dohSapFS6mel1AfOevFKqR5KqbnKrIuwTCnV3Xr7eFt9/DetWdtCBIwkAiE8KKX6AhdgiqsNAWqAS4A4TA2YYcDXwD3WS14D/qq1HgT8Ytv+JvCU1nowcCxmFjmYyq03YerJd8PUGxIiYMIDHYAQQWg8MBxYbF2sx2AKfdUCb1vHvAG8r5RKApK11l9b218F3rHq8WRrrT8A0FqXA1jv96PWOtd6vhyzJsV3/v+xhPBOEoEQdSngVa31VLeNSt3lcVxD9Vkaau6psD2uQf4ORYBJ05AQdX0JnKeUyoRD6/F2xvy9nGcdczHwnda6EDiglBptbb8M+FqbtRpylVJnWe8RpZSKbdGfQggfyZWIEB601quVUn/DrMLlwFSH/SNmUZP+SqmlQCGmHwFMaeBnrRP9JuBKa/tlwHNKqb9b7/GbFvwxhPCZVB8VwkdKqRKtdXyg4xCiuUnTkBBChDi5IxBCiBAndwRCCBHiJBEIIUSIk0QghBAhThKBEEKEOEkEQggR4v4fN1v5lkK/QnkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\git_repo\\Project-Final\\saved_models\\Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 46.86%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting emotions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.5847552e-02, 3.5662955e-04, 1.9684581e-01, ..., 5.8119758e-09,\n",
       "        1.0832265e-07, 1.4073287e-07],\n",
       "       [9.9496776e-07, 4.0785052e-11, 9.6166897e-10, ..., 1.4188084e-02,\n",
       "        6.3523546e-02, 7.4735438e-03],\n",
       "       [7.6222612e-04, 6.0384840e-01, 4.4709761e-04, ..., 2.8866523e-07,\n",
       "        1.0658275e-08, 1.4011290e-05],\n",
       "       ...,\n",
       "       [8.0707883e-03, 2.7532911e-02, 1.4915332e-04, ..., 1.9111853e-08,\n",
       "        1.9480867e-06, 7.1967420e-08],\n",
       "       [1.0579091e-02, 9.3216473e-01, 1.0116033e-02, ..., 8.6885387e-07,\n",
       "        2.5363929e-06, 6.4039887e-06],\n",
       "       [3.5705277e-01, 1.8723211e-01, 2.3336728e-01, ..., 2.1445342e-06,\n",
       "        1.4633004e-04, 5.3128629e-04]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 1, 8, 4, 1, 6, 1, 1, 3, 3, 1, 9, 1, 4, 4, 8, 8, 3, 4, 2, 8,\n",
       "       1, 5, 8, 6, 6, 5, 2, 2, 1, 4, 6, 0, 6, 7, 1, 6, 9, 8, 9, 4, 8, 0,\n",
       "       5, 7, 3, 5, 5, 0, 1, 8, 4, 8, 0, 7, 8, 8, 1, 6, 0, 2, 7, 8, 9, 2,\n",
       "       5, 2, 6, 0, 7, 8, 3, 8, 2, 8, 2, 2, 3, 4, 9, 9, 6, 3, 8, 8, 6, 4,\n",
       "       5, 6, 9, 3, 8, 8, 6, 5, 5, 5, 1, 4, 5, 3, 3, 8, 2, 2, 8, 7, 8, 0,\n",
       "       4, 3, 3, 8, 2, 6, 2, 1, 6, 6, 0, 7, 2, 5, 1, 5, 9, 4, 8, 8, 3, 2,\n",
       "       8, 8, 5, 6, 8, 5, 1, 6, 3, 3, 4, 9, 3, 0, 8, 8, 4, 2, 2, 0, 3, 8,\n",
       "       5, 2, 8, 2, 1, 1, 8, 8, 8, 6, 5, 2, 5, 8, 1, 6, 5, 8, 3, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predictedvalues\n",
       "0      female_sad\n",
       "1      male_angry\n",
       "2     female_calm\n",
       "3      male_happy\n",
       "4      female_sad\n",
       "5     female_calm\n",
       "6       male_calm\n",
       "7     female_calm\n",
       "8     female_calm\n",
       "9    female_happy"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actualvalues\n",
       "0  female_happy\n",
       "1    male_angry\n",
       "2    female_sad\n",
       "3    male_happy\n",
       "4    female_sad\n",
       "5    female_sad\n",
       "6     male_calm\n",
       "7   female_calm\n",
       "8   female_calm\n",
       "9    female_sad"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual v/s Predicted emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>male_fearful</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>female_fearful</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>female_calm</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       actualvalues predictedvalues\n",
       "170      male_angry      male_angry\n",
       "171    male_fearful      male_happy\n",
       "172    female_happy    female_happy\n",
       "173  female_fearful     female_calm\n",
       "174     female_calm    female_angry"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf[170:180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_calm</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_calm</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predictedvalues\n",
       "actualvalues                   \n",
       "female_angry                 11\n",
       "female_calm                  23\n",
       "female_fearful               17\n",
       "female_happy                 21\n",
       "female_sad                   10\n",
       "male_angry                   19\n",
       "male_calm                    18\n",
       "male_fearful                 13\n",
       "male_happy                   26\n",
       "male_sad                     17"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictedvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_calm</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_calm</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 actualvalues\n",
       "predictedvalues              \n",
       "female_angry               11\n",
       "female_calm                19\n",
       "female_fearful             20\n",
       "female_happy               18\n",
       "female_sad                 15\n",
       "male_angry                 20\n",
       "male_calm                  19\n",
       "male_fearful                7\n",
       "male_happy                 37\n",
       "male_sad                    9"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The file 'output10.wav' in the next cell is the file that was recorded live using the code in AudioRecoreder notebook found in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('output10.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x20d6df80550>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# % pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#livedf= pd.DataFrame(columns=['feature'])\n",
    "X, sample_rate = librosa.load('AudioFile/03-02-05-01-01-01-07.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "featurelive = mfccs\n",
    "livedf2 = featurelive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2= pd.DataFrame(data=livedf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2 = livedf2.stack().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.463947</td>\n",
       "      <td>-32.431175</td>\n",
       "      <td>-31.96899</td>\n",
       "      <td>-33.014484</td>\n",
       "      <td>-35.74715</td>\n",
       "      <td>-34.635471</td>\n",
       "      <td>-33.296459</td>\n",
       "      <td>-24.63722</td>\n",
       "      <td>-19.529123</td>\n",
       "      <td>-15.690511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows  216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "           0          0          0          0          0          0   \n",
       "0 -54.311943 -54.311943 -54.311943 -54.311943 -54.311943 -54.311943   \n",
       "\n",
       "         6          7          8          9    ...        206        207  \\\n",
       "           0          0          0          0  ...          0          0   \n",
       "0 -54.311943 -54.311943 -54.311943 -54.311943  ... -31.463947 -32.431175   \n",
       "\n",
       "        208        209       210        211        212       213        214  \\\n",
       "          0          0         0          0          0         0          0   \n",
       "0 -31.96899 -33.014484 -35.74715 -34.635471 -33.296459 -24.63722 -19.529123   \n",
       "\n",
       "         215  \n",
       "           0  \n",
       "0 -15.690511  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livedf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "twodim= np.expand_dims(livedf2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "livepreds = loaded_model.predict(twodim, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.2869291e-06, 7.0907280e-10, 4.6659920e-10, 6.9979293e-13,\n",
       "        1.0852528e-08, 9.7627568e-01, 9.5520569e-05, 1.0852168e-02,\n",
       "        8.5640255e-05, 1.2685582e-02]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "livepreds1=livepreds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveabc = livepreds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male_angry'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepredictions = (lb.inverse_transform((liveabc)))\n",
    "livepredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
