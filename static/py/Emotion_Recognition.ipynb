{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\Anaconda3\\envs\\may\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist= os.listdir('../../Resources/data/AudioFile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-01-01-01-01-01-19.wav\n"
     ]
    }
   ],
   "source": [
    "print(mylist[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03\n"
     ]
    }
   ],
   "source": [
    "print(mylist[400][6:-16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the audio file's waveform and its spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('../../Resources/data/AudioFile/03-01-06-02-02-01-15.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x1e1a1289eb8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# % pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeling_list=[]\n",
    "for item in mylist:\n",
    "    if item[6:-16]=='02' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_calm')\n",
    "    elif item[6:-16]=='02' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_calm')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_happy')\n",
    "    elif item[6:-16]=='03' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_happy')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_sad')\n",
    "    elif item[6:-16]=='04' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_sad')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_angry')\n",
    "    elif item[6:-16]=='05' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_angry')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==0:\n",
    "        feeling_list.append('female_fearful')\n",
    "    elif item[6:-16]=='06' and int(item[18:-4])%2==1:\n",
    "        feeling_list.append('male_fearful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(feeling_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    male_calm\n",
       "1  female_calm\n",
       "2    male_calm\n",
       "3  female_calm\n",
       "4    male_calm\n",
       "5  female_calm\n",
       "6    male_calm\n",
       "7  female_calm\n",
       "8    male_calm\n",
       "9  female_calm"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the features of audio files using librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['feature'])\n",
    "bookmark=0\n",
    "for index,y in enumerate(mylist):\n",
    "    if mylist[index][6:-16]!='01' and mylist[index][6:-16]!='07' and mylist[index][6:-16]!='08' and mylist[index][:2]!='su' and mylist[index][:1]!='n' and mylist[index][:1]!='d':\n",
    "        X, sample_rate = librosa.load('../../Resources/data/AudioFile/'+y, res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "        sample_rate = np.array(sample_rate)\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, \n",
    "                                            sr=sample_rate, \n",
    "                                            n_mfcc=13),\n",
    "                        axis=0)\n",
    "        feature = mfccs\n",
    "        #[float(i) for i in feature]\n",
    "        #feature1=feature[:135]\n",
    "        df.loc[bookmark] = [feature]\n",
    "        bookmark=bookmark+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-70.26908, -70.26908, -70.26908, -70.26908, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-65.707954, -65.707954, -63.58061, -61.41941,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-65.48336, -65.48336, -65.48336, -65.48336, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-64.52947, -64.52947, -64.52947, -64.52947, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-61.001263, -58.799526, -60.93121, -67.416855...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature\n",
       "0  [-70.26908, -70.26908, -70.26908, -70.26908, -...\n",
       "1  [-65.707954, -65.707954, -63.58061, -61.41941,...\n",
       "2  [-65.48336, -65.48336, -65.48336, -65.48336, -...\n",
       "3  [-64.52947, -64.52947, -64.52947, -64.52947, -...\n",
       "4  [-61.001263, -58.799526, -60.93121, -67.416855..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(df['feature'].values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat([df3,labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>-70.269081</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.606026</td>\n",
       "      <td>-59.165623</td>\n",
       "      <td>-58.309124</td>\n",
       "      <td>-56.908752</td>\n",
       "      <td>-59.104012</td>\n",
       "      <td>-62.528481</td>\n",
       "      <td>-62.309921</td>\n",
       "      <td>-61.065742</td>\n",
       "      <td>-60.911045</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-65.707954</td>\n",
       "      <td>-65.707954</td>\n",
       "      <td>-63.580608</td>\n",
       "      <td>-61.419411</td>\n",
       "      <td>-59.960712</td>\n",
       "      <td>-63.011276</td>\n",
       "      <td>-63.900513</td>\n",
       "      <td>-56.068394</td>\n",
       "      <td>-54.799675</td>\n",
       "      <td>-54.788815</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.834072</td>\n",
       "      <td>-40.705566</td>\n",
       "      <td>-41.277607</td>\n",
       "      <td>-41.391945</td>\n",
       "      <td>-43.967670</td>\n",
       "      <td>-49.544460</td>\n",
       "      <td>-50.657040</td>\n",
       "      <td>-49.280472</td>\n",
       "      <td>-48.760681</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>-65.483360</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.934776</td>\n",
       "      <td>-34.849857</td>\n",
       "      <td>-36.426250</td>\n",
       "      <td>-36.479450</td>\n",
       "      <td>-37.743347</td>\n",
       "      <td>-40.266872</td>\n",
       "      <td>-41.793125</td>\n",
       "      <td>-41.500591</td>\n",
       "      <td>-40.949795</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-64.529472</td>\n",
       "      <td>-65.920654</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.780212</td>\n",
       "      <td>-48.577007</td>\n",
       "      <td>-47.649605</td>\n",
       "      <td>-42.966824</td>\n",
       "      <td>-42.567753</td>\n",
       "      <td>-43.183723</td>\n",
       "      <td>-44.057907</td>\n",
       "      <td>-43.637939</td>\n",
       "      <td>-44.574593</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-61.001263</td>\n",
       "      <td>-58.799526</td>\n",
       "      <td>-60.931210</td>\n",
       "      <td>-67.416855</td>\n",
       "      <td>-72.383270</td>\n",
       "      <td>-64.842598</td>\n",
       "      <td>-61.867981</td>\n",
       "      <td>-64.517372</td>\n",
       "      <td>-60.647495</td>\n",
       "      <td>-58.380913</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.386536</td>\n",
       "      <td>-42.110699</td>\n",
       "      <td>-41.020592</td>\n",
       "      <td>-38.441113</td>\n",
       "      <td>-36.532555</td>\n",
       "      <td>-37.991196</td>\n",
       "      <td>-40.078472</td>\n",
       "      <td>-43.429203</td>\n",
       "      <td>-43.876236</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0 -70.269081 -70.269081 -70.269081 -70.269081 -70.269081 -70.269081   \n",
       "1 -65.707954 -65.707954 -63.580608 -61.419411 -59.960712 -63.011276   \n",
       "2 -65.483360 -65.483360 -65.483360 -65.483360 -65.483360 -65.483360   \n",
       "3 -64.529472 -64.529472 -64.529472 -64.529472 -64.529472 -64.529472   \n",
       "4 -61.001263 -58.799526 -60.931210 -67.416855 -72.383270 -64.842598   \n",
       "\n",
       "         6          7          8          9    ...        207        208  \\\n",
       "0 -70.269081 -70.269081 -70.269081 -70.269081  ... -57.606026 -59.165623   \n",
       "1 -63.900513 -56.068394 -54.799675 -54.788815  ... -39.834072 -40.705566   \n",
       "2 -65.483360 -65.483360 -65.483360 -65.483360  ... -31.934776 -34.849857   \n",
       "3 -64.529472 -64.529472 -64.529472 -65.920654  ... -48.780212 -48.577007   \n",
       "4 -61.867981 -64.517372 -60.647495 -58.380913  ... -39.386536 -42.110699   \n",
       "\n",
       "         209        210        211        212        213        214  \\\n",
       "0 -58.309124 -56.908752 -59.104012 -62.528481 -62.309921 -61.065742   \n",
       "1 -41.277607 -41.391945 -43.967670 -49.544460 -50.657040 -49.280472   \n",
       "2 -36.426250 -36.479450 -37.743347 -40.266872 -41.793125 -41.500591   \n",
       "3 -47.649605 -42.966824 -42.567753 -43.183723 -44.057907 -43.637939   \n",
       "4 -41.020592 -38.441113 -36.532555 -37.991196 -40.078472 -43.429203   \n",
       "\n",
       "         215          0    \n",
       "0 -60.911045    male_calm  \n",
       "1 -48.760681  female_calm  \n",
       "2 -40.949795    male_calm  \n",
       "3 -44.574593  female_calm  \n",
       "4 -43.876236    male_calm  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnewdf[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>-79.435638</td>\n",
       "      <td>-79.435638</td>\n",
       "      <td>-78.686943</td>\n",
       "      <td>-71.375862</td>\n",
       "      <td>-67.122002</td>\n",
       "      <td>-68.116364</td>\n",
       "      <td>-74.360542</td>\n",
       "      <td>-69.576897</td>\n",
       "      <td>-69.593620</td>\n",
       "      <td>-77.246216</td>\n",
       "      <td>...</td>\n",
       "      <td>-59.928574</td>\n",
       "      <td>-57.491684</td>\n",
       "      <td>-58.985573</td>\n",
       "      <td>-64.209747</td>\n",
       "      <td>-61.663204</td>\n",
       "      <td>-58.318909</td>\n",
       "      <td>-57.961082</td>\n",
       "      <td>-58.964241</td>\n",
       "      <td>-59.840477</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>-53.846745</td>\n",
       "      <td>-55.077541</td>\n",
       "      <td>-53.213943</td>\n",
       "      <td>-51.161003</td>\n",
       "      <td>-52.952957</td>\n",
       "      <td>-52.184334</td>\n",
       "      <td>-53.711166</td>\n",
       "      <td>-54.610836</td>\n",
       "      <td>-53.040466</td>\n",
       "      <td>-52.105446</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.541813</td>\n",
       "      <td>-47.603245</td>\n",
       "      <td>-46.504757</td>\n",
       "      <td>-47.173546</td>\n",
       "      <td>-48.046284</td>\n",
       "      <td>-49.019577</td>\n",
       "      <td>-50.901035</td>\n",
       "      <td>-51.013924</td>\n",
       "      <td>-49.100830</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>-66.118599</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.112911</td>\n",
       "      <td>-42.837837</td>\n",
       "      <td>-44.003872</td>\n",
       "      <td>-45.647476</td>\n",
       "      <td>-44.321590</td>\n",
       "      <td>-43.452980</td>\n",
       "      <td>-43.615913</td>\n",
       "      <td>-38.091393</td>\n",
       "      <td>-32.151810</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>-47.361263</td>\n",
       "      <td>-47.380356</td>\n",
       "      <td>-47.380356</td>\n",
       "      <td>-47.399944</td>\n",
       "      <td>-47.442410</td>\n",
       "      <td>-47.358257</td>\n",
       "      <td>-47.269058</td>\n",
       "      <td>-47.364361</td>\n",
       "      <td>-47.500504</td>\n",
       "      <td>-47.412178</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.110233</td>\n",
       "      <td>-33.327957</td>\n",
       "      <td>-34.514805</td>\n",
       "      <td>-34.207066</td>\n",
       "      <td>-33.304726</td>\n",
       "      <td>-31.966728</td>\n",
       "      <td>-31.356388</td>\n",
       "      <td>-20.281324</td>\n",
       "      <td>-13.181356</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-55.828598</td>\n",
       "      <td>-54.927223</td>\n",
       "      <td>-55.899063</td>\n",
       "      <td>-54.731400</td>\n",
       "      <td>-54.648117</td>\n",
       "      <td>-54.109776</td>\n",
       "      <td>-51.159790</td>\n",
       "      <td>-52.668129</td>\n",
       "      <td>-54.077656</td>\n",
       "      <td>-52.973198</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.920723</td>\n",
       "      <td>-47.436123</td>\n",
       "      <td>-46.915627</td>\n",
       "      <td>-48.195213</td>\n",
       "      <td>-49.986801</td>\n",
       "      <td>-50.084087</td>\n",
       "      <td>-52.191463</td>\n",
       "      <td>-53.971855</td>\n",
       "      <td>-53.709595</td>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>-36.126728</td>\n",
       "      <td>-37.925468</td>\n",
       "      <td>-44.676418</td>\n",
       "      <td>-44.408535</td>\n",
       "      <td>-45.143883</td>\n",
       "      <td>-46.200142</td>\n",
       "      <td>-46.784981</td>\n",
       "      <td>-48.610306</td>\n",
       "      <td>-48.341511</td>\n",
       "      <td>-47.609085</td>\n",
       "      <td>...</td>\n",
       "      <td>-47.586033</td>\n",
       "      <td>-45.349567</td>\n",
       "      <td>-45.404732</td>\n",
       "      <td>-46.597786</td>\n",
       "      <td>-45.618145</td>\n",
       "      <td>-47.008972</td>\n",
       "      <td>-47.374065</td>\n",
       "      <td>-47.736271</td>\n",
       "      <td>-48.120403</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>-44.502144</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.404114</td>\n",
       "      <td>-30.510338</td>\n",
       "      <td>-33.666458</td>\n",
       "      <td>-34.622902</td>\n",
       "      <td>-34.255554</td>\n",
       "      <td>-34.659317</td>\n",
       "      <td>-36.206184</td>\n",
       "      <td>-14.178889</td>\n",
       "      <td>-6.240913</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>-66.134102</td>\n",
       "      <td>-66.134102</td>\n",
       "      <td>-66.134102</td>\n",
       "      <td>-66.134102</td>\n",
       "      <td>-64.129135</td>\n",
       "      <td>-64.604721</td>\n",
       "      <td>-66.134102</td>\n",
       "      <td>-66.134102</td>\n",
       "      <td>-66.134102</td>\n",
       "      <td>-66.134102</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.269119</td>\n",
       "      <td>-41.032089</td>\n",
       "      <td>-44.079765</td>\n",
       "      <td>-46.428951</td>\n",
       "      <td>-45.710022</td>\n",
       "      <td>-45.489117</td>\n",
       "      <td>-48.365913</td>\n",
       "      <td>-48.693192</td>\n",
       "      <td>-49.968472</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>-41.355442</td>\n",
       "      <td>-41.410957</td>\n",
       "      <td>-42.389957</td>\n",
       "      <td>-42.051632</td>\n",
       "      <td>-41.906570</td>\n",
       "      <td>-43.455910</td>\n",
       "      <td>-43.266167</td>\n",
       "      <td>-44.424095</td>\n",
       "      <td>-44.371040</td>\n",
       "      <td>-42.989670</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.448526</td>\n",
       "      <td>-28.893654</td>\n",
       "      <td>-28.805887</td>\n",
       "      <td>-28.799578</td>\n",
       "      <td>-32.017281</td>\n",
       "      <td>-34.166515</td>\n",
       "      <td>-32.210762</td>\n",
       "      <td>-26.593798</td>\n",
       "      <td>-22.249102</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-52.611351</td>\n",
       "      <td>-54.193245</td>\n",
       "      <td>-55.792133</td>\n",
       "      <td>-54.260006</td>\n",
       "      <td>-52.850620</td>\n",
       "      <td>-52.462875</td>\n",
       "      <td>-56.099991</td>\n",
       "      <td>-55.851360</td>\n",
       "      <td>-53.044067</td>\n",
       "      <td>-52.092690</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.436104</td>\n",
       "      <td>-49.173382</td>\n",
       "      <td>-50.586445</td>\n",
       "      <td>-52.753426</td>\n",
       "      <td>-53.797512</td>\n",
       "      <td>-54.839138</td>\n",
       "      <td>-54.712898</td>\n",
       "      <td>-55.000065</td>\n",
       "      <td>-61.607857</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "848 -79.435638 -79.435638 -78.686943 -71.375862 -67.122002 -68.116364   \n",
       "419 -53.846745 -55.077541 -53.213943 -51.161003 -52.952957 -52.184334   \n",
       "119 -66.118599 -66.118599 -66.118599 -66.118599 -66.118599 -66.118599   \n",
       "741 -47.361263 -47.380356 -47.380356 -47.399944 -47.442410 -47.358257   \n",
       "441 -55.828598 -54.927223 -55.899063 -54.731400 -54.648117 -54.109776   \n",
       "470 -36.126728 -37.925468 -44.676418 -44.408535 -45.143883 -46.200142   \n",
       "695 -44.502144 -44.502144 -44.502144 -44.502144 -44.502144 -44.502144   \n",
       "430 -66.134102 -66.134102 -66.134102 -66.134102 -64.129135 -64.604721   \n",
       "691 -41.355442 -41.410957 -42.389957 -42.051632 -41.906570 -43.455910   \n",
       "414 -52.611351 -54.193245 -55.792133 -54.260006 -52.850620 -52.462875   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "848 -74.360542 -69.576897 -69.593620 -77.246216  ... -59.928574 -57.491684   \n",
       "419 -53.711166 -54.610836 -53.040466 -52.105446  ... -48.541813 -47.603245   \n",
       "119 -66.118599 -66.118599 -66.118599 -66.118599  ... -44.112911 -42.837837   \n",
       "741 -47.269058 -47.364361 -47.500504 -47.412178  ... -32.110233 -33.327957   \n",
       "441 -51.159790 -52.668129 -54.077656 -52.973198  ... -49.920723 -47.436123   \n",
       "470 -46.784981 -48.610306 -48.341511 -47.609085  ... -47.586033 -45.349567   \n",
       "695 -44.502144 -44.502144 -44.502144 -44.502144  ... -29.404114 -30.510338   \n",
       "430 -66.134102 -66.134102 -66.134102 -66.134102  ... -39.269119 -41.032089   \n",
       "691 -43.266167 -44.424095 -44.371040 -42.989670  ... -29.448526 -28.893654   \n",
       "414 -56.099991 -55.851360 -53.044067 -52.092690  ... -52.436104 -49.173382   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "848 -58.985573 -64.209747 -61.663204 -58.318909 -57.961082 -58.964241   \n",
       "419 -46.504757 -47.173546 -48.046284 -49.019577 -50.901035 -51.013924   \n",
       "119 -44.003872 -45.647476 -44.321590 -43.452980 -43.615913 -38.091393   \n",
       "741 -34.514805 -34.207066 -33.304726 -31.966728 -31.356388 -20.281324   \n",
       "441 -46.915627 -48.195213 -49.986801 -50.084087 -52.191463 -53.971855   \n",
       "470 -45.404732 -46.597786 -45.618145 -47.008972 -47.374065 -47.736271   \n",
       "695 -33.666458 -34.622902 -34.255554 -34.659317 -36.206184 -14.178889   \n",
       "430 -44.079765 -46.428951 -45.710022 -45.489117 -48.365913 -48.693192   \n",
       "691 -28.805887 -28.799578 -32.017281 -34.166515 -32.210762 -26.593798   \n",
       "414 -50.586445 -52.753426 -53.797512 -54.839138 -54.712898 -55.000065   \n",
       "\n",
       "           215           0    \n",
       "848 -59.840477  male_fearful  \n",
       "419 -49.100830    female_sad  \n",
       "119 -32.151810   female_calm  \n",
       "741 -13.181356  female_angry  \n",
       "441 -53.709595    female_sad  \n",
       "470 -48.120403      male_sad  \n",
       "695  -6.240913  female_angry  \n",
       "430 -49.968472      male_sad  \n",
       "691 -22.249102  female_angry  \n",
       "414 -61.607857      male_sad  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "rnewdf = shuffle(newdf)\n",
    "rnewdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnewdf=rnewdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = np.random.rand(len(rnewdf)) < 0.8\n",
    "train = rnewdf[newdf1]\n",
    "test = rnewdf[~newdf1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>-60.113277</td>\n",
       "      <td>-61.480373</td>\n",
       "      <td>-62.337132</td>\n",
       "      <td>-62.337132</td>\n",
       "      <td>-62.337132</td>\n",
       "      <td>-62.099205</td>\n",
       "      <td>-62.337132</td>\n",
       "      <td>-62.337132</td>\n",
       "      <td>-62.337132</td>\n",
       "      <td>-62.337132</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.349625</td>\n",
       "      <td>-61.982887</td>\n",
       "      <td>-59.662254</td>\n",
       "      <td>-60.827881</td>\n",
       "      <td>-62.069481</td>\n",
       "      <td>-62.337132</td>\n",
       "      <td>-62.319901</td>\n",
       "      <td>-58.939781</td>\n",
       "      <td>-60.151546</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>-53.265671</td>\n",
       "      <td>-53.873226</td>\n",
       "      <td>-53.571774</td>\n",
       "      <td>-54.281437</td>\n",
       "      <td>-54.985538</td>\n",
       "      <td>-51.726456</td>\n",
       "      <td>-49.456474</td>\n",
       "      <td>-48.631340</td>\n",
       "      <td>-48.471985</td>\n",
       "      <td>-49.238091</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.622597</td>\n",
       "      <td>-42.108971</td>\n",
       "      <td>-40.963406</td>\n",
       "      <td>-38.895622</td>\n",
       "      <td>-38.272129</td>\n",
       "      <td>-38.398685</td>\n",
       "      <td>-39.295212</td>\n",
       "      <td>-39.509701</td>\n",
       "      <td>-33.066578</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>-57.103317</td>\n",
       "      <td>-58.846394</td>\n",
       "      <td>-62.483608</td>\n",
       "      <td>-60.748840</td>\n",
       "      <td>-57.373867</td>\n",
       "      <td>-56.759415</td>\n",
       "      <td>-55.434879</td>\n",
       "      <td>-54.679077</td>\n",
       "      <td>-56.113235</td>\n",
       "      <td>-57.170918</td>\n",
       "      <td>...</td>\n",
       "      <td>-56.112251</td>\n",
       "      <td>-56.136909</td>\n",
       "      <td>-57.315056</td>\n",
       "      <td>-59.008846</td>\n",
       "      <td>-59.973488</td>\n",
       "      <td>-58.183811</td>\n",
       "      <td>-56.690311</td>\n",
       "      <td>-56.731438</td>\n",
       "      <td>-58.309311</td>\n",
       "      <td>male_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-63.797665</td>\n",
       "      <td>-63.797665</td>\n",
       "      <td>-63.797665</td>\n",
       "      <td>-63.797665</td>\n",
       "      <td>-63.797665</td>\n",
       "      <td>-59.036747</td>\n",
       "      <td>-57.874493</td>\n",
       "      <td>-61.433617</td>\n",
       "      <td>-63.797665</td>\n",
       "      <td>-63.797665</td>\n",
       "      <td>...</td>\n",
       "      <td>-62.349586</td>\n",
       "      <td>-59.253220</td>\n",
       "      <td>-60.011063</td>\n",
       "      <td>-58.259274</td>\n",
       "      <td>-59.059578</td>\n",
       "      <td>-63.660530</td>\n",
       "      <td>-63.819454</td>\n",
       "      <td>-63.866131</td>\n",
       "      <td>-62.618755</td>\n",
       "      <td>male_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-54.916752</td>\n",
       "      <td>-53.507561</td>\n",
       "      <td>-53.439835</td>\n",
       "      <td>-54.011238</td>\n",
       "      <td>-54.143227</td>\n",
       "      <td>-53.406937</td>\n",
       "      <td>-54.146221</td>\n",
       "      <td>-53.641865</td>\n",
       "      <td>-53.747654</td>\n",
       "      <td>-52.604374</td>\n",
       "      <td>...</td>\n",
       "      <td>-49.080509</td>\n",
       "      <td>-49.629562</td>\n",
       "      <td>-55.179153</td>\n",
       "      <td>-59.767414</td>\n",
       "      <td>-57.050034</td>\n",
       "      <td>-55.839741</td>\n",
       "      <td>-55.907513</td>\n",
       "      <td>-57.098518</td>\n",
       "      <td>-56.193832</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>-54.437271</td>\n",
       "      <td>-54.320618</td>\n",
       "      <td>-54.417931</td>\n",
       "      <td>-54.531578</td>\n",
       "      <td>-53.982185</td>\n",
       "      <td>-53.191643</td>\n",
       "      <td>-53.615845</td>\n",
       "      <td>-53.894936</td>\n",
       "      <td>-53.894936</td>\n",
       "      <td>-53.912369</td>\n",
       "      <td>...</td>\n",
       "      <td>-44.167282</td>\n",
       "      <td>-45.208656</td>\n",
       "      <td>-47.425510</td>\n",
       "      <td>-48.709202</td>\n",
       "      <td>-48.069168</td>\n",
       "      <td>-46.475285</td>\n",
       "      <td>-45.687840</td>\n",
       "      <td>-48.411385</td>\n",
       "      <td>-49.075588</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>-62.690250</td>\n",
       "      <td>-60.901104</td>\n",
       "      <td>-60.310390</td>\n",
       "      <td>-60.257004</td>\n",
       "      <td>-61.249214</td>\n",
       "      <td>-63.841129</td>\n",
       "      <td>-60.683586</td>\n",
       "      <td>-60.608040</td>\n",
       "      <td>-62.260258</td>\n",
       "      <td>-61.724197</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.165695</td>\n",
       "      <td>-61.075905</td>\n",
       "      <td>-60.047195</td>\n",
       "      <td>-57.097397</td>\n",
       "      <td>-55.411484</td>\n",
       "      <td>-56.119907</td>\n",
       "      <td>-60.323399</td>\n",
       "      <td>-63.528954</td>\n",
       "      <td>-59.453232</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-42.748131</td>\n",
       "      <td>-42.931320</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.085606</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-42.891567</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>-43.104778</td>\n",
       "      <td>male_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-67.782623</td>\n",
       "      <td>-67.646133</td>\n",
       "      <td>-67.782623</td>\n",
       "      <td>-67.782623</td>\n",
       "      <td>-67.665245</td>\n",
       "      <td>-66.754837</td>\n",
       "      <td>-67.782623</td>\n",
       "      <td>-67.743919</td>\n",
       "      <td>-61.295418</td>\n",
       "      <td>-57.663574</td>\n",
       "      <td>...</td>\n",
       "      <td>-59.778748</td>\n",
       "      <td>-59.529095</td>\n",
       "      <td>-56.865257</td>\n",
       "      <td>-56.516727</td>\n",
       "      <td>-58.672173</td>\n",
       "      <td>-62.704830</td>\n",
       "      <td>-57.393917</td>\n",
       "      <td>-57.419025</td>\n",
       "      <td>-59.819069</td>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>-47.335747</td>\n",
       "      <td>-47.880394</td>\n",
       "      <td>-47.564209</td>\n",
       "      <td>-47.440208</td>\n",
       "      <td>-48.164780</td>\n",
       "      <td>-48.736382</td>\n",
       "      <td>-48.969528</td>\n",
       "      <td>-48.073845</td>\n",
       "      <td>-46.957420</td>\n",
       "      <td>-46.738323</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.162621</td>\n",
       "      <td>-33.885574</td>\n",
       "      <td>-33.927269</td>\n",
       "      <td>-36.003525</td>\n",
       "      <td>-36.588448</td>\n",
       "      <td>-36.450668</td>\n",
       "      <td>-37.397915</td>\n",
       "      <td>-33.739315</td>\n",
       "      <td>-28.100016</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5    \\\n",
       "816 -60.113277 -61.480373 -62.337132 -62.337132 -62.337132 -62.099205   \n",
       "520 -53.265671 -53.873226 -53.571774 -54.281437 -54.985538 -51.726456   \n",
       "828 -57.103317 -58.846394 -62.483608 -60.748840 -57.373867 -56.759415   \n",
       "192 -63.797665 -63.797665 -63.797665 -63.797665 -63.797665 -59.036747   \n",
       "18  -54.916752 -53.507561 -53.439835 -54.011238 -54.143227 -53.406937   \n",
       "482 -54.437271 -54.320618 -54.417931 -54.531578 -53.982185 -53.191643   \n",
       "821 -62.690250 -60.901104 -60.310390 -60.257004 -61.249214 -63.841129   \n",
       "676 -43.104778 -43.104778 -43.104778 -43.104778 -43.104778 -43.104778   \n",
       "180 -67.782623 -67.646133 -67.782623 -67.782623 -67.665245 -66.754837   \n",
       "371 -47.335747 -47.880394 -47.564209 -47.440208 -48.164780 -48.736382   \n",
       "\n",
       "           6          7          8          9    ...        207        208  \\\n",
       "816 -62.337132 -62.337132 -62.337132 -62.337132  ... -61.349625 -61.982887   \n",
       "520 -49.456474 -48.631340 -48.471985 -49.238091  ... -41.622597 -42.108971   \n",
       "828 -55.434879 -54.679077 -56.113235 -57.170918  ... -56.112251 -56.136909   \n",
       "192 -57.874493 -61.433617 -63.797665 -63.797665  ... -62.349586 -59.253220   \n",
       "18  -54.146221 -53.641865 -53.747654 -52.604374  ... -49.080509 -49.629562   \n",
       "482 -53.615845 -53.894936 -53.894936 -53.912369  ... -44.167282 -45.208656   \n",
       "821 -60.683586 -60.608040 -62.260258 -61.724197  ... -58.165695 -61.075905   \n",
       "676 -42.748131 -42.931320 -43.104778 -43.104778  ... -43.085606 -43.104778   \n",
       "180 -67.782623 -67.743919 -61.295418 -57.663574  ... -59.778748 -59.529095   \n",
       "371 -48.969528 -48.073845 -46.957420 -46.738323  ... -34.162621 -33.885574   \n",
       "\n",
       "           209        210        211        212        213        214  \\\n",
       "816 -59.662254 -60.827881 -62.069481 -62.337132 -62.319901 -58.939781   \n",
       "520 -40.963406 -38.895622 -38.272129 -38.398685 -39.295212 -39.509701   \n",
       "828 -57.315056 -59.008846 -59.973488 -58.183811 -56.690311 -56.731438   \n",
       "192 -60.011063 -58.259274 -59.059578 -63.660530 -63.819454 -63.866131   \n",
       "18  -55.179153 -59.767414 -57.050034 -55.839741 -55.907513 -57.098518   \n",
       "482 -47.425510 -48.709202 -48.069168 -46.475285 -45.687840 -48.411385   \n",
       "821 -60.047195 -57.097397 -55.411484 -56.119907 -60.323399 -63.528954   \n",
       "676 -43.104778 -43.104778 -43.104778 -42.891567 -43.104778 -43.104778   \n",
       "180 -56.865257 -56.516727 -58.672173 -62.704830 -57.393917 -57.419025   \n",
       "371 -33.927269 -36.003525 -36.588448 -36.450668 -37.397915 -33.739315   \n",
       "\n",
       "           215             0    \n",
       "816 -60.151546    male_fearful  \n",
       "520 -33.066578        male_sad  \n",
       "828 -58.309311    male_fearful  \n",
       "192 -62.618755      male_happy  \n",
       "18  -56.193832       male_calm  \n",
       "482 -49.075588        male_sad  \n",
       "821 -59.453232  female_fearful  \n",
       "676 -43.104778      male_angry  \n",
       "180 -59.819069       male_calm  \n",
       "371 -28.100016    female_happy  \n",
       "\n",
       "[10 rows x 217 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[250:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfeatures = train.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlabel = train.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfeatures = test.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlabel = test.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\niran\\Anaconda3\\envs\\may\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = np.array(trainfeatures)\n",
    "y_train = np.array(trainlabel)\n",
    "X_test = np.array(testfeatures)\n",
    "y_test = np.array(testlabel)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 216)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dimension for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn =np.expand_dims(X_train, axis=2)\n",
    "x_testcnn= np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(216,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 216, 256)          1536      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 216, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 216, 128)          163968    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 216, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 27, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 27, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                34570     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 364,170\n",
      "Trainable params: 364,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removed the whole training part for avoiding unnecessary long epochs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 785 samples, validate on 175 samples\n",
      "Epoch 1/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.3689 - accuracy: 0.1019 - val_loss: 2.2601 - val_accuracy: 0.1543\n",
      "Epoch 2/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.2397 - accuracy: 0.1605 - val_loss: 2.2596 - val_accuracy: 0.1029\n",
      "Epoch 3/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.2164 - accuracy: 0.1376 - val_loss: 2.2147 - val_accuracy: 0.1657\n",
      "Epoch 4/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.1879 - accuracy: 0.1694 - val_loss: 2.1849 - val_accuracy: 0.1657\n",
      "Epoch 5/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.1702 - accuracy: 0.1834 - val_loss: 2.1686 - val_accuracy: 0.1657\n",
      "Epoch 6/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.1505 - accuracy: 0.1949 - val_loss: 2.1964 - val_accuracy: 0.1086\n",
      "Epoch 7/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.1298 - accuracy: 0.1962 - val_loss: 2.1683 - val_accuracy: 0.1600\n",
      "Epoch 8/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.1151 - accuracy: 0.1962 - val_loss: 2.1354 - val_accuracy: 0.2114\n",
      "Epoch 9/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.0962 - accuracy: 0.2191 - val_loss: 2.0983 - val_accuracy: 0.2057\n",
      "Epoch 10/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.0755 - accuracy: 0.2217 - val_loss: 2.0984 - val_accuracy: 0.2057\n",
      "Epoch 11/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 2.0621 - accuracy: 0.2395 - val_loss: 2.0939 - val_accuracy: 0.1829\n",
      "Epoch 12/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.0462 - accuracy: 0.2522 - val_loss: 2.0486 - val_accuracy: 0.2743\n",
      "Epoch 13/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.0309 - accuracy: 0.2395 - val_loss: 2.0889 - val_accuracy: 0.1257\n",
      "Epoch 14/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 2.0169 - accuracy: 0.2522 - val_loss: 2.1110 - val_accuracy: 0.1257\n",
      "Epoch 15/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.9998 - accuracy: 0.2624 - val_loss: 2.0307 - val_accuracy: 0.2800\n",
      "Epoch 16/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.9907 - accuracy: 0.2624 - val_loss: 2.0377 - val_accuracy: 0.1771\n",
      "Epoch 17/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.9735 - accuracy: 0.2484 - val_loss: 2.0060 - val_accuracy: 0.2400\n",
      "Epoch 18/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.9601 - accuracy: 0.2561 - val_loss: 1.9845 - val_accuracy: 0.2743\n",
      "Epoch 19/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.9431 - accuracy: 0.2892 - val_loss: 1.9824 - val_accuracy: 0.2914\n",
      "Epoch 20/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.9308 - accuracy: 0.3019 - val_loss: 1.9803 - val_accuracy: 0.2457\n",
      "Epoch 21/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 1.9224 - accuracy: 0.3032 - val_loss: 1.9912 - val_accuracy: 0.2229\n",
      "Epoch 22/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.9062 - accuracy: 0.2841 - val_loss: 1.9347 - val_accuracy: 0.2914\n",
      "Epoch 23/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.8968 - accuracy: 0.3083 - val_loss: 1.9403 - val_accuracy: 0.2914\n",
      "Epoch 24/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.8917 - accuracy: 0.2968 - val_loss: 1.9377 - val_accuracy: 0.2800\n",
      "Epoch 25/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.8773 - accuracy: 0.2854 - val_loss: 1.8891 - val_accuracy: 0.3029\n",
      "Epoch 26/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.8659 - accuracy: 0.3083 - val_loss: 1.9264 - val_accuracy: 0.2343\n",
      "Epoch 27/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.8559 - accuracy: 0.3019 - val_loss: 1.9182 - val_accuracy: 0.2057\n",
      "Epoch 28/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.8483 - accuracy: 0.3338 - val_loss: 1.9004 - val_accuracy: 0.3086\n",
      "Epoch 29/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.8330 - accuracy: 0.3503 - val_loss: 1.9039 - val_accuracy: 0.3029\n",
      "Epoch 30/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.8345 - accuracy: 0.3172 - val_loss: 1.9326 - val_accuracy: 0.3086\n",
      "Epoch 31/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.8155 - accuracy: 0.3248 - val_loss: 1.9169 - val_accuracy: 0.2571\n",
      "Epoch 32/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.8111 - accuracy: 0.3299 - val_loss: 1.8306 - val_accuracy: 0.3429\n",
      "Epoch 33/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7972 - accuracy: 0.3363 - val_loss: 1.8437 - val_accuracy: 0.2971\n",
      "Epoch 34/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7875 - accuracy: 0.3338 - val_loss: 1.8596 - val_accuracy: 0.3486\n",
      "Epoch 35/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7846 - accuracy: 0.3452 - val_loss: 1.8143 - val_accuracy: 0.3886\n",
      "Epoch 36/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7747 - accuracy: 0.3439 - val_loss: 1.8829 - val_accuracy: 0.2343\n",
      "Epoch 37/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7658 - accuracy: 0.3541 - val_loss: 1.8500 - val_accuracy: 0.2857\n",
      "Epoch 38/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7462 - accuracy: 0.3834 - val_loss: 1.8439 - val_accuracy: 0.2857\n",
      "Epoch 39/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7417 - accuracy: 0.3694 - val_loss: 1.8219 - val_accuracy: 0.3257\n",
      "Epoch 40/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.7409 - accuracy: 0.3567 - val_loss: 1.8579 - val_accuracy: 0.3143\n",
      "Epoch 41/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7250 - accuracy: 0.3720 - val_loss: 1.9161 - val_accuracy: 0.2743\n",
      "Epoch 42/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.7312 - accuracy: 0.3796 - val_loss: 1.7897 - val_accuracy: 0.3314\n",
      "Epoch 43/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7212 - accuracy: 0.3707 - val_loss: 1.7784 - val_accuracy: 0.3543\n",
      "Epoch 44/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7100 - accuracy: 0.3707 - val_loss: 1.7884 - val_accuracy: 0.3429\n",
      "Epoch 45/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.7072 - accuracy: 0.3783 - val_loss: 1.8012 - val_accuracy: 0.3029\n",
      "Epoch 46/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6951 - accuracy: 0.3554 - val_loss: 1.7972 - val_accuracy: 0.3086\n",
      "Epoch 47/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6883 - accuracy: 0.3822 - val_loss: 1.7557 - val_accuracy: 0.3886\n",
      "Epoch 48/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6790 - accuracy: 0.3975 - val_loss: 1.8244 - val_accuracy: 0.3086\n",
      "Epoch 49/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6780 - accuracy: 0.3809 - val_loss: 1.7715 - val_accuracy: 0.3829\n",
      "Epoch 50/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6712 - accuracy: 0.3924 - val_loss: 1.7366 - val_accuracy: 0.3543\n",
      "Epoch 51/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.6581 - accuracy: 0.4038 - val_loss: 1.8344 - val_accuracy: 0.2629\n",
      "Epoch 52/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6610 - accuracy: 0.3949 - val_loss: 1.7333 - val_accuracy: 0.3829\n",
      "Epoch 53/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6505 - accuracy: 0.3885 - val_loss: 1.7715 - val_accuracy: 0.3371\n",
      "Epoch 54/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6387 - accuracy: 0.3873 - val_loss: 1.8027 - val_accuracy: 0.2971\n",
      "Epoch 55/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6397 - accuracy: 0.3847 - val_loss: 1.7006 - val_accuracy: 0.3886\n",
      "Epoch 56/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.6277 - accuracy: 0.4064 - val_loss: 1.7727 - val_accuracy: 0.3086\n",
      "Epoch 57/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 2s 3ms/step - loss: 1.6254 - accuracy: 0.4076 - val_loss: 1.6891 - val_accuracy: 0.3886\n",
      "Epoch 58/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.6091 - accuracy: 0.3911 - val_loss: 1.7103 - val_accuracy: 0.3771\n",
      "Epoch 59/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.6103 - accuracy: 0.4000 - val_loss: 1.6793 - val_accuracy: 0.3714\n",
      "Epoch 60/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5938 - accuracy: 0.4076 - val_loss: 1.6688 - val_accuracy: 0.3886\n",
      "Epoch 61/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5955 - accuracy: 0.3987 - val_loss: 1.6816 - val_accuracy: 0.3943\n",
      "Epoch 62/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5804 - accuracy: 0.4127 - val_loss: 1.6696 - val_accuracy: 0.4229\n",
      "Epoch 63/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.5892 - accuracy: 0.3975 - val_loss: 1.6678 - val_accuracy: 0.3886\n",
      "Epoch 64/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5776 - accuracy: 0.4000 - val_loss: 1.7307 - val_accuracy: 0.3200\n",
      "Epoch 65/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5729 - accuracy: 0.4025 - val_loss: 1.6645 - val_accuracy: 0.3600\n",
      "Epoch 66/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5557 - accuracy: 0.4255 - val_loss: 1.6274 - val_accuracy: 0.4000\n",
      "Epoch 67/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.5555 - accuracy: 0.4217 - val_loss: 1.6718 - val_accuracy: 0.3943\n",
      "Epoch 68/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.5489 - accuracy: 0.4280 - val_loss: 1.7335 - val_accuracy: 0.3257\n",
      "Epoch 69/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.5417 - accuracy: 0.4280 - val_loss: 1.7377 - val_accuracy: 0.3200\n",
      "Epoch 70/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5369 - accuracy: 0.4331 - val_loss: 1.7095 - val_accuracy: 0.4057\n",
      "Epoch 71/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.5258 - accuracy: 0.4382 - val_loss: 1.6405 - val_accuracy: 0.3657\n",
      "Epoch 72/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.5234 - accuracy: 0.4510 - val_loss: 1.6796 - val_accuracy: 0.3429\n",
      "Epoch 73/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.5162 - accuracy: 0.4255 - val_loss: 1.6473 - val_accuracy: 0.3886\n",
      "Epoch 74/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5129 - accuracy: 0.4408 - val_loss: 1.6429 - val_accuracy: 0.3543\n",
      "Epoch 75/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5134 - accuracy: 0.4484 - val_loss: 1.6677 - val_accuracy: 0.3714\n",
      "Epoch 76/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.5107 - accuracy: 0.4382 - val_loss: 1.6301 - val_accuracy: 0.4000\n",
      "Epoch 77/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4934 - accuracy: 0.4446 - val_loss: 1.6345 - val_accuracy: 0.3771\n",
      "Epoch 78/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4935 - accuracy: 0.4369 - val_loss: 1.6626 - val_accuracy: 0.3371\n",
      "Epoch 79/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4760 - accuracy: 0.4675 - val_loss: 1.6491 - val_accuracy: 0.4000\n",
      "Epoch 80/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4821 - accuracy: 0.4382 - val_loss: 1.5727 - val_accuracy: 0.3829\n",
      "Epoch 81/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4776 - accuracy: 0.4459 - val_loss: 1.5419 - val_accuracy: 0.4571\n",
      "Epoch 82/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4679 - accuracy: 0.4561 - val_loss: 1.5710 - val_accuracy: 0.4114\n",
      "Epoch 83/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4527 - accuracy: 0.4662 - val_loss: 1.6435 - val_accuracy: 0.3714\n",
      "Epoch 84/700\n",
      "785/785 [==============================] - ETA: 0s - loss: 1.4604 - accuracy: 0.46 - 3s 3ms/step - loss: 1.4574 - accuracy: 0.4637 - val_loss: 1.5891 - val_accuracy: 0.4114\n",
      "Epoch 85/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4516 - accuracy: 0.4561 - val_loss: 1.6039 - val_accuracy: 0.4000\n",
      "Epoch 86/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4548 - accuracy: 0.4484 - val_loss: 1.6303 - val_accuracy: 0.4057\n",
      "Epoch 87/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4458 - accuracy: 0.4611 - val_loss: 1.6519 - val_accuracy: 0.3371\n",
      "Epoch 88/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4448 - accuracy: 0.4650 - val_loss: 1.6484 - val_accuracy: 0.3371\n",
      "Epoch 89/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4337 - accuracy: 0.4803 - val_loss: 1.5998 - val_accuracy: 0.3657\n",
      "Epoch 90/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4235 - accuracy: 0.4662 - val_loss: 1.6059 - val_accuracy: 0.4400\n",
      "Epoch 91/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4361 - accuracy: 0.4650 - val_loss: 1.5501 - val_accuracy: 0.4114\n",
      "Epoch 92/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4199 - accuracy: 0.4637 - val_loss: 1.5681 - val_accuracy: 0.3600\n",
      "Epoch 93/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4112 - accuracy: 0.4713 - val_loss: 1.6342 - val_accuracy: 0.3714\n",
      "Epoch 94/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.4148 - accuracy: 0.4713 - val_loss: 1.6018 - val_accuracy: 0.4000\n",
      "Epoch 95/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4130 - accuracy: 0.4701 - val_loss: 1.5779 - val_accuracy: 0.4114\n",
      "Epoch 96/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3991 - accuracy: 0.4866 - val_loss: 1.7199 - val_accuracy: 0.3371\n",
      "Epoch 97/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.4054 - accuracy: 0.4484 - val_loss: 1.6176 - val_accuracy: 0.3886\n",
      "Epoch 98/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3888 - accuracy: 0.4752 - val_loss: 1.5989 - val_accuracy: 0.3771\n",
      "Epoch 99/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3953 - accuracy: 0.4790 - val_loss: 1.5009 - val_accuracy: 0.4343\n",
      "Epoch 100/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3786 - accuracy: 0.4790 - val_loss: 1.5036 - val_accuracy: 0.4400\n",
      "Epoch 101/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3745 - accuracy: 0.4879 - val_loss: 1.5995 - val_accuracy: 0.3771\n",
      "Epoch 102/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3679 - accuracy: 0.4994 - val_loss: 1.5055 - val_accuracy: 0.4343\n",
      "Epoch 103/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3681 - accuracy: 0.5070 - val_loss: 1.5087 - val_accuracy: 0.4343\n",
      "Epoch 104/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3613 - accuracy: 0.4803 - val_loss: 1.5698 - val_accuracy: 0.4114\n",
      "Epoch 105/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3612 - accuracy: 0.4879 - val_loss: 1.5806 - val_accuracy: 0.3657\n",
      "Epoch 106/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3631 - accuracy: 0.4904 - val_loss: 1.5213 - val_accuracy: 0.4400\n",
      "Epoch 107/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3524 - accuracy: 0.5185 - val_loss: 1.6345 - val_accuracy: 0.3657\n",
      "Epoch 108/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3644 - accuracy: 0.4904 - val_loss: 1.5630 - val_accuracy: 0.4000\n",
      "Epoch 109/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3550 - accuracy: 0.4943 - val_loss: 1.5264 - val_accuracy: 0.4000\n",
      "Epoch 110/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3488 - accuracy: 0.4943 - val_loss: 1.5402 - val_accuracy: 0.4114\n",
      "Epoch 111/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 1.3506 - accuracy: 0.4981 - val_loss: 1.5324 - val_accuracy: 0.4400\n",
      "Epoch 112/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3426 - accuracy: 0.4879 - val_loss: 1.6156 - val_accuracy: 0.3829\n",
      "Epoch 113/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3367 - accuracy: 0.5045 - val_loss: 1.4686 - val_accuracy: 0.4514\n",
      "Epoch 114/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3284 - accuracy: 0.5172 - val_loss: 1.5257 - val_accuracy: 0.4229\n",
      "Epoch 115/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3246 - accuracy: 0.5096 - val_loss: 1.5310 - val_accuracy: 0.4229\n",
      "Epoch 116/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3171 - accuracy: 0.5159 - val_loss: 1.8376 - val_accuracy: 0.3143\n",
      "Epoch 117/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3296 - accuracy: 0.5096 - val_loss: 1.5476 - val_accuracy: 0.3886\n",
      "Epoch 118/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3302 - accuracy: 0.5019 - val_loss: 1.4649 - val_accuracy: 0.4743\n",
      "Epoch 119/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3179 - accuracy: 0.5057 - val_loss: 1.5894 - val_accuracy: 0.4171\n",
      "Epoch 120/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3187 - accuracy: 0.5134 - val_loss: 1.6558 - val_accuracy: 0.4000\n",
      "Epoch 121/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3286 - accuracy: 0.4994 - val_loss: 1.4713 - val_accuracy: 0.4400\n",
      "Epoch 122/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3089 - accuracy: 0.5248 - val_loss: 1.4840 - val_accuracy: 0.4286\n",
      "Epoch 123/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3096 - accuracy: 0.5223 - val_loss: 1.4543 - val_accuracy: 0.4571\n",
      "Epoch 124/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2995 - accuracy: 0.5146 - val_loss: 1.5478 - val_accuracy: 0.4114\n",
      "Epoch 125/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.3047 - accuracy: 0.5019 - val_loss: 1.4314 - val_accuracy: 0.4629\n",
      "Epoch 126/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.3007 - accuracy: 0.5096 - val_loss: 1.4403 - val_accuracy: 0.4857\n",
      "Epoch 127/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2852 - accuracy: 0.5274 - val_loss: 1.4576 - val_accuracy: 0.4514\n",
      "Epoch 128/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2933 - accuracy: 0.5134 - val_loss: 1.6256 - val_accuracy: 0.3143\n",
      "Epoch 129/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2962 - accuracy: 0.5197 - val_loss: 1.5161 - val_accuracy: 0.3943\n",
      "Epoch 130/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2803 - accuracy: 0.5274 - val_loss: 1.5112 - val_accuracy: 0.4000\n",
      "Epoch 131/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2920 - accuracy: 0.5223 - val_loss: 1.6311 - val_accuracy: 0.3657\n",
      "Epoch 132/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2834 - accuracy: 0.5083 - val_loss: 1.5809 - val_accuracy: 0.3829\n",
      "Epoch 133/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2863 - accuracy: 0.5159 - val_loss: 1.5312 - val_accuracy: 0.4000\n",
      "Epoch 134/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.2797 - accuracy: 0.5057 - val_loss: 1.4796 - val_accuracy: 0.4229\n",
      "Epoch 135/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 1.2747 - accuracy: 0.5299 - val_loss: 1.4657 - val_accuracy: 0.4629\n",
      "Epoch 136/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.2693 - accuracy: 0.5350 - val_loss: 1.5713 - val_accuracy: 0.4057\n",
      "Epoch 137/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2669 - accuracy: 0.5185 - val_loss: 1.4717 - val_accuracy: 0.4571\n",
      "Epoch 138/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2666 - accuracy: 0.5146 - val_loss: 1.4100 - val_accuracy: 0.4571\n",
      "Epoch 139/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2591 - accuracy: 0.5389 - val_loss: 1.4334 - val_accuracy: 0.4743\n",
      "Epoch 140/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2570 - accuracy: 0.5401 - val_loss: 1.4392 - val_accuracy: 0.4857\n",
      "Epoch 141/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2544 - accuracy: 0.5274 - val_loss: 1.4321 - val_accuracy: 0.4457\n",
      "Epoch 142/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2531 - accuracy: 0.5414 - val_loss: 1.4357 - val_accuracy: 0.4457\n",
      "Epoch 143/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2544 - accuracy: 0.5503 - val_loss: 1.5334 - val_accuracy: 0.4514\n",
      "Epoch 144/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2462 - accuracy: 0.5376 - val_loss: 1.4980 - val_accuracy: 0.4571\n",
      "Epoch 145/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2372 - accuracy: 0.5580 - val_loss: 1.5522 - val_accuracy: 0.4229\n",
      "Epoch 146/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2402 - accuracy: 0.5261 - val_loss: 1.4682 - val_accuracy: 0.4286\n",
      "Epoch 147/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2442 - accuracy: 0.5325 - val_loss: 1.4135 - val_accuracy: 0.4800\n",
      "Epoch 148/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2393 - accuracy: 0.5503 - val_loss: 1.4884 - val_accuracy: 0.4000\n",
      "Epoch 149/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2345 - accuracy: 0.5618 - val_loss: 1.6941 - val_accuracy: 0.4000\n",
      "Epoch 150/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.2134 - accuracy: 0.5452 - val_loss: 1.5925 - val_accuracy: 0.4343\n",
      "Epoch 151/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2220 - accuracy: 0.5567 - val_loss: 1.5226 - val_accuracy: 0.4286\n",
      "Epoch 152/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2243 - accuracy: 0.5465 - val_loss: 1.6238 - val_accuracy: 0.4114\n",
      "Epoch 153/700\n",
      "785/785 [==============================] - ETA: 0s - loss: 1.2222 - accuracy: 0.54 - 2s 3ms/step - loss: 1.2263 - accuracy: 0.5389 - val_loss: 1.5436 - val_accuracy: 0.3943\n",
      "Epoch 154/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2212 - accuracy: 0.5503 - val_loss: 1.6073 - val_accuracy: 0.4343\n",
      "Epoch 155/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2147 - accuracy: 0.5389 - val_loss: 1.4994 - val_accuracy: 0.3943\n",
      "Epoch 156/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2248 - accuracy: 0.5592 - val_loss: 1.5006 - val_accuracy: 0.4571\n",
      "Epoch 157/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2093 - accuracy: 0.5541 - val_loss: 1.5161 - val_accuracy: 0.4514\n",
      "Epoch 158/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.2053 - accuracy: 0.5401 - val_loss: 1.4713 - val_accuracy: 0.4629\n",
      "Epoch 159/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2037 - accuracy: 0.5503 - val_loss: 1.4349 - val_accuracy: 0.4457\n",
      "Epoch 160/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.2089 - accuracy: 0.5592 - val_loss: 1.4899 - val_accuracy: 0.4114\n",
      "Epoch 161/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1986 - accuracy: 0.5503 - val_loss: 1.5699 - val_accuracy: 0.4000\n",
      "Epoch 162/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2020 - accuracy: 0.5554 - val_loss: 1.4572 - val_accuracy: 0.4629\n",
      "Epoch 163/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.2035 - accuracy: 0.5580 - val_loss: 1.4795 - val_accuracy: 0.4343\n",
      "Epoch 164/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1955 - accuracy: 0.5592 - val_loss: 1.4836 - val_accuracy: 0.4343\n",
      "Epoch 165/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.2046 - accuracy: 0.5631 - val_loss: 1.6012 - val_accuracy: 0.4171\n",
      "Epoch 166/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1944 - accuracy: 0.5605 - val_loss: 1.4121 - val_accuracy: 0.4971\n",
      "Epoch 167/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1892 - accuracy: 0.5592 - val_loss: 1.4069 - val_accuracy: 0.4971\n",
      "Epoch 168/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1811 - accuracy: 0.5669 - val_loss: 1.3941 - val_accuracy: 0.4800\n",
      "Epoch 169/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1814 - accuracy: 0.5631 - val_loss: 1.5011 - val_accuracy: 0.4114\n",
      "Epoch 170/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1784 - accuracy: 0.5707 - val_loss: 1.4222 - val_accuracy: 0.4971\n",
      "Epoch 171/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1789 - accuracy: 0.5720 - val_loss: 1.6290 - val_accuracy: 0.4286\n",
      "Epoch 172/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1945 - accuracy: 0.5631 - val_loss: 1.5047 - val_accuracy: 0.4457\n",
      "Epoch 173/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1758 - accuracy: 0.5885 - val_loss: 1.4135 - val_accuracy: 0.4457\n",
      "Epoch 174/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1699 - accuracy: 0.5643 - val_loss: 1.4857 - val_accuracy: 0.4571\n",
      "Epoch 175/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1726 - accuracy: 0.5694 - val_loss: 1.5058 - val_accuracy: 0.4229\n",
      "Epoch 176/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1705 - accuracy: 0.5847 - val_loss: 1.4144 - val_accuracy: 0.4686\n",
      "Epoch 177/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1705 - accuracy: 0.5567 - val_loss: 1.5715 - val_accuracy: 0.4229\n",
      "Epoch 178/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1733 - accuracy: 0.5580 - val_loss: 1.4637 - val_accuracy: 0.4400\n",
      "Epoch 179/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1693 - accuracy: 0.5656 - val_loss: 1.4987 - val_accuracy: 0.4286\n",
      "Epoch 180/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1572 - accuracy: 0.5707 - val_loss: 1.4205 - val_accuracy: 0.4743\n",
      "Epoch 181/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1556 - accuracy: 0.5873 - val_loss: 1.3728 - val_accuracy: 0.5029\n",
      "Epoch 182/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1598 - accuracy: 0.5618 - val_loss: 1.4469 - val_accuracy: 0.4686\n",
      "Epoch 183/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1601 - accuracy: 0.5694 - val_loss: 1.3821 - val_accuracy: 0.4914\n",
      "Epoch 184/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1628 - accuracy: 0.5873 - val_loss: 1.4227 - val_accuracy: 0.5029\n",
      "Epoch 185/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1471 - accuracy: 0.5783 - val_loss: 1.5280 - val_accuracy: 0.4343\n",
      "Epoch 186/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1484 - accuracy: 0.5822 - val_loss: 1.3910 - val_accuracy: 0.4571\n",
      "Epoch 187/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1584 - accuracy: 0.5783 - val_loss: 1.4038 - val_accuracy: 0.4629\n",
      "Epoch 188/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1462 - accuracy: 0.5924 - val_loss: 1.3975 - val_accuracy: 0.4457\n",
      "Epoch 189/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1513 - accuracy: 0.5809 - val_loss: 1.4894 - val_accuracy: 0.4457\n",
      "Epoch 190/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1446 - accuracy: 0.5796 - val_loss: 1.4377 - val_accuracy: 0.4514\n",
      "Epoch 191/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1445 - accuracy: 0.5898 - val_loss: 1.4174 - val_accuracy: 0.4914\n",
      "Epoch 192/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1240 - accuracy: 0.5885 - val_loss: 1.4327 - val_accuracy: 0.4571\n",
      "Epoch 193/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1376 - accuracy: 0.5796 - val_loss: 1.4027 - val_accuracy: 0.4857\n",
      "Epoch 194/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1269 - accuracy: 0.5873 - val_loss: 1.4785 - val_accuracy: 0.4571\n",
      "Epoch 195/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1366 - accuracy: 0.5873 - val_loss: 1.4782 - val_accuracy: 0.4400\n",
      "Epoch 196/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1303 - accuracy: 0.5783 - val_loss: 1.3646 - val_accuracy: 0.4971\n",
      "Epoch 197/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1233 - accuracy: 0.5873 - val_loss: 1.4496 - val_accuracy: 0.4743\n",
      "Epoch 198/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1237 - accuracy: 0.5962 - val_loss: 1.4601 - val_accuracy: 0.4457\n",
      "Epoch 199/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1265 - accuracy: 0.5873 - val_loss: 1.3878 - val_accuracy: 0.4571\n",
      "Epoch 200/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1262 - accuracy: 0.5924 - val_loss: 1.3650 - val_accuracy: 0.4971\n",
      "Epoch 201/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1139 - accuracy: 0.5949 - val_loss: 1.4095 - val_accuracy: 0.4686\n",
      "Epoch 202/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1171 - accuracy: 0.5975 - val_loss: 1.4360 - val_accuracy: 0.4571\n",
      "Epoch 203/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1164 - accuracy: 0.5834 - val_loss: 1.5973 - val_accuracy: 0.4286\n",
      "Epoch 204/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1168 - accuracy: 0.5936 - val_loss: 1.5482 - val_accuracy: 0.4343\n",
      "Epoch 205/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1153 - accuracy: 0.5822 - val_loss: 1.3996 - val_accuracy: 0.4857\n",
      "Epoch 206/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1053 - accuracy: 0.6051 - val_loss: 1.3546 - val_accuracy: 0.4743\n",
      "Epoch 207/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.1028 - accuracy: 0.5962 - val_loss: 1.3581 - val_accuracy: 0.4971\n",
      "Epoch 208/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1025 - accuracy: 0.5911 - val_loss: 1.4211 - val_accuracy: 0.4743\n",
      "Epoch 209/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1036 - accuracy: 0.5834 - val_loss: 1.4600 - val_accuracy: 0.4629\n",
      "Epoch 210/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1042 - accuracy: 0.6025 - val_loss: 1.3985 - val_accuracy: 0.4800\n",
      "Epoch 211/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0929 - accuracy: 0.6038 - val_loss: 1.5184 - val_accuracy: 0.4000\n",
      "Epoch 212/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0984 - accuracy: 0.6089 - val_loss: 1.4265 - val_accuracy: 0.4343\n",
      "Epoch 213/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0940 - accuracy: 0.5936 - val_loss: 1.3971 - val_accuracy: 0.4800\n",
      "Epoch 214/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0869 - accuracy: 0.6025 - val_loss: 1.4295 - val_accuracy: 0.4629\n",
      "Epoch 215/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0840 - accuracy: 0.6191 - val_loss: 1.3562 - val_accuracy: 0.4857\n",
      "Epoch 216/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0930 - accuracy: 0.5987 - val_loss: 1.4880 - val_accuracy: 0.4286\n",
      "Epoch 217/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.1008 - accuracy: 0.5771 - val_loss: 1.4127 - val_accuracy: 0.4629\n",
      "Epoch 218/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0864 - accuracy: 0.6025 - val_loss: 1.4605 - val_accuracy: 0.4343\n",
      "Epoch 219/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0718 - accuracy: 0.6051 - val_loss: 1.5375 - val_accuracy: 0.4229\n",
      "Epoch 220/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0796 - accuracy: 0.6089 - val_loss: 1.5566 - val_accuracy: 0.4171\n",
      "Epoch 221/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0776 - accuracy: 0.6178 - val_loss: 1.3445 - val_accuracy: 0.4914\n",
      "Epoch 222/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0672 - accuracy: 0.6178 - val_loss: 1.4863 - val_accuracy: 0.4286\n",
      "Epoch 223/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0798 - accuracy: 0.6140 - val_loss: 1.3436 - val_accuracy: 0.4971\n",
      "Epoch 224/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0727 - accuracy: 0.6191 - val_loss: 1.4096 - val_accuracy: 0.4686\n",
      "Epoch 225/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0657 - accuracy: 0.6331 - val_loss: 1.4991 - val_accuracy: 0.4286\n",
      "Epoch 226/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0711 - accuracy: 0.6153 - val_loss: 1.3947 - val_accuracy: 0.5257\n",
      "Epoch 227/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0570 - accuracy: 0.6127 - val_loss: 1.4703 - val_accuracy: 0.4971\n",
      "Epoch 228/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0677 - accuracy: 0.6191 - val_loss: 1.3331 - val_accuracy: 0.4914\n",
      "Epoch 229/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0573 - accuracy: 0.6268 - val_loss: 1.3785 - val_accuracy: 0.5143\n",
      "Epoch 230/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0623 - accuracy: 0.6268 - val_loss: 1.5939 - val_accuracy: 0.4400\n",
      "Epoch 231/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0681 - accuracy: 0.6115 - val_loss: 1.3910 - val_accuracy: 0.4914\n",
      "Epoch 232/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0610 - accuracy: 0.6217 - val_loss: 1.4427 - val_accuracy: 0.4686\n",
      "Epoch 233/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0659 - accuracy: 0.6076 - val_loss: 1.4864 - val_accuracy: 0.4914\n",
      "Epoch 234/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0600 - accuracy: 0.6153 - val_loss: 1.5037 - val_accuracy: 0.4743\n",
      "Epoch 235/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0486 - accuracy: 0.6153 - val_loss: 1.3500 - val_accuracy: 0.5086\n",
      "Epoch 236/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0399 - accuracy: 0.6369 - val_loss: 1.3651 - val_accuracy: 0.4686\n",
      "Epoch 237/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0506 - accuracy: 0.6204 - val_loss: 1.3257 - val_accuracy: 0.4800\n",
      "Epoch 238/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0461 - accuracy: 0.6217 - val_loss: 1.4069 - val_accuracy: 0.4800\n",
      "Epoch 239/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0388 - accuracy: 0.6255 - val_loss: 1.4106 - val_accuracy: 0.4629\n",
      "Epoch 240/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0506 - accuracy: 0.6217 - val_loss: 1.5269 - val_accuracy: 0.4571\n",
      "Epoch 241/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0457 - accuracy: 0.6280 - val_loss: 1.4673 - val_accuracy: 0.4514\n",
      "Epoch 242/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0424 - accuracy: 0.6140 - val_loss: 1.4303 - val_accuracy: 0.4571\n",
      "Epoch 243/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0396 - accuracy: 0.6191 - val_loss: 1.4385 - val_accuracy: 0.4571\n",
      "Epoch 244/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0444 - accuracy: 0.6420 - val_loss: 1.3374 - val_accuracy: 0.5371\n",
      "Epoch 245/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0348 - accuracy: 0.6293 - val_loss: 1.3315 - val_accuracy: 0.5143\n",
      "Epoch 246/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0327 - accuracy: 0.6280 - val_loss: 1.4541 - val_accuracy: 0.4286\n",
      "Epoch 247/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0254 - accuracy: 0.6357 - val_loss: 1.3858 - val_accuracy: 0.5029\n",
      "Epoch 248/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0178 - accuracy: 0.6420 - val_loss: 1.5902 - val_accuracy: 0.4286\n",
      "Epoch 249/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0252 - accuracy: 0.6357 - val_loss: 1.3752 - val_accuracy: 0.5029\n",
      "Epoch 250/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0286 - accuracy: 0.6293 - val_loss: 1.4488 - val_accuracy: 0.4286\n",
      "Epoch 251/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0289 - accuracy: 0.6344 - val_loss: 1.6348 - val_accuracy: 0.4343\n",
      "Epoch 252/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0093 - accuracy: 0.6382 - val_loss: 1.4547 - val_accuracy: 0.4457\n",
      "Epoch 253/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0266 - accuracy: 0.6357 - val_loss: 1.4346 - val_accuracy: 0.4686\n",
      "Epoch 254/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0295 - accuracy: 0.6191 - val_loss: 1.4490 - val_accuracy: 0.4571\n",
      "Epoch 255/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0212 - accuracy: 0.6446 - val_loss: 1.3893 - val_accuracy: 0.4971\n",
      "Epoch 256/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0067 - accuracy: 0.6637 - val_loss: 1.4377 - val_accuracy: 0.4800\n",
      "Epoch 257/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0093 - accuracy: 0.6548 - val_loss: 1.5571 - val_accuracy: 0.4571\n",
      "Epoch 258/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0034 - accuracy: 0.6459 - val_loss: 1.4687 - val_accuracy: 0.4514\n",
      "Epoch 259/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0122 - accuracy: 0.6369 - val_loss: 1.3748 - val_accuracy: 0.4971\n",
      "Epoch 260/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0048 - accuracy: 0.6497 - val_loss: 1.4046 - val_accuracy: 0.5200\n",
      "Epoch 261/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0104 - accuracy: 0.6433 - val_loss: 1.4575 - val_accuracy: 0.4857\n",
      "Epoch 262/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0004 - accuracy: 0.6420 - val_loss: 1.4748 - val_accuracy: 0.4743\n",
      "Epoch 263/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0011 - accuracy: 0.6446 - val_loss: 1.3409 - val_accuracy: 0.4857\n",
      "Epoch 264/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9947 - accuracy: 0.6497 - val_loss: 1.3464 - val_accuracy: 0.5086\n",
      "Epoch 265/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9984 - accuracy: 0.6548 - val_loss: 1.3549 - val_accuracy: 0.5029\n",
      "Epoch 266/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 1.0028 - accuracy: 0.6561 - val_loss: 1.5316 - val_accuracy: 0.4400\n",
      "Epoch 267/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 1.0015 - accuracy: 0.6446 - val_loss: 1.3761 - val_accuracy: 0.5086\n",
      "Epoch 268/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9868 - accuracy: 0.6433 - val_loss: 1.3119 - val_accuracy: 0.5371\n",
      "Epoch 269/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9831 - accuracy: 0.6344 - val_loss: 1.4298 - val_accuracy: 0.4629\n",
      "Epoch 270/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9793 - accuracy: 0.6586 - val_loss: 1.5580 - val_accuracy: 0.3657\n",
      "Epoch 271/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9852 - accuracy: 0.6637 - val_loss: 1.3891 - val_accuracy: 0.4914\n",
      "Epoch 272/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9824 - accuracy: 0.6471 - val_loss: 1.4080 - val_accuracy: 0.4743\n",
      "Epoch 273/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9685 - accuracy: 0.6624 - val_loss: 1.5228 - val_accuracy: 0.4514\n",
      "Epoch 274/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9788 - accuracy: 0.6662 - val_loss: 1.4592 - val_accuracy: 0.4571\n",
      "Epoch 275/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9782 - accuracy: 0.6675 - val_loss: 1.3817 - val_accuracy: 0.5200\n",
      "Epoch 276/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9646 - accuracy: 0.6624 - val_loss: 1.5918 - val_accuracy: 0.4400\n",
      "Epoch 277/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9847 - accuracy: 0.6433 - val_loss: 1.3770 - val_accuracy: 0.4971\n",
      "Epoch 278/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9688 - accuracy: 0.6650 - val_loss: 1.3708 - val_accuracy: 0.4800\n",
      "Epoch 279/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9746 - accuracy: 0.6611 - val_loss: 1.4977 - val_accuracy: 0.4286\n",
      "Epoch 280/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9680 - accuracy: 0.6675 - val_loss: 1.5665 - val_accuracy: 0.4743\n",
      "Epoch 281/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9786 - accuracy: 0.6586 - val_loss: 1.3934 - val_accuracy: 0.4914\n",
      "Epoch 282/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9682 - accuracy: 0.6611 - val_loss: 1.4167 - val_accuracy: 0.4629\n",
      "Epoch 283/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9646 - accuracy: 0.6752 - val_loss: 1.4048 - val_accuracy: 0.4857\n",
      "Epoch 284/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9716 - accuracy: 0.6471 - val_loss: 1.3826 - val_accuracy: 0.4857\n",
      "Epoch 285/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9568 - accuracy: 0.6688 - val_loss: 1.4778 - val_accuracy: 0.4514\n",
      "Epoch 286/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9674 - accuracy: 0.6701 - val_loss: 1.4279 - val_accuracy: 0.4857\n",
      "Epoch 287/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9603 - accuracy: 0.6561 - val_loss: 1.3848 - val_accuracy: 0.5029\n",
      "Epoch 288/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9514 - accuracy: 0.6752 - val_loss: 1.4927 - val_accuracy: 0.4514\n",
      "Epoch 289/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9507 - accuracy: 0.6675 - val_loss: 1.4575 - val_accuracy: 0.4800\n",
      "Epoch 290/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9431 - accuracy: 0.6726 - val_loss: 1.6533 - val_accuracy: 0.4629\n",
      "Epoch 291/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9453 - accuracy: 0.6726 - val_loss: 1.6348 - val_accuracy: 0.4229\n",
      "Epoch 292/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9550 - accuracy: 0.6599 - val_loss: 1.3985 - val_accuracy: 0.4686\n",
      "Epoch 293/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9367 - accuracy: 0.6879 - val_loss: 1.3761 - val_accuracy: 0.5029\n",
      "Epoch 294/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9465 - accuracy: 0.6739 - val_loss: 1.3998 - val_accuracy: 0.4571\n",
      "Epoch 295/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9435 - accuracy: 0.6752 - val_loss: 1.4278 - val_accuracy: 0.4743\n",
      "Epoch 296/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9485 - accuracy: 0.6752 - val_loss: 1.3174 - val_accuracy: 0.5200\n",
      "Epoch 297/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9453 - accuracy: 0.6752 - val_loss: 1.3964 - val_accuracy: 0.4914\n",
      "Epoch 298/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9433 - accuracy: 0.6777 - val_loss: 1.4843 - val_accuracy: 0.4857\n",
      "Epoch 299/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9391 - accuracy: 0.6688 - val_loss: 1.4797 - val_accuracy: 0.4571\n",
      "Epoch 300/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9333 - accuracy: 0.6904 - val_loss: 1.5164 - val_accuracy: 0.4686\n",
      "Epoch 301/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9327 - accuracy: 0.6879 - val_loss: 1.3952 - val_accuracy: 0.4857\n",
      "Epoch 302/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9350 - accuracy: 0.6688 - val_loss: 1.3735 - val_accuracy: 0.4971\n",
      "Epoch 303/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9325 - accuracy: 0.6815 - val_loss: 1.3927 - val_accuracy: 0.4800\n",
      "Epoch 304/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.9228 - accuracy: 0.6854 - val_loss: 1.3642 - val_accuracy: 0.5200\n",
      "Epoch 305/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9225 - accuracy: 0.6904 - val_loss: 1.5501 - val_accuracy: 0.4514\n",
      "Epoch 306/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9387 - accuracy: 0.6752 - val_loss: 1.3505 - val_accuracy: 0.5086\n",
      "Epoch 307/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9260 - accuracy: 0.6803 - val_loss: 1.4466 - val_accuracy: 0.5086\n",
      "Epoch 308/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9241 - accuracy: 0.6764 - val_loss: 1.3459 - val_accuracy: 0.5257\n",
      "Epoch 309/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.9151 - accuracy: 0.6917 - val_loss: 1.3158 - val_accuracy: 0.5143\n",
      "Epoch 310/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9131 - accuracy: 0.6701 - val_loss: 1.3633 - val_accuracy: 0.5143\n",
      "Epoch 311/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9065 - accuracy: 0.6841 - val_loss: 1.8188 - val_accuracy: 0.4057\n",
      "Epoch 312/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9214 - accuracy: 0.6828 - val_loss: 1.3135 - val_accuracy: 0.5371\n",
      "Epoch 313/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9158 - accuracy: 0.6854 - val_loss: 1.5448 - val_accuracy: 0.4514\n",
      "Epoch 314/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9075 - accuracy: 0.6828 - val_loss: 1.3653 - val_accuracy: 0.5086\n",
      "Epoch 315/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9013 - accuracy: 0.6968 - val_loss: 1.3903 - val_accuracy: 0.4571\n",
      "Epoch 316/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8975 - accuracy: 0.6968 - val_loss: 1.4239 - val_accuracy: 0.5086\n",
      "Epoch 317/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9007 - accuracy: 0.6904 - val_loss: 1.3979 - val_accuracy: 0.5143\n",
      "Epoch 318/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8992 - accuracy: 0.6917 - val_loss: 1.3685 - val_accuracy: 0.4800\n",
      "Epoch 319/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8969 - accuracy: 0.6904 - val_loss: 1.8420 - val_accuracy: 0.3886\n",
      "Epoch 320/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.9050 - accuracy: 0.6854 - val_loss: 1.3693 - val_accuracy: 0.5086\n",
      "Epoch 321/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8918 - accuracy: 0.7006 - val_loss: 1.5031 - val_accuracy: 0.4286\n",
      "Epoch 322/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8969 - accuracy: 0.7006 - val_loss: 1.5003 - val_accuracy: 0.4857\n",
      "Epoch 323/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8908 - accuracy: 0.7032 - val_loss: 1.3224 - val_accuracy: 0.4971\n",
      "Epoch 324/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8912 - accuracy: 0.6930 - val_loss: 1.4048 - val_accuracy: 0.5029\n",
      "Epoch 325/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8983 - accuracy: 0.6981 - val_loss: 1.4351 - val_accuracy: 0.4800\n",
      "Epoch 326/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8930 - accuracy: 0.6879 - val_loss: 1.3965 - val_accuracy: 0.4971\n",
      "Epoch 327/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8836 - accuracy: 0.6930 - val_loss: 1.4759 - val_accuracy: 0.4743\n",
      "Epoch 328/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8779 - accuracy: 0.7032 - val_loss: 1.4707 - val_accuracy: 0.4571\n",
      "Epoch 329/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.8848 - accuracy: 0.7108 - val_loss: 1.3184 - val_accuracy: 0.5200\n",
      "Epoch 330/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8823 - accuracy: 0.7057 - val_loss: 1.3958 - val_accuracy: 0.4857\n",
      "Epoch 331/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8787 - accuracy: 0.7032 - val_loss: 1.3621 - val_accuracy: 0.5257\n",
      "Epoch 332/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8803 - accuracy: 0.7019 - val_loss: 1.3813 - val_accuracy: 0.5029\n",
      "Epoch 333/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8774 - accuracy: 0.6968 - val_loss: 1.4171 - val_accuracy: 0.5029\n",
      "Epoch 334/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8681 - accuracy: 0.7197 - val_loss: 1.3664 - val_accuracy: 0.5029\n",
      "Epoch 335/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8735 - accuracy: 0.6968 - val_loss: 1.4475 - val_accuracy: 0.4857\n",
      "Epoch 336/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.8768 - accuracy: 0.7019 - val_loss: 1.3626 - val_accuracy: 0.5086\n",
      "Epoch 337/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 3ms/step - loss: 0.8749 - accuracy: 0.7006 - val_loss: 1.3531 - val_accuracy: 0.5029\n",
      "Epoch 338/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.8762 - accuracy: 0.7057 - val_loss: 1.4614 - val_accuracy: 0.4629\n",
      "Epoch 339/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.8656 - accuracy: 0.7108 - val_loss: 1.4470 - val_accuracy: 0.5257\n",
      "Epoch 340/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.8640 - accuracy: 0.7121 - val_loss: 1.3714 - val_accuracy: 0.5143\n",
      "Epoch 341/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.8705 - accuracy: 0.6981 - val_loss: 1.3731 - val_accuracy: 0.5029\n",
      "Epoch 342/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.8626 - accuracy: 0.7019 - val_loss: 1.3528 - val_accuracy: 0.5143\n",
      "Epoch 343/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.8609 - accuracy: 0.7057 - val_loss: 1.4877 - val_accuracy: 0.4743\n",
      "Epoch 344/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.8593 - accuracy: 0.7172 - val_loss: 1.3041 - val_accuracy: 0.5429\n",
      "Epoch 345/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.8648 - accuracy: 0.7134 - val_loss: 1.3343 - val_accuracy: 0.5314\n",
      "Epoch 346/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8530 - accuracy: 0.7108 - val_loss: 1.5604 - val_accuracy: 0.4914\n",
      "Epoch 347/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8575 - accuracy: 0.7146 - val_loss: 1.4440 - val_accuracy: 0.4857\n",
      "Epoch 348/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.8606 - accuracy: 0.7108 - val_loss: 1.4502 - val_accuracy: 0.4914\n",
      "Epoch 349/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.8451 - accuracy: 0.7185 - val_loss: 1.4795 - val_accuracy: 0.4800\n",
      "Epoch 350/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.8557 - accuracy: 0.7197 - val_loss: 1.3354 - val_accuracy: 0.5200\n",
      "Epoch 351/700\n",
      "785/785 [==============================] - 1527s 2s/step - loss: 0.8383 - accuracy: 0.7248 - val_loss: 1.4610 - val_accuracy: 0.4914\n",
      "Epoch 352/700\n",
      "785/785 [==============================] - 5s 6ms/step - loss: 0.8523 - accuracy: 0.7185 - val_loss: 1.3590 - val_accuracy: 0.5314\n",
      "Epoch 353/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.8389 - accuracy: 0.7274 - val_loss: 1.3741 - val_accuracy: 0.5029\n",
      "Epoch 354/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.8298 - accuracy: 0.7197 - val_loss: 1.3779 - val_accuracy: 0.5143\n",
      "Epoch 355/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8400 - accuracy: 0.7096 - val_loss: 1.3750 - val_accuracy: 0.5257\n",
      "Epoch 356/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8286 - accuracy: 0.7223 - val_loss: 1.3873 - val_accuracy: 0.4971\n",
      "Epoch 357/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8409 - accuracy: 0.7172 - val_loss: 1.3874 - val_accuracy: 0.4857\n",
      "Epoch 358/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8266 - accuracy: 0.7274 - val_loss: 1.3830 - val_accuracy: 0.5086\n",
      "Epoch 359/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8309 - accuracy: 0.7236 - val_loss: 1.5082 - val_accuracy: 0.4971\n",
      "Epoch 360/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8363 - accuracy: 0.7376 - val_loss: 1.3920 - val_accuracy: 0.5257\n",
      "Epoch 361/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8246 - accuracy: 0.7287 - val_loss: 1.3784 - val_accuracy: 0.5314\n",
      "Epoch 362/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8235 - accuracy: 0.7338 - val_loss: 1.3545 - val_accuracy: 0.5086\n",
      "Epoch 363/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8291 - accuracy: 0.7223 - val_loss: 1.3590 - val_accuracy: 0.4971\n",
      "Epoch 364/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8208 - accuracy: 0.7287 - val_loss: 1.3418 - val_accuracy: 0.4914\n",
      "Epoch 365/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8197 - accuracy: 0.7248 - val_loss: 1.4159 - val_accuracy: 0.4686\n",
      "Epoch 366/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8130 - accuracy: 0.7363 - val_loss: 1.4671 - val_accuracy: 0.4857\n",
      "Epoch 367/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8104 - accuracy: 0.7439 - val_loss: 1.3640 - val_accuracy: 0.5257\n",
      "Epoch 368/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8203 - accuracy: 0.7210 - val_loss: 1.4600 - val_accuracy: 0.4914\n",
      "Epoch 369/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8173 - accuracy: 0.7197 - val_loss: 1.3800 - val_accuracy: 0.5086\n",
      "Epoch 370/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8129 - accuracy: 0.7248 - val_loss: 1.4478 - val_accuracy: 0.4800\n",
      "Epoch 371/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8242 - accuracy: 0.7261 - val_loss: 1.3877 - val_accuracy: 0.5200\n",
      "Epoch 372/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8082 - accuracy: 0.7350 - val_loss: 1.3261 - val_accuracy: 0.5257\n",
      "Epoch 373/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8177 - accuracy: 0.7236 - val_loss: 1.3091 - val_accuracy: 0.5429\n",
      "Epoch 374/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8065 - accuracy: 0.7185 - val_loss: 1.3752 - val_accuracy: 0.5371\n",
      "Epoch 375/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8053 - accuracy: 0.7376 - val_loss: 1.4347 - val_accuracy: 0.4800\n",
      "Epoch 376/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8047 - accuracy: 0.7376 - val_loss: 1.4363 - val_accuracy: 0.4686\n",
      "Epoch 377/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7997 - accuracy: 0.7325 - val_loss: 1.4305 - val_accuracy: 0.5200\n",
      "Epoch 378/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.8020 - accuracy: 0.7197 - val_loss: 1.3275 - val_accuracy: 0.5257\n",
      "Epoch 379/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7992 - accuracy: 0.7439 - val_loss: 1.4984 - val_accuracy: 0.4629\n",
      "Epoch 380/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7985 - accuracy: 0.7363 - val_loss: 1.4288 - val_accuracy: 0.4914\n",
      "Epoch 381/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7982 - accuracy: 0.7350 - val_loss: 1.3399 - val_accuracy: 0.5314\n",
      "Epoch 382/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7866 - accuracy: 0.7541 - val_loss: 1.4859 - val_accuracy: 0.5257\n",
      "Epoch 383/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7881 - accuracy: 0.7210 - val_loss: 1.4784 - val_accuracy: 0.4914\n",
      "Epoch 384/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7861 - accuracy: 0.7427 - val_loss: 1.5401 - val_accuracy: 0.4571\n",
      "Epoch 385/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7865 - accuracy: 0.7248 - val_loss: 1.5924 - val_accuracy: 0.4914\n",
      "Epoch 386/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7851 - accuracy: 0.7465 - val_loss: 1.3681 - val_accuracy: 0.5257\n",
      "Epoch 387/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7771 - accuracy: 0.7350 - val_loss: 1.4893 - val_accuracy: 0.4857\n",
      "Epoch 388/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7832 - accuracy: 0.7376 - val_loss: 1.4372 - val_accuracy: 0.5200\n",
      "Epoch 389/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7828 - accuracy: 0.7389 - val_loss: 1.4592 - val_accuracy: 0.4971\n",
      "Epoch 390/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7828 - accuracy: 0.7478 - val_loss: 1.4602 - val_accuracy: 0.5029\n",
      "Epoch 391/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7709 - accuracy: 0.7516 - val_loss: 1.4299 - val_accuracy: 0.5257\n",
      "Epoch 392/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7722 - accuracy: 0.7338 - val_loss: 1.4362 - val_accuracy: 0.5086\n",
      "Epoch 393/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7779 - accuracy: 0.7389 - val_loss: 1.4609 - val_accuracy: 0.4971\n",
      "Epoch 394/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7707 - accuracy: 0.7490 - val_loss: 1.4155 - val_accuracy: 0.5200\n",
      "Epoch 395/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7701 - accuracy: 0.7439 - val_loss: 1.3608 - val_accuracy: 0.5486\n",
      "Epoch 396/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7621 - accuracy: 0.7490 - val_loss: 1.4918 - val_accuracy: 0.4857\n",
      "Epoch 397/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7632 - accuracy: 0.7516 - val_loss: 1.4545 - val_accuracy: 0.4971\n",
      "Epoch 398/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7691 - accuracy: 0.7567 - val_loss: 1.3901 - val_accuracy: 0.5200\n",
      "Epoch 399/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7551 - accuracy: 0.7554 - val_loss: 1.4994 - val_accuracy: 0.4686\n",
      "Epoch 400/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7645 - accuracy: 0.7452 - val_loss: 1.4877 - val_accuracy: 0.4914\n",
      "Epoch 401/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7638 - accuracy: 0.7389 - val_loss: 1.4671 - val_accuracy: 0.5086\n",
      "Epoch 402/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7553 - accuracy: 0.7605 - val_loss: 1.4909 - val_accuracy: 0.5143\n",
      "Epoch 403/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7493 - accuracy: 0.7541 - val_loss: 1.4020 - val_accuracy: 0.5086\n",
      "Epoch 404/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7543 - accuracy: 0.7618 - val_loss: 1.3768 - val_accuracy: 0.5029\n",
      "Epoch 405/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7439 - accuracy: 0.7656 - val_loss: 1.4068 - val_accuracy: 0.5086\n",
      "Epoch 406/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7570 - accuracy: 0.7478 - val_loss: 1.3802 - val_accuracy: 0.5200\n",
      "Epoch 407/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7470 - accuracy: 0.7656 - val_loss: 1.4136 - val_accuracy: 0.4686\n",
      "Epoch 408/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7492 - accuracy: 0.7592 - val_loss: 1.3619 - val_accuracy: 0.5200\n",
      "Epoch 409/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7465 - accuracy: 0.7541 - val_loss: 1.4348 - val_accuracy: 0.4914\n",
      "Epoch 410/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7348 - accuracy: 0.7707 - val_loss: 1.4226 - val_accuracy: 0.5143\n",
      "Epoch 411/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7399 - accuracy: 0.7592 - val_loss: 1.3884 - val_accuracy: 0.5029\n",
      "Epoch 412/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7387 - accuracy: 0.7529 - val_loss: 1.4840 - val_accuracy: 0.5371\n",
      "Epoch 413/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7456 - accuracy: 0.7694 - val_loss: 1.3760 - val_accuracy: 0.5086\n",
      "Epoch 414/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7347 - accuracy: 0.7529 - val_loss: 1.5352 - val_accuracy: 0.4629\n",
      "Epoch 415/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7427 - accuracy: 0.7567 - val_loss: 1.4404 - val_accuracy: 0.5029\n",
      "Epoch 416/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7336 - accuracy: 0.7592 - val_loss: 1.3313 - val_accuracy: 0.5600\n",
      "Epoch 417/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7298 - accuracy: 0.7490 - val_loss: 1.4507 - val_accuracy: 0.4800\n",
      "Epoch 418/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7311 - accuracy: 0.7707 - val_loss: 1.4010 - val_accuracy: 0.5143\n",
      "Epoch 419/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7377 - accuracy: 0.7503 - val_loss: 1.4198 - val_accuracy: 0.5200\n",
      "Epoch 420/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7192 - accuracy: 0.7631 - val_loss: 1.3694 - val_accuracy: 0.5486\n",
      "Epoch 421/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7233 - accuracy: 0.7516 - val_loss: 1.4050 - val_accuracy: 0.5371\n",
      "Epoch 422/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7165 - accuracy: 0.7694 - val_loss: 1.6361 - val_accuracy: 0.4343\n",
      "Epoch 423/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7217 - accuracy: 0.7592 - val_loss: 1.4079 - val_accuracy: 0.5257\n",
      "Epoch 424/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7148 - accuracy: 0.7783 - val_loss: 1.5234 - val_accuracy: 0.4400\n",
      "Epoch 425/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7288 - accuracy: 0.7732 - val_loss: 1.3648 - val_accuracy: 0.5257\n",
      "Epoch 426/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7122 - accuracy: 0.7732 - val_loss: 1.3968 - val_accuracy: 0.5200\n",
      "Epoch 427/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7191 - accuracy: 0.7529 - val_loss: 1.3922 - val_accuracy: 0.5314\n",
      "Epoch 428/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7136 - accuracy: 0.7643 - val_loss: 1.5545 - val_accuracy: 0.4571\n",
      "Epoch 429/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7144 - accuracy: 0.7567 - val_loss: 1.3793 - val_accuracy: 0.5371\n",
      "Epoch 430/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7132 - accuracy: 0.7694 - val_loss: 1.4817 - val_accuracy: 0.5029\n",
      "Epoch 431/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7144 - accuracy: 0.7643 - val_loss: 1.3800 - val_accuracy: 0.5200\n",
      "Epoch 432/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7092 - accuracy: 0.7758 - val_loss: 1.4405 - val_accuracy: 0.5371\n",
      "Epoch 433/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.7064 - accuracy: 0.7605 - val_loss: 1.5528 - val_accuracy: 0.5029\n",
      "Epoch 434/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6983 - accuracy: 0.7682 - val_loss: 1.4512 - val_accuracy: 0.4914\n",
      "Epoch 435/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.6963 - accuracy: 0.7796 - val_loss: 1.3746 - val_accuracy: 0.5029\n",
      "Epoch 436/700\n",
      "785/785 [==============================] - 7s 9ms/step - loss: 0.6995 - accuracy: 0.7745 - val_loss: 1.4868 - val_accuracy: 0.4629\n",
      "Epoch 437/700\n",
      "785/785 [==============================] - 7s 9ms/step - loss: 0.7047 - accuracy: 0.7682 - val_loss: 1.4706 - val_accuracy: 0.5200\n",
      "Epoch 438/700\n",
      "785/785 [==============================] - 14403s 18s/step - loss: 0.7046 - accuracy: 0.7682 - val_loss: 1.4059 - val_accuracy: 0.5143\n",
      "Epoch 439/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.6948 - accuracy: 0.7783 - val_loss: 1.5706 - val_accuracy: 0.4629\n",
      "Epoch 440/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.6912 - accuracy: 0.7707 - val_loss: 1.3815 - val_accuracy: 0.5371\n",
      "Epoch 441/700\n",
      "785/785 [==============================] - 35297s 45s/step - loss: 0.6894 - accuracy: 0.7809 - val_loss: 1.4265 - val_accuracy: 0.4971\n",
      "Epoch 442/700\n",
      "785/785 [==============================] - 6s 8ms/step - loss: 0.6940 - accuracy: 0.7860 - val_loss: 1.3834 - val_accuracy: 0.5257\n",
      "Epoch 443/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.6948 - accuracy: 0.7592 - val_loss: 1.4040 - val_accuracy: 0.5086\n",
      "Epoch 444/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6842 - accuracy: 0.7809 - val_loss: 1.4518 - val_accuracy: 0.4743\n",
      "Epoch 445/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.6822 - accuracy: 0.7924 - val_loss: 1.4281 - val_accuracy: 0.5143\n",
      "Epoch 446/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.6803 - accuracy: 0.7796 - val_loss: 1.4064 - val_accuracy: 0.5257\n",
      "Epoch 447/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.6883 - accuracy: 0.7809 - val_loss: 1.4286 - val_accuracy: 0.4914\n",
      "Epoch 448/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6721 - accuracy: 0.7949 - val_loss: 1.3960 - val_accuracy: 0.5029\n",
      "Epoch 449/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6868 - accuracy: 0.7669 - val_loss: 1.3849 - val_accuracy: 0.5143\n",
      "Epoch 450/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6710 - accuracy: 0.7936 - val_loss: 1.6346 - val_accuracy: 0.4343\n",
      "Epoch 451/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6743 - accuracy: 0.7834 - val_loss: 1.4371 - val_accuracy: 0.5086\n",
      "Epoch 452/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6749 - accuracy: 0.7847 - val_loss: 1.4249 - val_accuracy: 0.4971\n",
      "Epoch 453/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6801 - accuracy: 0.7834 - val_loss: 1.5614 - val_accuracy: 0.4971\n",
      "Epoch 454/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6733 - accuracy: 0.7847 - val_loss: 1.4140 - val_accuracy: 0.4800\n",
      "Epoch 455/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6677 - accuracy: 0.7962 - val_loss: 1.6914 - val_accuracy: 0.4400\n",
      "Epoch 456/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6712 - accuracy: 0.7873 - val_loss: 1.4830 - val_accuracy: 0.4800\n",
      "Epoch 457/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6700 - accuracy: 0.7847 - val_loss: 1.5092 - val_accuracy: 0.4857\n",
      "Epoch 458/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6689 - accuracy: 0.7847 - val_loss: 1.4938 - val_accuracy: 0.5029\n",
      "Epoch 459/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6612 - accuracy: 0.7885 - val_loss: 1.6202 - val_accuracy: 0.4400\n",
      "Epoch 460/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6663 - accuracy: 0.7771 - val_loss: 1.5643 - val_accuracy: 0.4914\n",
      "Epoch 461/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6598 - accuracy: 0.7873 - val_loss: 1.4766 - val_accuracy: 0.5029\n",
      "Epoch 462/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6615 - accuracy: 0.8025 - val_loss: 1.5471 - val_accuracy: 0.5086\n",
      "Epoch 463/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6634 - accuracy: 0.7911 - val_loss: 1.4523 - val_accuracy: 0.5086\n",
      "Epoch 464/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6558 - accuracy: 0.7949 - val_loss: 1.5437 - val_accuracy: 0.5143\n",
      "Epoch 465/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6573 - accuracy: 0.7936 - val_loss: 1.3558 - val_accuracy: 0.5600\n",
      "Epoch 466/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6558 - accuracy: 0.7975 - val_loss: 1.3917 - val_accuracy: 0.5371\n",
      "Epoch 467/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6467 - accuracy: 0.8013 - val_loss: 1.4164 - val_accuracy: 0.5371\n",
      "Epoch 468/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6454 - accuracy: 0.7987 - val_loss: 1.3773 - val_accuracy: 0.5714\n",
      "Epoch 469/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6425 - accuracy: 0.7975 - val_loss: 1.5403 - val_accuracy: 0.4571\n",
      "Epoch 470/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6451 - accuracy: 0.7936 - val_loss: 1.4793 - val_accuracy: 0.5429\n",
      "Epoch 471/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6431 - accuracy: 0.7898 - val_loss: 1.5805 - val_accuracy: 0.4800\n",
      "Epoch 472/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6397 - accuracy: 0.8064 - val_loss: 1.3818 - val_accuracy: 0.5371\n",
      "Epoch 473/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6334 - accuracy: 0.8051 - val_loss: 1.3462 - val_accuracy: 0.5714\n",
      "Epoch 474/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6432 - accuracy: 0.7975 - val_loss: 1.4196 - val_accuracy: 0.5200\n",
      "Epoch 475/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6295 - accuracy: 0.8051 - val_loss: 1.4586 - val_accuracy: 0.5086\n",
      "Epoch 476/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6388 - accuracy: 0.8000 - val_loss: 1.3476 - val_accuracy: 0.5543\n",
      "Epoch 477/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6318 - accuracy: 0.7962 - val_loss: 1.4702 - val_accuracy: 0.4457\n",
      "Epoch 478/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6271 - accuracy: 0.8089 - val_loss: 1.4231 - val_accuracy: 0.5143\n",
      "Epoch 479/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6259 - accuracy: 0.8153 - val_loss: 1.4335 - val_accuracy: 0.4914\n",
      "Epoch 480/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6280 - accuracy: 0.8064 - val_loss: 1.4860 - val_accuracy: 0.4857\n",
      "Epoch 481/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6182 - accuracy: 0.7975 - val_loss: 1.4273 - val_accuracy: 0.5257\n",
      "Epoch 482/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6297 - accuracy: 0.7962 - val_loss: 1.4342 - val_accuracy: 0.5143\n",
      "Epoch 483/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6199 - accuracy: 0.8127 - val_loss: 1.4535 - val_accuracy: 0.4629\n",
      "Epoch 484/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6194 - accuracy: 0.8025 - val_loss: 1.5731 - val_accuracy: 0.5200\n",
      "Epoch 485/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6195 - accuracy: 0.8127 - val_loss: 1.6102 - val_accuracy: 0.4457\n",
      "Epoch 486/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6226 - accuracy: 0.8115 - val_loss: 1.3442 - val_accuracy: 0.5543\n",
      "Epoch 487/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6195 - accuracy: 0.8127 - val_loss: 1.4693 - val_accuracy: 0.5029\n",
      "Epoch 488/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6126 - accuracy: 0.8217 - val_loss: 1.4528 - val_accuracy: 0.4857\n",
      "Epoch 489/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6086 - accuracy: 0.8115 - val_loss: 1.4256 - val_accuracy: 0.5086\n",
      "Epoch 490/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6129 - accuracy: 0.8229 - val_loss: 1.4325 - val_accuracy: 0.5029\n",
      "Epoch 491/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6065 - accuracy: 0.8166 - val_loss: 1.3778 - val_accuracy: 0.5543\n",
      "Epoch 492/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6094 - accuracy: 0.8280 - val_loss: 1.4443 - val_accuracy: 0.4914\n",
      "Epoch 493/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6152 - accuracy: 0.8115 - val_loss: 1.4044 - val_accuracy: 0.5257\n",
      "Epoch 494/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6129 - accuracy: 0.8064 - val_loss: 1.4296 - val_accuracy: 0.5429\n",
      "Epoch 495/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6032 - accuracy: 0.8064 - val_loss: 1.3567 - val_accuracy: 0.5600\n",
      "Epoch 496/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6140 - accuracy: 0.8038 - val_loss: 1.3781 - val_accuracy: 0.5314\n",
      "Epoch 497/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6049 - accuracy: 0.8064 - val_loss: 1.5306 - val_accuracy: 0.5314\n",
      "Epoch 498/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5983 - accuracy: 0.8166 - val_loss: 1.4237 - val_accuracy: 0.5029\n",
      "Epoch 499/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.6015 - accuracy: 0.8178 - val_loss: 1.4503 - val_accuracy: 0.5200\n",
      "Epoch 500/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.5901 - accuracy: 0.8153 - val_loss: 1.4447 - val_accuracy: 0.5143\n",
      "Epoch 501/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.6001 - accuracy: 0.8115 - val_loss: 1.3904 - val_accuracy: 0.5314\n",
      "Epoch 502/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.5917 - accuracy: 0.8127 - val_loss: 1.4693 - val_accuracy: 0.5429\n",
      "Epoch 503/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.5930 - accuracy: 0.8178 - val_loss: 1.4454 - val_accuracy: 0.5200\n",
      "Epoch 504/700\n",
      "785/785 [==============================] - 4s 5ms/step - loss: 0.5816 - accuracy: 0.8242 - val_loss: 1.5271 - val_accuracy: 0.5086\n",
      "Epoch 505/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5853 - accuracy: 0.8217 - val_loss: 1.3873 - val_accuracy: 0.5486\n",
      "Epoch 506/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5924 - accuracy: 0.8204 - val_loss: 1.5972 - val_accuracy: 0.5143\n",
      "Epoch 507/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5854 - accuracy: 0.8166 - val_loss: 1.4123 - val_accuracy: 0.4971\n",
      "Epoch 508/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5859 - accuracy: 0.8255 - val_loss: 1.5657 - val_accuracy: 0.4743\n",
      "Epoch 509/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5825 - accuracy: 0.8293 - val_loss: 1.6315 - val_accuracy: 0.4686\n",
      "Epoch 510/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5771 - accuracy: 0.8280 - val_loss: 1.5403 - val_accuracy: 0.5029\n",
      "Epoch 511/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5785 - accuracy: 0.8242 - val_loss: 1.6725 - val_accuracy: 0.4743\n",
      "Epoch 512/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5828 - accuracy: 0.8089 - val_loss: 1.4503 - val_accuracy: 0.5314\n",
      "Epoch 513/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5793 - accuracy: 0.8204 - val_loss: 1.4992 - val_accuracy: 0.5143\n",
      "Epoch 514/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5654 - accuracy: 0.8331 - val_loss: 1.6685 - val_accuracy: 0.4571\n",
      "Epoch 515/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5800 - accuracy: 0.8318 - val_loss: 1.4717 - val_accuracy: 0.5314\n",
      "Epoch 516/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5654 - accuracy: 0.8178 - val_loss: 1.4271 - val_accuracy: 0.5657\n",
      "Epoch 517/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5660 - accuracy: 0.8255 - val_loss: 1.3773 - val_accuracy: 0.5543\n",
      "Epoch 518/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5663 - accuracy: 0.8268 - val_loss: 1.4573 - val_accuracy: 0.4857\n",
      "Epoch 519/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5642 - accuracy: 0.8344 - val_loss: 1.4470 - val_accuracy: 0.5257\n",
      "Epoch 520/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5664 - accuracy: 0.8204 - val_loss: 1.4666 - val_accuracy: 0.4857\n",
      "Epoch 521/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5576 - accuracy: 0.8420 - val_loss: 1.4651 - val_accuracy: 0.5143\n",
      "Epoch 522/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5592 - accuracy: 0.8229 - val_loss: 1.5530 - val_accuracy: 0.5086\n",
      "Epoch 523/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5584 - accuracy: 0.8166 - val_loss: 1.4277 - val_accuracy: 0.5429\n",
      "Epoch 524/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5547 - accuracy: 0.8293 - val_loss: 1.4312 - val_accuracy: 0.5086\n",
      "Epoch 525/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5516 - accuracy: 0.8357 - val_loss: 1.7513 - val_accuracy: 0.4571\n",
      "Epoch 526/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5611 - accuracy: 0.8369 - val_loss: 1.7090 - val_accuracy: 0.4571\n",
      "Epoch 527/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5576 - accuracy: 0.8331 - val_loss: 1.5143 - val_accuracy: 0.4857\n",
      "Epoch 528/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5536 - accuracy: 0.8229 - val_loss: 1.4960 - val_accuracy: 0.5029\n",
      "Epoch 529/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5546 - accuracy: 0.8280 - val_loss: 1.3911 - val_accuracy: 0.5371\n",
      "Epoch 530/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5418 - accuracy: 0.8357 - val_loss: 1.4231 - val_accuracy: 0.5257\n",
      "Epoch 531/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5438 - accuracy: 0.8369 - val_loss: 1.5211 - val_accuracy: 0.4800\n",
      "Epoch 532/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5488 - accuracy: 0.8306 - val_loss: 1.4618 - val_accuracy: 0.5029\n",
      "Epoch 533/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.8433 - val_loss: 1.4708 - val_accuracy: 0.5314\n",
      "Epoch 534/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5470 - accuracy: 0.8344 - val_loss: 1.4648 - val_accuracy: 0.4914\n",
      "Epoch 535/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5449 - accuracy: 0.8382 - val_loss: 1.4266 - val_accuracy: 0.5257\n",
      "Epoch 536/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5404 - accuracy: 0.8318 - val_loss: 1.4285 - val_accuracy: 0.5371\n",
      "Epoch 537/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5314 - accuracy: 0.8408 - val_loss: 1.4504 - val_accuracy: 0.5029\n",
      "Epoch 538/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5332 - accuracy: 0.8420 - val_loss: 1.5022 - val_accuracy: 0.5029\n",
      "Epoch 539/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5360 - accuracy: 0.8318 - val_loss: 1.4115 - val_accuracy: 0.5486\n",
      "Epoch 540/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5352 - accuracy: 0.8268 - val_loss: 1.3631 - val_accuracy: 0.5771\n",
      "Epoch 541/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5385 - accuracy: 0.8382 - val_loss: 1.3973 - val_accuracy: 0.5314\n",
      "Epoch 542/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5234 - accuracy: 0.8484 - val_loss: 1.5552 - val_accuracy: 0.4686\n",
      "Epoch 543/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5305 - accuracy: 0.8357 - val_loss: 1.4786 - val_accuracy: 0.5029\n",
      "Epoch 544/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5246 - accuracy: 0.8433 - val_loss: 1.6023 - val_accuracy: 0.5314\n",
      "Epoch 545/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5289 - accuracy: 0.8395 - val_loss: 1.5646 - val_accuracy: 0.4914\n",
      "Epoch 546/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5265 - accuracy: 0.8420 - val_loss: 1.4881 - val_accuracy: 0.5086\n",
      "Epoch 547/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5211 - accuracy: 0.8357 - val_loss: 1.5684 - val_accuracy: 0.4914\n",
      "Epoch 548/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5172 - accuracy: 0.8535 - val_loss: 1.7259 - val_accuracy: 0.4914\n",
      "Epoch 549/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5278 - accuracy: 0.8395 - val_loss: 1.3835 - val_accuracy: 0.5600\n",
      "Epoch 550/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5157 - accuracy: 0.8433 - val_loss: 1.4962 - val_accuracy: 0.4914\n",
      "Epoch 551/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5210 - accuracy: 0.8408 - val_loss: 1.5079 - val_accuracy: 0.5257\n",
      "Epoch 552/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5171 - accuracy: 0.8446 - val_loss: 1.5162 - val_accuracy: 0.5143\n",
      "Epoch 553/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5085 - accuracy: 0.8548 - val_loss: 1.4539 - val_accuracy: 0.5371\n",
      "Epoch 554/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5200 - accuracy: 0.8433 - val_loss: 1.4745 - val_accuracy: 0.5314\n",
      "Epoch 555/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5072 - accuracy: 0.8382 - val_loss: 1.5124 - val_accuracy: 0.4914\n",
      "Epoch 556/700\n",
      "785/785 [==============================] - 4s 6ms/step - loss: 0.5121 - accuracy: 0.8548 - val_loss: 1.3972 - val_accuracy: 0.5429\n",
      "Epoch 557/700\n",
      "785/785 [==============================] - 7s 9ms/step - loss: 0.5094 - accuracy: 0.8357 - val_loss: 1.6867 - val_accuracy: 0.4857\n",
      "Epoch 558/700\n",
      "785/785 [==============================] - 7s 9ms/step - loss: 0.5074 - accuracy: 0.8573 - val_loss: 1.7073 - val_accuracy: 0.4857\n",
      "Epoch 559/700\n",
      "785/785 [==============================] - 355s 453ms/step - loss: 0.5102 - accuracy: 0.8382 - val_loss: 1.4010 - val_accuracy: 0.5486\n",
      "Epoch 560/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.4998 - accuracy: 0.8624 - val_loss: 1.5235 - val_accuracy: 0.4971\n",
      "Epoch 561/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 4ms/step - loss: 0.5031 - accuracy: 0.8637 - val_loss: 1.4774 - val_accuracy: 0.5086\n",
      "Epoch 562/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.4941 - accuracy: 0.8548 - val_loss: 1.4203 - val_accuracy: 0.5371\n",
      "Epoch 563/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.4995 - accuracy: 0.8561 - val_loss: 1.4347 - val_accuracy: 0.5371\n",
      "Epoch 564/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.4873 - accuracy: 0.8611 - val_loss: 1.4823 - val_accuracy: 0.5029\n",
      "Epoch 565/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.4911 - accuracy: 0.8573 - val_loss: 1.6110 - val_accuracy: 0.5029\n",
      "Epoch 566/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.4999 - accuracy: 0.8446 - val_loss: 1.5680 - val_accuracy: 0.5029\n",
      "Epoch 567/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4852 - accuracy: 0.8497 - val_loss: 1.5084 - val_accuracy: 0.5029\n",
      "Epoch 568/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4904 - accuracy: 0.8497 - val_loss: 1.6304 - val_accuracy: 0.4971\n",
      "Epoch 569/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4865 - accuracy: 0.8382 - val_loss: 1.6009 - val_accuracy: 0.4857\n",
      "Epoch 570/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4929 - accuracy: 0.8573 - val_loss: 1.4513 - val_accuracy: 0.5257\n",
      "Epoch 571/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4820 - accuracy: 0.8561 - val_loss: 1.5959 - val_accuracy: 0.4857\n",
      "Epoch 572/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4790 - accuracy: 0.8586 - val_loss: 1.7460 - val_accuracy: 0.4571\n",
      "Epoch 573/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4841 - accuracy: 0.8637 - val_loss: 1.7010 - val_accuracy: 0.4686\n",
      "Epoch 574/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4797 - accuracy: 0.8522 - val_loss: 1.5970 - val_accuracy: 0.4971\n",
      "Epoch 575/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4821 - accuracy: 0.8713 - val_loss: 1.5589 - val_accuracy: 0.5086\n",
      "Epoch 576/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4747 - accuracy: 0.8611 - val_loss: 1.4055 - val_accuracy: 0.5543\n",
      "Epoch 577/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4635 - accuracy: 0.8637 - val_loss: 1.4541 - val_accuracy: 0.5543\n",
      "Epoch 578/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4674 - accuracy: 0.8624 - val_loss: 1.6183 - val_accuracy: 0.5029\n",
      "Epoch 579/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4684 - accuracy: 0.8484 - val_loss: 1.6262 - val_accuracy: 0.4571\n",
      "Epoch 580/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4666 - accuracy: 0.8637 - val_loss: 1.5508 - val_accuracy: 0.5086\n",
      "Epoch 581/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4725 - accuracy: 0.8701 - val_loss: 1.4725 - val_accuracy: 0.5086\n",
      "Epoch 582/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4701 - accuracy: 0.8599 - val_loss: 1.4255 - val_accuracy: 0.5657\n",
      "Epoch 583/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4574 - accuracy: 0.8611 - val_loss: 1.8595 - val_accuracy: 0.4514\n",
      "Epoch 584/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4680 - accuracy: 0.8637 - val_loss: 1.6949 - val_accuracy: 0.4629\n",
      "Epoch 585/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4630 - accuracy: 0.8701 - val_loss: 1.4894 - val_accuracy: 0.5200\n",
      "Epoch 586/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4637 - accuracy: 0.8637 - val_loss: 1.6068 - val_accuracy: 0.4857\n",
      "Epoch 587/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4595 - accuracy: 0.8688 - val_loss: 1.4291 - val_accuracy: 0.5486\n",
      "Epoch 588/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4608 - accuracy: 0.8726 - val_loss: 1.4475 - val_accuracy: 0.5257\n",
      "Epoch 589/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4484 - accuracy: 0.8713 - val_loss: 1.8332 - val_accuracy: 0.4571\n",
      "Epoch 590/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4545 - accuracy: 0.8713 - val_loss: 1.5836 - val_accuracy: 0.4914\n",
      "Epoch 591/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4526 - accuracy: 0.8675 - val_loss: 1.5039 - val_accuracy: 0.5371\n",
      "Epoch 592/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4502 - accuracy: 0.8573 - val_loss: 1.4582 - val_accuracy: 0.5314\n",
      "Epoch 593/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4448 - accuracy: 0.8713 - val_loss: 1.5533 - val_accuracy: 0.4914\n",
      "Epoch 594/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4581 - accuracy: 0.8688 - val_loss: 1.4127 - val_accuracy: 0.5314\n",
      "Epoch 595/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4441 - accuracy: 0.8726 - val_loss: 1.5450 - val_accuracy: 0.5200\n",
      "Epoch 596/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4453 - accuracy: 0.8764 - val_loss: 1.4481 - val_accuracy: 0.5600\n",
      "Epoch 597/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4477 - accuracy: 0.8662 - val_loss: 1.4902 - val_accuracy: 0.5371\n",
      "Epoch 598/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4421 - accuracy: 0.8764 - val_loss: 1.4954 - val_accuracy: 0.5314\n",
      "Epoch 599/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4402 - accuracy: 0.8739 - val_loss: 1.4978 - val_accuracy: 0.5314\n",
      "Epoch 600/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4385 - accuracy: 0.8815 - val_loss: 1.5037 - val_accuracy: 0.5371\n",
      "Epoch 601/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4418 - accuracy: 0.8790 - val_loss: 1.4745 - val_accuracy: 0.5257\n",
      "Epoch 602/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4390 - accuracy: 0.8739 - val_loss: 1.5065 - val_accuracy: 0.5371\n",
      "Epoch 603/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4357 - accuracy: 0.8764 - val_loss: 1.5326 - val_accuracy: 0.5086\n",
      "Epoch 604/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4362 - accuracy: 0.8777 - val_loss: 1.4987 - val_accuracy: 0.5086\n",
      "Epoch 605/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4388 - accuracy: 0.8764 - val_loss: 1.4631 - val_accuracy: 0.5600\n",
      "Epoch 606/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4289 - accuracy: 0.8803 - val_loss: 1.5038 - val_accuracy: 0.5371\n",
      "Epoch 607/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4210 - accuracy: 0.8764 - val_loss: 1.4585 - val_accuracy: 0.5600\n",
      "Epoch 608/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4360 - accuracy: 0.8713 - val_loss: 1.4920 - val_accuracy: 0.5314\n",
      "Epoch 609/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4256 - accuracy: 0.8841 - val_loss: 1.6006 - val_accuracy: 0.4743\n",
      "Epoch 610/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4226 - accuracy: 0.8815 - val_loss: 1.5052 - val_accuracy: 0.4914\n",
      "Epoch 611/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4255 - accuracy: 0.8726 - val_loss: 1.5070 - val_accuracy: 0.5200\n",
      "Epoch 612/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4122 - accuracy: 0.8854 - val_loss: 1.4794 - val_accuracy: 0.5314\n",
      "Epoch 613/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4168 - accuracy: 0.8764 - val_loss: 1.5825 - val_accuracy: 0.5200\n",
      "Epoch 614/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4196 - accuracy: 0.8739 - val_loss: 1.5003 - val_accuracy: 0.5371\n",
      "Epoch 615/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4102 - accuracy: 0.8854 - val_loss: 1.4758 - val_accuracy: 0.5429\n",
      "Epoch 616/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4102 - accuracy: 0.8892 - val_loss: 1.5598 - val_accuracy: 0.5143: 0s - loss: 0.394\n",
      "Epoch 617/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4173 - accuracy: 0.8854 - val_loss: 1.6233 - val_accuracy: 0.4914\n",
      "Epoch 618/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4115 - accuracy: 0.8841 - val_loss: 1.4579 - val_accuracy: 0.5371\n",
      "Epoch 619/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4144 - accuracy: 0.8930 - val_loss: 1.4620 - val_accuracy: 0.5200\n",
      "Epoch 620/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4130 - accuracy: 0.8803 - val_loss: 1.6008 - val_accuracy: 0.4857\n",
      "Epoch 621/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3949 - accuracy: 0.8892 - val_loss: 1.5866 - val_accuracy: 0.5086\n",
      "Epoch 622/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3982 - accuracy: 0.8917 - val_loss: 1.6491 - val_accuracy: 0.4629\n",
      "Epoch 623/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4121 - accuracy: 0.8841 - val_loss: 1.7810 - val_accuracy: 0.4514\n",
      "Epoch 624/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4073 - accuracy: 0.8790 - val_loss: 1.4636 - val_accuracy: 0.5600\n",
      "Epoch 625/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4008 - accuracy: 0.8854 - val_loss: 1.4642 - val_accuracy: 0.5086\n",
      "Epoch 626/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4018 - accuracy: 0.8930 - val_loss: 1.5459 - val_accuracy: 0.4914\n",
      "Epoch 627/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.4004 - accuracy: 0.8917 - val_loss: 1.7422 - val_accuracy: 0.4800\n",
      "Epoch 628/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8892 - val_loss: 1.5735 - val_accuracy: 0.5200\n",
      "Epoch 629/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3929 - accuracy: 0.8917 - val_loss: 1.4651 - val_accuracy: 0.5543\n",
      "Epoch 630/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3920 - accuracy: 0.8968 - val_loss: 1.7382 - val_accuracy: 0.4686\n",
      "Epoch 631/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3922 - accuracy: 0.8892 - val_loss: 1.5536 - val_accuracy: 0.5029\n",
      "Epoch 632/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3908 - accuracy: 0.8828 - val_loss: 1.5835 - val_accuracy: 0.4971\n",
      "Epoch 633/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3895 - accuracy: 0.8917 - val_loss: 1.6384 - val_accuracy: 0.4629\n",
      "Epoch 634/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3893 - accuracy: 0.8777 - val_loss: 1.6139 - val_accuracy: 0.5257\n",
      "Epoch 635/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3964 - accuracy: 0.8892 - val_loss: 1.5949 - val_accuracy: 0.5086\n",
      "Epoch 636/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3771 - accuracy: 0.9045 - val_loss: 1.5603 - val_accuracy: 0.4914\n",
      "Epoch 637/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3784 - accuracy: 0.8930 - val_loss: 1.7046 - val_accuracy: 0.4971\n",
      "Epoch 638/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3873 - accuracy: 0.8841 - val_loss: 1.4865 - val_accuracy: 0.5429\n",
      "Epoch 639/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3801 - accuracy: 0.8943 - val_loss: 1.4571 - val_accuracy: 0.5771\n",
      "Epoch 640/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3792 - accuracy: 0.8981 - val_loss: 1.5105 - val_accuracy: 0.5486\n",
      "Epoch 641/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3771 - accuracy: 0.8981 - val_loss: 1.5442 - val_accuracy: 0.5029\n",
      "Epoch 642/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3755 - accuracy: 0.8994 - val_loss: 1.6855 - val_accuracy: 0.4857\n",
      "Epoch 643/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3755 - accuracy: 0.8904 - val_loss: 1.5882 - val_accuracy: 0.5029\n",
      "Epoch 644/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3724 - accuracy: 0.8968 - val_loss: 1.6129 - val_accuracy: 0.5314\n",
      "Epoch 645/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3778 - accuracy: 0.8968 - val_loss: 1.5049 - val_accuracy: 0.5143\n",
      "Epoch 646/700\n",
      "785/785 [==============================] - 6s 8ms/step - loss: 0.3658 - accuracy: 0.9070 - val_loss: 1.6158 - val_accuracy: 0.4743\n",
      "Epoch 647/700\n",
      "785/785 [==============================] - 7s 8ms/step - loss: 0.3656 - accuracy: 0.8981 - val_loss: 1.5304 - val_accuracy: 0.5086\n",
      "Epoch 648/700\n",
      "785/785 [==============================] - 6s 8ms/step - loss: 0.3694 - accuracy: 0.8943 - val_loss: 1.5246 - val_accuracy: 0.5200\n",
      "Epoch 649/700\n",
      "785/785 [==============================] - 6s 8ms/step - loss: 0.3665 - accuracy: 0.8994 - val_loss: 1.4399 - val_accuracy: 0.5600\n",
      "Epoch 650/700\n",
      "785/785 [==============================] - 1084s 1s/step - loss: 0.3725 - accuracy: 0.8930 - val_loss: 1.6290 - val_accuracy: 0.4914\n",
      "Epoch 651/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.3616 - accuracy: 0.8994 - val_loss: 1.6547 - val_accuracy: 0.4857\n",
      "Epoch 652/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3596 - accuracy: 0.8994 - val_loss: 1.5913 - val_accuracy: 0.4971\n",
      "Epoch 653/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.3544 - accuracy: 0.9006 - val_loss: 1.5344 - val_accuracy: 0.5257\n",
      "Epoch 654/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.3526 - accuracy: 0.9057 - val_loss: 1.5445 - val_accuracy: 0.5371\n",
      "Epoch 655/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.3546 - accuracy: 0.9134 - val_loss: 1.5447 - val_accuracy: 0.5371\n",
      "Epoch 656/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.3594 - accuracy: 0.8994 - val_loss: 1.5627 - val_accuracy: 0.5143\n",
      "Epoch 657/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.3551 - accuracy: 0.9057 - val_loss: 1.5434 - val_accuracy: 0.5200\n",
      "Epoch 658/700\n",
      "785/785 [==============================] - 2s 3ms/step - loss: 0.3612 - accuracy: 0.9006 - val_loss: 1.7127 - val_accuracy: 0.4629\n",
      "Epoch 659/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3551 - accuracy: 0.9134 - val_loss: 1.6039 - val_accuracy: 0.5143\n",
      "Epoch 660/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3498 - accuracy: 0.9096 - val_loss: 1.5628 - val_accuracy: 0.5086\n",
      "Epoch 661/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3500 - accuracy: 0.8955 - val_loss: 1.6216 - val_accuracy: 0.4914\n",
      "Epoch 662/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3403 - accuracy: 0.9134 - val_loss: 1.5725 - val_accuracy: 0.4971\n",
      "Epoch 663/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3429 - accuracy: 0.9019 - val_loss: 1.6633 - val_accuracy: 0.4914\n",
      "Epoch 664/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3408 - accuracy: 0.8968 - val_loss: 1.7474 - val_accuracy: 0.4971\n",
      "Epoch 665/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3336 - accuracy: 0.9236 - val_loss: 1.5399 - val_accuracy: 0.5486\n",
      "Epoch 666/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3395 - accuracy: 0.9057 - val_loss: 1.5132 - val_accuracy: 0.5200\n",
      "Epoch 667/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.3415 - accuracy: 0.9019 - val_loss: 1.6261 - val_accuracy: 0.4914\n",
      "Epoch 668/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3382 - accuracy: 0.9121 - val_loss: 1.5563 - val_accuracy: 0.5314\n",
      "Epoch 669/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3327 - accuracy: 0.9210 - val_loss: 1.5791 - val_accuracy: 0.4971\n",
      "Epoch 670/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3387 - accuracy: 0.9070 - val_loss: 1.6198 - val_accuracy: 0.4743\n",
      "Epoch 671/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3354 - accuracy: 0.9083 - val_loss: 1.4836 - val_accuracy: 0.5429\n",
      "Epoch 672/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3409 - accuracy: 0.9032 - val_loss: 1.4668 - val_accuracy: 0.5829\n",
      "Epoch 673/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3297 - accuracy: 0.9121 - val_loss: 1.5432 - val_accuracy: 0.5086\n",
      "Epoch 674/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3313 - accuracy: 0.9083 - val_loss: 1.6000 - val_accuracy: 0.5200\n",
      "Epoch 675/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3278 - accuracy: 0.9210 - val_loss: 1.7195 - val_accuracy: 0.4914\n",
      "Epoch 676/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3273 - accuracy: 0.9121 - val_loss: 1.5777 - val_accuracy: 0.5086\n",
      "Epoch 677/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3304 - accuracy: 0.9032 - val_loss: 1.7237 - val_accuracy: 0.4514\n",
      "Epoch 678/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3286 - accuracy: 0.9159 - val_loss: 1.5568 - val_accuracy: 0.5200\n",
      "Epoch 679/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3163 - accuracy: 0.9159 - val_loss: 1.7532 - val_accuracy: 0.4800\n",
      "Epoch 680/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3245 - accuracy: 0.9159 - val_loss: 1.7746 - val_accuracy: 0.4914\n",
      "Epoch 681/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3261 - accuracy: 0.9159 - val_loss: 1.5687 - val_accuracy: 0.5257\n",
      "Epoch 682/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3155 - accuracy: 0.9045 - val_loss: 1.6576 - val_accuracy: 0.4971\n",
      "Epoch 683/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3200 - accuracy: 0.9159 - val_loss: 1.5409 - val_accuracy: 0.5257\n",
      "Epoch 684/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3153 - accuracy: 0.9223 - val_loss: 1.5243 - val_accuracy: 0.5486\n",
      "Epoch 685/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3151 - accuracy: 0.9134 - val_loss: 1.5986 - val_accuracy: 0.5086\n",
      "Epoch 686/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3134 - accuracy: 0.9172 - val_loss: 1.5563 - val_accuracy: 0.5143\n",
      "Epoch 687/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3064 - accuracy: 0.9210 - val_loss: 1.9084 - val_accuracy: 0.4686\n",
      "Epoch 688/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3198 - accuracy: 0.9172 - val_loss: 1.5735 - val_accuracy: 0.5257\n",
      "Epoch 689/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3073 - accuracy: 0.9223 - val_loss: 1.5922 - val_accuracy: 0.5314\n",
      "Epoch 690/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.2997 - accuracy: 0.9274 - val_loss: 1.6013 - val_accuracy: 0.5257\n",
      "Epoch 691/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3089 - accuracy: 0.9287 - val_loss: 1.5399 - val_accuracy: 0.5600\n",
      "Epoch 692/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3039 - accuracy: 0.9223 - val_loss: 1.6660 - val_accuracy: 0.5086\n",
      "Epoch 693/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3023 - accuracy: 0.9223 - val_loss: 1.6807 - val_accuracy: 0.5200\n",
      "Epoch 694/700\n",
      "785/785 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.93 - 3s 4ms/step - loss: 0.3043 - accuracy: 0.9325 - val_loss: 1.6553 - val_accuracy: 0.4686\n",
      "Epoch 695/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3004 - accuracy: 0.9172 - val_loss: 1.5077 - val_accuracy: 0.5829\n",
      "Epoch 696/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.2983 - accuracy: 0.9248 - val_loss: 1.6488 - val_accuracy: 0.5029\n",
      "Epoch 697/700\n",
      "785/785 [==============================] - 3s 3ms/step - loss: 0.2950 - accuracy: 0.9248 - val_loss: 1.6317 - val_accuracy: 0.4800\n",
      "Epoch 698/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.3032 - accuracy: 0.9197 - val_loss: 1.5345 - val_accuracy: 0.5371\n",
      "Epoch 699/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.2992 - accuracy: 0.9223 - val_loss: 1.6112 - val_accuracy: 0.5143\n",
      "Epoch 700/700\n",
      "785/785 [==============================] - 3s 4ms/step - loss: 0.2915 - accuracy: 0.9325 - val_loss: 1.7129 - val_accuracy: 0.4971\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=700, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at C:\\Users\\niran\\OneDrive\\Desktop\\Project\\Project_Final\\Project-Final\\static\\py\\saved_models\\Emotion_Voice_Detection_Model.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 49.71%\n"
     ]
    }
   ],
   "source": [
    "# loading json and creating model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"saved_models/Emotion_Voice_Detection_Model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_testcnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting emotions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s 934us/step\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model.predict(x_testcnn, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.3107059e-04, 7.5867534e-01, 1.6998310e-02, ..., 1.5355609e-02,\n",
       "        2.9689772e-04, 1.4221893e-02],\n",
       "       [4.9009908e-04, 9.0589738e-01, 2.8636234e-04, ..., 1.4310696e-06,\n",
       "        6.1432490e-07, 6.2854810e-06],\n",
       "       [7.2338857e-04, 9.3168737e-06, 1.9660776e-07, ..., 1.0811578e-01,\n",
       "        4.4220723e-03, 8.5662496e-01],\n",
       "       ...,\n",
       "       [3.3178518e-03, 1.0396882e-03, 7.2984882e-02, ..., 8.7810174e-02,\n",
       "        7.9355566e-03, 7.2589965e-04],\n",
       "       [2.4480075e-01, 8.7389046e-05, 7.2740090e-01, ..., 2.6168616e-02,\n",
       "        8.9067784e-05, 2.1553387e-04],\n",
       "       [2.1930457e-04, 4.5302542e-04, 6.5915850e-03, ..., 3.1913483e-01,\n",
       "        2.5421951e-02, 5.0191158e-01]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1=preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 9, 0, 3, 9, 3, 0, 9, 1, 2, 1, 1, 7, 2, 4, 9, 1, 9, 6, 3, 6,\n",
       "       5, 8, 7, 5, 0, 5, 5, 1, 4, 5, 2, 3, 6, 8, 1, 4, 0, 6, 1, 3, 1, 5,\n",
       "       9, 9, 1, 9, 0, 9, 7, 8, 1, 3, 0, 0, 5, 5, 1, 3, 9, 8, 1, 8, 7, 7,\n",
       "       0, 5, 2, 0, 8, 5, 3, 0, 3, 3, 2, 3, 5, 5, 9, 9, 7, 4, 3, 3, 0, 5,\n",
       "       5, 0, 1, 0, 3, 0, 8, 2, 1, 3, 3, 5, 1, 9, 5, 7, 8, 8, 2, 4, 1, 9,\n",
       "       9, 8, 5, 1, 7, 7, 9, 1, 3, 0, 5, 3, 0, 7, 4, 7, 5, 9, 0, 4, 9, 6,\n",
       "       2, 7, 7, 9, 0, 9, 7, 6, 7, 6, 0, 5, 9, 9, 5, 3, 3, 7, 2, 8, 8, 4,\n",
       "       0, 2, 9, 1, 3, 5, 3, 3, 1, 3, 8, 0, 6, 3, 0, 7, 3, 3, 3, 2, 9],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = preds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (lb.inverse_transform((abc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predictedvalues\n",
       "0       female_calm\n",
       "1       female_calm\n",
       "2          male_sad\n",
       "3      female_angry\n",
       "4      female_happy\n",
       "..              ...\n",
       "170    female_happy\n",
       "171    female_happy\n",
       "172    female_happy\n",
       "173  female_fearful\n",
       "174        male_sad\n",
       "\n",
       "[175 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
    "preddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test.argmax(axis=1)\n",
    "abc123 = actual.astype(int).flatten()\n",
    "actualvalues = (lb.inverse_transform((abc123)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>male_calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actualvalues\n",
       "0        female_sad\n",
       "1       female_calm\n",
       "2          male_sad\n",
       "3      female_angry\n",
       "4      female_happy\n",
       "..              ...\n",
       "170    female_happy\n",
       "171     female_calm\n",
       "172    female_angry\n",
       "173  female_fearful\n",
       "174       male_calm\n",
       "\n",
       "[175 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
    "actualdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = actualdf.join(preddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Actual v/s Predicted emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_calm</td>\n",
       "      <td>female_calm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_angry</td>\n",
       "      <td>female_angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>female_calm</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>female_angry</td>\n",
       "      <td>female_happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>female_fearful</td>\n",
       "      <td>female_fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>male_calm</td>\n",
       "      <td>male_sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       actualvalues predictedvalues\n",
       "0        female_sad     female_calm\n",
       "1       female_calm     female_calm\n",
       "2          male_sad        male_sad\n",
       "3      female_angry    female_angry\n",
       "4      female_happy    female_happy\n",
       "..              ...             ...\n",
       "170    female_happy    female_happy\n",
       "171     female_calm    female_happy\n",
       "172    female_angry    female_happy\n",
       "173  female_fearful  female_fearful\n",
       "174       male_calm        male_sad\n",
       "\n",
       "[175 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_column = np.where(finaldf[\"actualvalues\"] == finaldf[\"predictedvalues\"], True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf['equal']=comparison_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf=finaldf.groupby(['actualvalues','equal']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf_reset=finaldf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion=finaldf_reset.actualvalues.unique()\n",
    "sum=[]\n",
    "for i in range(0,len(emotion)):\n",
    "    subset_df = finaldf_reset[finaldf_reset['actualvalues']==emotion[i]]\n",
    "    sum.append((subset_df.predictedvalues/subset_df.predictedvalues.sum()*100).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "percentage=reduce(lambda x,y: x+y,sum)\n",
    "finaldf_reset['percentage']=percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actualvalues</th>\n",
       "      <th>equal</th>\n",
       "      <th>predictedvalues</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female_angry</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>47.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female_angry</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>52.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female_calm</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female_calm</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>73.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female_fearful</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female_fearful</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>21.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>female_happy</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>78.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female_sad</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>23.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>15.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>male_angry</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>84.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>male_calm</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>76.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>male_calm</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>23.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>male_fearful</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>57.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>male_fearful</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>42.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>male_happy</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>71.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>male_happy</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>male_sad</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actualvalues  equal  predictedvalues  percentage\n",
       "0     female_angry  False               10   47.619048\n",
       "1     female_angry   True               11   52.380952\n",
       "2      female_calm  False                4   26.666667\n",
       "3      female_calm   True               11   73.333333\n",
       "4   female_fearful  False               15   71.428571\n",
       "5   female_fearful   True                6   28.571429\n",
       "6     female_happy  False                4   21.052632\n",
       "7     female_happy   True               15   78.947368\n",
       "8       female_sad  False               16   76.190476\n",
       "9       female_sad   True                5   23.809524\n",
       "10      male_angry  False                3   15.789474\n",
       "11      male_angry   True               16   84.210526\n",
       "12       male_calm  False               16   76.190476\n",
       "13       male_calm   True                5   23.809524\n",
       "14    male_fearful  False               11   57.894737\n",
       "15    male_fearful   True                8   42.105263\n",
       "16      male_happy  False                5   71.428571\n",
       "17      male_happy   True                2   28.571429\n",
       "18        male_sad  False                4   33.333333\n",
       "19        male_sad   True                8   66.666667"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,7))  \n",
    "\n",
    "detected = finaldf_reset['equal'].drop_duplicates()\n",
    "margin_bottom = np.zeros(len(finaldf_reset['actualvalues'].drop_duplicates()))\n",
    "colors = [\"#FF3333\", \"#31A354\"]\n",
    "\n",
    "for num, month in enumerate(detected):\n",
    "    values = list(finaldf_reset[finaldf_reset['equal'] == month].loc[:, 'percentage'])\n",
    "\n",
    "    finaldf_reset[finaldf_reset['equal'] == month].plot.bar(x='actualvalues',y='percentage', ax=ax, stacked=True, \n",
    "                                    bottom = margin_bottom, color=colors[num], label=month)\n",
    "    margin_bottom += values\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "subset_df = finaldf_reset[finaldf_reset['actualvalues']=='male_sad']\n",
    "print(subset_df.predictedvalues.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualvalues</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female_angry</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_calm</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_fearful</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_happy</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female_sad</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_angry</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_calm</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_fearful</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_happy</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male_sad</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predictedvalues\n",
       "actualvalues                   \n",
       "female_angry                  2\n",
       "female_calm                   2\n",
       "female_fearful                2\n",
       "female_happy                  2\n",
       "female_sad                    2\n",
       "male_angry                    2\n",
       "male_calm                     2\n",
       "male_fearful                  2\n",
       "male_happy                    2\n",
       "male_sad                      2"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('actualvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictedvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2, 3, 4, 5, 6, 8, 10, 11, 15, 16]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf.groupby('predictedvalues').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The file 'output10.wav' in the next cell is the file that was recorded live using the code in AudioRecoreder notebook found in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load('output10.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x20d6df80550>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# % pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import glob \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveplot(data, sr=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#livedf= pd.DataFrame(columns=['feature'])\n",
    "X, sample_rate = librosa.load('AudioFile/03-02-05-01-01-01-07.wav', res_type='kaiser_fast',duration=2.5,sr=22050*2,offset=0.5)\n",
    "sample_rate = np.array(sample_rate)\n",
    "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
    "featurelive = mfccs\n",
    "livedf2 = featurelive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2= pd.DataFrame(data=livedf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "livedf2 = livedf2.stack().to_frame().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>-54.311943</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.463947</td>\n",
       "      <td>-32.431175</td>\n",
       "      <td>-31.96899</td>\n",
       "      <td>-33.014484</td>\n",
       "      <td>-35.74715</td>\n",
       "      <td>-34.635471</td>\n",
       "      <td>-33.296459</td>\n",
       "      <td>-24.63722</td>\n",
       "      <td>-19.529123</td>\n",
       "      <td>-15.690511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "           0          0          0          0          0          0   \n",
       "0 -54.311943 -54.311943 -54.311943 -54.311943 -54.311943 -54.311943   \n",
       "\n",
       "         6          7          8          9    ...        206        207  \\\n",
       "           0          0          0          0  ...          0          0   \n",
       "0 -54.311943 -54.311943 -54.311943 -54.311943  ... -31.463947 -32.431175   \n",
       "\n",
       "        208        209       210        211        212       213        214  \\\n",
       "          0          0         0          0          0         0          0   \n",
       "0 -31.96899 -33.014484 -35.74715 -34.635471 -33.296459 -24.63722 -19.529123   \n",
       "\n",
       "         215  \n",
       "           0  \n",
       "0 -15.690511  \n",
       "\n",
       "[1 rows x 216 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livedf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "twodim= np.expand_dims(livedf2, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "livepreds = loaded_model.predict(twodim, \n",
    "                         batch_size=32, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.2869291e-06, 7.0907280e-10, 4.6659920e-10, 6.9979293e-13,\n",
       "        1.0852528e-08, 9.7627568e-01, 9.5520569e-05, 1.0852168e-02,\n",
       "        8.5640255e-05, 1.2685582e-02]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "livepreds1=livepreds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveabc = livepreds1.astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['male_angry'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livepredictions = (lb.inverse_transform((liveabc)))\n",
    "livepredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
